{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "169193be",
   "metadata": {},
   "source": [
    "# ğŸ§° Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ø«Ø§Ù„Ø«: Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù€ NLP | NLP Tools\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ **Ù‡Ø°Ø§ Ø§Ù„Ù†ÙˆØªØ¨ÙˆÙƒ ÙŠÙ…Ø«Ù„ Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ø«Ø§Ù„Ø« Ù…Ù† Ø§Ù„ÙƒÙˆØ±Ø³**ØŒ Ø¨Ø¹Ø¯ Ø£Ù† ØªØ¹Ø±Ù‘ÙÙ†Ø§ Ø¹Ù„Ù‰ Ù…Ù‚Ø¯Ù…Ø© Ø§Ù„Ù…Ø¬Ø§Ù„ ÙˆØ£Ø³Ø§Ø³ÙŠØ§Øª Ø§Ù„Ù€ NLP.\n",
    "> Ø³Ù†ØªÙ†Ø§ÙˆÙ„ ÙÙŠÙ‡ Ø£Ù‡Ù… Ø§Ù„Ø£Ø¯ÙˆØ§Øª ÙˆØ§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ ÙˆÙÙ‡Ù… Ø§Ù„Ù„ØºØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨Ø§ÙŠØ«ÙˆÙ†.\n",
    "\n",
    "> ğŸ‡¬ğŸ‡§ **This notebook represents the third section of the course**, following the introduction and NLP basics.\n",
    "> Here, weâ€™ll explore the main tools and libraries used in Python for text analysis and language understanding.\n",
    "\n",
    "---\n",
    "# âœ‚ï¸ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø£ÙˆÙ„: Ø§Ù„ØªØ±Ù…ÙŠØ² (Tokenization) | Tokenization Overview\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ **Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©:**\n",
    "> Ø§Ù„ØªØ±Ù…ÙŠØ² Ø£Ùˆ **Tokenization** Ù‡Ùˆ Ø£ÙˆÙ„ ÙˆØ£Ù‡Ù… Ø®Ø·ÙˆØ© ÙÙŠ Ø£ÙŠ Ù…Ø´Ø±ÙˆØ¹ **Ù…Ø¹Ø§Ù„Ø¬Ø© Ù„ØºØ© Ø·Ø¨ÙŠØ¹ÙŠØ© (NLP)**.\n",
    "> ÙˆÙ‡ÙŠ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªÙŠ Ù†Ù‚ÙˆÙ… ÙÙŠÙ‡Ø§ **Ø¨ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡ ØµØºÙŠØ±Ø© ØªØ³Ù…Ù‘Ù‰ â€œTokensâ€** â€” Ù…Ø«Ù„ Ø§Ù„ÙƒÙ„Ù…Ø§ØªØŒ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø§ØªØŒ Ø£Ùˆ Ø­ØªÙ‰ Ø§Ù„Ø¬Ù…Ù„.\n",
    "> ØªØ³Ø§Ø¹Ø¯Ù†Ø§ Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø·ÙˆØ© Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ ÙƒÙ„ ÙƒÙ„Ù…Ø© Ø£Ùˆ ÙˆØ­Ø¯Ø© Ù„ØºÙˆÙŠØ© Ø¹Ù„Ù‰ Ø­Ø¯Ø© Ù„Ù…Ø¹Ø±ÙØ© Ù…Ø¹Ù†Ø§Ù‡Ø§ØŒ Ù†ÙˆØ¹Ù‡Ø§ØŒ ÙˆØ¯ÙˆØ±Ù‡Ø§ ÙÙŠ Ø§Ù„Ø¬Ù…Ù„Ø©.\n",
    "\n",
    "> ğŸ‡¬ğŸ‡§ **In English:**\n",
    "> **Tokenization** is the first and most fundamental step in any **Natural Language Processing (NLP)** workflow.\n",
    "> It means **splitting text into smaller meaningful units called â€œtokensâ€**, such as words, subwords, or sentences.\n",
    "> This process allows us to analyze and understand the structure and meaning of each word or phrase individually.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"assets/tokenization.jpeg\" alt=\"NLP Tools\" width=\"250\">\n",
    "</p>\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§© Ù„Ù…Ø§Ø°Ø§ Ù†Ø­ØªØ§Ø¬ Ø¥Ù„Ù‰ TokenizationØŸ | Why Tokenization Matters\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ Ø¨Ø¯ÙˆÙ† ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¬Ù…Ù„ Ø¥Ù„Ù‰ ÙƒÙ„Ù…Ø§ØªØŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ù„Ù„Ù†Ø¸Ø§Ù… Ø£Ù† ÙŠØ¹Ø±Ù:\n",
    ">\n",
    "> * Ø£ÙŠÙ† ØªØ¨Ø¯Ø£ ÙˆØªÙ†ØªÙ‡ÙŠ Ø§Ù„ÙƒÙ„Ù…Ø©.\n",
    "> * Ù…Ø§ Ù†ÙˆØ¹ Ø§Ù„ÙƒÙ„Ù…Ø© (ÙØ¹Ù„ØŒ Ø§Ø³Ù…ØŒ Ø¶Ù…ÙŠØ±...).\n",
    "> * ÙƒÙŠÙ ØªØ±Ø¨Ø· Ø¨ÙŠÙ† Ø§Ù„Ù…Ø¹Ø§Ù†ÙŠ ÙÙŠ Ø§Ù„Ø¬Ù…Ù„Ø©.\n",
    ">\n",
    "> Ù…Ø«Ø§Ù„:\n",
    "> `\"I'm learning NLP!\"`\n",
    "> ÙŠØ¬Ø¨ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø§Ø³ÙˆØ¨ Ø£Ù† ÙŠÙÙ‡Ù… Ø£Ù† `\"I'm\"` = `\"I\" + \"am\"`ØŒ ÙˆØ£Ù† `\"NLP\"` ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø©ØŒ ÙˆÙ„ÙŠØ³Øª Ø«Ù„Ø§Ø« Ø­Ø±ÙˆÙ Ù…Ù†ÙØµÙ„Ø©.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ Without tokenization, a computer canâ€™t understand where one word ends and another begins â€”\n",
    "> or how words relate to each other in a sentence.\n",
    "> Example: `\"I'm learning NLP!\"` â†’ `\"I\" + \"am\"` and `\"NLP\"` is a single entity, not three separate letters.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§± Ø£Ù†ÙˆØ§Ø¹ Tokenization | Types of Tokenization\n",
    "\n",
    "| Ø§Ù„Ù†ÙˆØ¹                  | ğŸ‡¸ğŸ‡¦ Ø§Ù„Ø´Ø±Ø­ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©                                       | ğŸ‡¬ğŸ‡§ Explanation in English                      |\n",
    "| ---------------------- | --------------------------------------------------------- | ------------------------------------------------ |\n",
    "| **Word Tokenizer**     | ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª ÙØ±Ø¯ÙŠØ© (Ù…Ø«Ù„ ÙØµÙ„ â€œIâ€™mâ€ Ø¥Ù„Ù‰ â€œIâ€ Ùˆ â€œamâ€) | Splits text into individual words or subwords    |\n",
    "| **Sentence Tokenizer** | ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø¬Ù…Ù„ (Ù„ÙƒÙ„ Ø¬Ù…Ù„Ø© ØªØ­Ù„ÙŠÙ„ Ù…Ù†ÙØµÙ„)                 | Splits text into sentences for separate analysis |\n",
    "\n",
    "---\n",
    "\n",
    "## âš–ï¸ Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† split() Ùˆ tokenizer\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† `split()` Ùˆ Tokenization Ù…Ù‡Ù… Ø¬Ø¯Ù‹Ø§:\n",
    ">\n",
    "> * `split()` ÙŠØ¹ØªÙ…Ø¯ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø£Ùˆ Ø§Ù„Ø±Ù…ÙˆØ².\n",
    "> * Ø¨ÙŠÙ†Ù…Ø§ Ø§Ù„Ù€ Tokenizer ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ **Ù…Ø¹Ù†Ù‰ Ø§Ù„Ù†Øµ** ÙˆÙŠØ£Ø®Ø° Ø¨Ø¹ÙŠÙ† Ø§Ù„Ø§Ø¹ØªØ¨Ø§Ø± Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ…ØŒ ÙˆØ§Ù„Ø§Ø®ØªØµØ§Ø±Ø§ØªØŒ ÙˆØ§Ù„Ø¶Ù…Ø§Ø¦Ø± Ø§Ù„Ù…Ø±ÙƒØ¨Ø©.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ The difference between `split()` and real tokenization is crucial:\n",
    ">\n",
    "> * `split()` just breaks text at spaces or symbols.\n",
    "> * `tokenizer` understands the **linguistic meaning**, punctuation, and contractions like `\"donâ€™t\"` or `\"Iâ€™m\"`.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸŒ ØªØ­Ø¯Ù‘ÙŠØ§Øª Tokenization ÙÙŠ Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ© | Tokenization Challenges Across Languages\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ ØªØ®ØªÙ„Ù Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ±Ù…ÙŠØ² Ø¨ÙŠÙ† Ø§Ù„Ù„ØºØ§Øª:\n",
    ">\n",
    "> * ÙÙŠ **Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©** Ø§Ù„ØªØ­Ø¯ÙŠ Ù‡Ùˆ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø§Ø®ØªØµØ§Ø±Ø§Øª Ù…Ø«Ù„ *Iâ€™m â€“ donâ€™t â€“ U.S.*\n",
    "> * ÙÙŠ **Ø§Ù„ÙØ±Ù†Ø³ÙŠØ©** Ùˆ **Ø§Ù„Ø£Ù„Ù…Ø§Ù†ÙŠØ©** Ø§Ù„Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ù„ØªØµÙ‚Ø© (Ù…Ø«Ù„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø±ÙƒØ¨Ø© Ø§Ù„Ø·ÙˆÙŠÙ„Ø©).\n",
    "> * ÙÙŠ **Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©** Ù„Ø¯ÙŠÙ†Ø§ Ù…Ø´ÙƒÙ„Ø© **Ø§Ù„Ø§Ù„ØªØµØ§Ù‚** Ø¨ÙŠÙ† Ø§Ù„Ø¶Ù…Ø§Ø¦Ø± ÙˆØ§Ù„ÙƒÙ„Ù…Ø§Øª (\"ÙƒØªØ§Ø¨ÙÙ‡\" = \"ÙƒØªØ§Ø¨\" + \"Ù‡Ù\").\n",
    "> * Ø£Ù…Ø§ ÙÙŠ **Ø§Ù„ØµÙŠÙ†ÙŠØ© ÙˆØ§Ù„ÙŠØ§Ø¨Ø§Ù†ÙŠØ©** ÙÙ„Ø§ ØªÙˆØ¬Ø¯ Ù…Ø³Ø§ÙØ§Øª Ø£ØµÙ„Ù‹Ø§ Ø¨ÙŠÙ† Ø§Ù„ÙƒÙ„Ù…Ø§ØªØŒ ÙÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø·Ø±ÙŠÙ‚Ø© ØªØ³Ù…Ù‘Ù‰ **Max-Match Algorithm**\n",
    ">   Ù„ØªØ­Ø¯ÙŠØ¯ Ø£Ø·ÙˆÙ„ ØªØ³Ù„Ø³Ù„ Ù…Ù† Ø§Ù„Ø£Ø­Ø±Ù ÙŠÙ…ÙƒÙ† Ø£Ù† ÙŠÙØ´ÙƒÙ‘Ù„ ÙƒÙ„Ù…Ø© Ø°Ø§Øª Ù…Ø¹Ù†Ù‰.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ Tokenization varies across languages:\n",
    ">\n",
    "> * **English:** Handles contractions and abbreviations.\n",
    "> * **French / German:** Deals with compound or glued words.\n",
    "> * **Arabic:** Must separate prefixes/suffixes (e.g., â€œÙƒØªØ§Ø¨Ù‡â€ â†’ â€œÙƒØªØ§Ø¨ + Ù‡â€).\n",
    "> * **Chinese / Japanese:** No spaces at all â€” use a **Max-Match algorithm** to detect valid words.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”„ Ø®Ø·ÙˆØ§Øª Tokenization | How Tokenization Works\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"assets/tokenization-steps.jpeg.png\" alt=\"NLP Tools\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ **Ù…Ù„Ø§Ø­Ø¸Ø©:** Ø®Ø·ÙˆØ§Øª Ø§Ù„Ù€ Tokenization Ù„ÙŠØ³Øª Ø«Ø§Ø¨ØªØ©ØŒ Ø¨Ù„ ØªØªØºÙŠÙ‘Ø± Ø­Ø³Ø¨ Ø§Ù„Ù„ØºØ©ØŒ ÙˆØ§Ù„Ø³ÙŠØ§Ù‚ØŒ ÙˆØ·Ø¨ÙŠØ¹Ø© Ø§Ù„Ù†Øµ.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ **Note:** Tokenization steps arenâ€™t fixed â€” they adapt dynamically to the language, context, and text structure.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14ca5994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (3.8.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.8.8-cp310-cp310-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.8-cp310-cp310-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Collecting weasel<0.5.0,>=0.4.2 (from spacy)\n",
      "  Downloading weasel-0.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer-slim<1.0.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from spacy) (2.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from spacy) (2.32.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from spacy) (2.12.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from spacy) (72.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from spacy) (25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.10.5)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.3.0-cp310-cp310-win_amd64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from typer-slim<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.21.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.3.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shosh\\.conda\\envs\\nlp\\lib\\site-packages (from jinja2->spacy) (3.0.2)\n",
      "Downloading spacy-3.8.8-cp310-cp310-win_amd64.whl (15.3 MB)\n",
      "   ---------------------------------------- 0.0/15.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/15.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.8/15.3 MB 7.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.6/15.3 MB 17.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.9/15.3 MB 22.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.3/15.3 MB 21.4 MB/s  0:00:00\n",
      "Downloading thinc-8.3.8-cp310-cp310-win_amd64.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/1.8 MB 24.6 MB/s  0:00:00\n",
      "Downloading blis-1.3.0-cp310-cp310-win_amd64.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   -------------------------------------- - 6.0/6.2 MB 37.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 29.5 MB/s  0:00:00\n",
      "Downloading typer_slim-0.20.0-py3-none-any.whl (47 kB)\n",
      "Downloading weasel-0.4.2-py3-none-any.whl (50 kB)\n",
      "Installing collected packages: blis, typer-slim, weasel, thinc, spacy\n",
      "\n",
      "  Attempting uninstall: blis\n",
      "\n",
      "    Found existing installation: blis 1.0.1\n",
      "\n",
      "    Uninstalling blis-1.0.1:\n",
      "\n",
      "      Successfully uninstalled blis-1.0.1\n",
      "\n",
      "   ---------------------------------------- 0/5 [blis]\n",
      "   ---------------------------------------- 0/5 [blis]\n",
      "   -------- ------------------------------- 1/5 [typer-slim]\n",
      "   -------- ------------------------------- 1/5 [typer-slim]\n",
      "   -------- ------------------------------- 1/5 [typer-slim]\n",
      "  Attempting uninstall: weasel\n",
      "   -------- ------------------------------- 1/5 [typer-slim]\n",
      "    Found existing installation: weasel 0.4.1\n",
      "   -------- ------------------------------- 1/5 [typer-slim]\n",
      "    Uninstalling weasel-0.4.1:\n",
      "   -------- ------------------------------- 1/5 [typer-slim]\n",
      "      Successfully uninstalled weasel-0.4.1\n",
      "   -------- ------------------------------- 1/5 [typer-slim]\n",
      "   ---------------- ----------------------- 2/5 [weasel]\n",
      "   ---------------- ----------------------- 2/5 [weasel]\n",
      "   ---------------- ----------------------- 2/5 [weasel]\n",
      "   ---------------- ----------------------- 2/5 [weasel]\n",
      "   ---------------- ----------------------- 2/5 [weasel]\n",
      "   ---------------- ----------------------- 2/5 [weasel]\n",
      "  Attempting uninstall: thinc\n",
      "   ---------------- ----------------------- 2/5 [weasel]\n",
      "    Found existing installation: thinc 8.3.2\n",
      "   ---------------- ----------------------- 2/5 [weasel]\n",
      "   ------------------------ --------------- 3/5 [thinc]\n",
      "    Uninstalling thinc-8.3.2:\n",
      "   ------------------------ --------------- 3/5 [thinc]\n",
      "      Successfully uninstalled thinc-8.3.2\n",
      "   ------------------------ --------------- 3/5 [thinc]\n",
      "   ------------------------ --------------- 3/5 [thinc]\n",
      "   ------------------------ --------------- 3/5 [thinc]\n",
      "   ------------------------ --------------- 3/5 [thinc]\n",
      "   ------------------------ --------------- 3/5 [thinc]\n",
      "   ------------------------ --------------- 3/5 [thinc]\n",
      "   ------------------------ --------------- 3/5 [thinc]\n",
      "   ------------------------ --------------- 3/5 [thinc]\n",
      "   ------------------------ --------------- 3/5 [thinc]\n",
      "   ------------------------ --------------- 3/5 [thinc]\n",
      "   ------------------------ --------------- 3/5 [thinc]\n",
      "   ------------------------ --------------- 3/5 [thinc]\n",
      "   ------------------------ --------------- 3/5 [thinc]\n",
      "   ------------------------ --------------- 3/5 [thinc]\n",
      "   ------------------------ --------------- 3/5 [thinc]\n",
      "   ------------------------ --------------- 3/5 [thinc]\n",
      "   ------------------------ --------------- 3/5 [thinc]\n",
      "   ------------------------ --------------- 3/5 [thinc]\n",
      "   ------------------------ --------------- 3/5 [thinc]\n",
      "  Attempting uninstall: spacy\n",
      "   ------------------------ --------------- 3/5 [thinc]\n",
      "    Found existing installation: spacy 3.8.2\n",
      "   ------------------------ --------------- 3/5 [thinc]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "    Uninstalling spacy-3.8.2:\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "      Successfully uninstalled spacy-3.8.2\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   -------------------------------- ------- 4/5 [spacy]\n",
      "   ---------------------------------------- 5/5 [spacy]\n",
      "\n",
      "Successfully installed blis-1.3.0 spacy-3.8.8 thinc-8.3.8 typer-slim-0.20.0 weasel-0.4.2\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     -- ------------------------------------- 0.8/12.8 MB 4.2 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.2/12.8 MB 11.4 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 10.2/12.8 MB 17.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 17.4 MB/s  0:00:00\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# ØªØ«Ø¨ÙŠØª ÙˆØ§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª | Installing and Importing Libraries\n",
    "%pip install -U spacy\n",
    "# ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¥Ù†ÙƒÙ„ÙŠØ²ÙŠØ© Ø§Ù„ØµØºÙŠØ± Ø¥Ù† Ù„Ù… ÙŠÙƒÙ† Ù…Ø«Ø¨ØªÙ‹Ø§\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a066f452",
   "metadata": {},
   "source": [
    "> âœ… **Ù…Ù„Ø§Ø­Ø¸Ø© Ù…Ù‡Ù…Ø© (Update 2025):**\n",
    "> Ø§Ù„Ù…ÙƒØªØ¨Ø© **spaCy** Ù…Ø§ Ø²Ø§Ù„Øª ØªÙØ³ØªØ®Ø¯Ù… Ø¨ÙƒØ«Ø±Ø©ØŒ Ù„ÙƒÙ† Ø§Ù„Ø¢Ù† Ø£ØºÙ„Ø¨ Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ Ø§Ù„Ø­Ø¯ÙŠØ«Ø© ØªØ³ØªØ®Ø¯Ù…Ù‡Ø§ Ù…Ø¹ Ù…ÙƒØªØ¨Ø© **transformers** Ù…Ù† HuggingFace Ù„ØªØ­Ù„ÙŠÙ„ Ø£Ø¹Ù…Ù‚ (semantic analysis).\n",
    "> ÙˆÙ…Ø¹ Ø°Ù„ÙƒØŒ ØªØ¨Ù‚Ù‰ spaCy Ù…Ù…ØªØ§Ø²Ø© Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adc01026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla\n",
      "Xxxxx\n",
      "True\n",
      "---------------\n",
      "is\n",
      "xx\n",
      "True\n",
      "---------------\n",
      "looking\n",
      "xxxx\n",
      "True\n",
      "---------------\n",
      "at\n",
      "xx\n",
      "True\n",
      "---------------\n",
      "buying\n",
      "xxxx\n",
      "True\n",
      "---------------\n",
      "U.S.\n",
      "X.X.\n",
      "False\n",
      "---------------\n",
      "startup\n",
      "xxxx\n",
      "True\n",
      "---------------\n",
      "for\n",
      "xxx\n",
      "True\n",
      "---------------\n",
      "$\n",
      "$\n",
      "False\n",
      "---------------\n",
      "69\n",
      "dd\n",
      "False\n",
      "---------------\n",
      "million\n",
      "xxxx\n",
      "True\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# Ù…Ø«Ø§Ù„ Ø¹Ù…Ù„ÙŠ: ØªØ­Ù„ÙŠÙ„ Ø¬Ù…Ù„Ø© Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© | Example: English Sentence Analysis\n",
    "doc = nlp('Tesla is looking at buying U.S. startup for $69 million')\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text)\n",
    "    print(token.shape_)\n",
    "    print(token.is_alpha)\n",
    "    print('---------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486686b4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ ÙŠÙ‚ÙˆÙ… Ù‡Ø°Ø§ Ø§Ù„ÙƒÙˆØ¯ Ø¨ØªØ¬Ø²Ø¦Ø© Ø§Ù„Ø¬Ù…Ù„Ø© Ø¥Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª (Tokens)ØŒ ÙˆÙŠØ¹Ø±Ø¶:\n",
    ">\n",
    "> * Ø´ÙƒÙ„ Ø§Ù„ÙƒÙ„Ù…Ø© (`token.shape_`) Ù…Ø«Ù„: XxxxxØŒ ddØŒ X.X.\n",
    "> * Ù‡Ù„ Ù‡ÙŠ Ø­Ø±ÙˆÙ (`is_alpha`) Ø£Ù… Ø£Ø±Ù‚Ø§Ù… Ø£Ùˆ Ø±Ù…ÙˆØ².\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ This code splits the sentence into tokens and prints:\n",
    ">\n",
    "> * The word shape (`token.shape_`): e.g., Xxxxx, dd, X.X.\n",
    "> * Whether itâ€™s alphabetic or not (`is_alpha`).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b102775b",
   "metadata": {},
   "source": [
    "\n",
    "## ğŸ§  Ù…Ù„Ø§Ø­Ø¸Ø© ØªØ­Ù„ÙŠÙ„ÙŠØ© | Analytical Note\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ **Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©:**\n",
    "> Ù†Ù„Ø§Ø­Ø¸ Ø£Ù† Ù…ÙƒØªØ¨Ø© **spaCy** ØªÙØµÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø¨Ø°ÙƒØ§Ø¡ â€” ÙÙ…Ø«Ù„Ù‹Ø§ `$69` ÙŠØªÙ… ÙÙ‡Ù…Ù‡Ø§ ÙƒØ±Ù…Ø² **$** Ù…Ù†ÙØµÙ„ Ø¹Ù† **Ø§Ù„Ø±Ù‚Ù…**ØŒ\n",
    "> Ø¨ÙŠÙ†Ù…Ø§ ØªØªØ¹Ø§Ù…Ù„ Ù…Ø¹ **\"U.S.\"** ÙƒÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø© Ø±ØºÙ… ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù†Ù‚Ø§Ø·ØŒ Ù„Ø£Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºÙˆÙŠ ÙŠØ¯Ø±Ùƒ Ø£Ù†Ù‡Ø§ **Ø§Ø®ØªØµØ§Ø± Ù„Ø¯ÙˆÙ„Ø©**.\n",
    "> Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ù‚Ø© ÙÙŠ Ø§Ù„ÙØµÙ„ ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ ØªØ¬Ø¹Ù„ spaCy Ù…Ù† Ø£Ù‚ÙˆÙ‰ Ø§Ù„Ø£Ø¯ÙˆØ§Øª ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ.\n",
    "\n",
    "> ğŸ‡¬ğŸ‡§ **In English:**\n",
    "> Notice how **spaCy** intelligently separates tokens â€” for example, `$69` is split into the symbol **$** and the number separately,\n",
    "> while **\"U.S.\"** remains a single token because the model recognizes it as a **country abbreviation**.\n",
    "> This level of smart segmentation is one reason spaCy is highly valued in NLP tasks.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d54af3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Tesla, is, looking, at, buying, U.S., startup, for)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø¹Ù†Ø§ØµØ± Ù…Ø¹ÙŠÙ†Ø© | Accessing Specific Tokens\n",
    "doc[0], doc[1], doc[2], doc[3], doc[4], doc[5], doc[6], doc[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b0ccde",
   "metadata": {},
   "source": [
    "> ğŸ‡¸ğŸ‡¦ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ø³ØªØ¹Ø±Ø§Ø¶ Ø§Ù„ÙƒÙ„Ù…Ø§Øª ÙˆØ§Ø­Ø¯Ø© ØªÙ„Ùˆ Ø§Ù„Ø£Ø®Ø±Ù‰ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙÙ‡Ø±Ø³Ø©.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ You can view individual tokens by indexing into the `doc` object.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49337ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Life is what happens to us while we are making other plans\n"
     ]
    }
   ],
   "source": [
    "# Ø§Ù‚ØªØ·Ø§Ø¹ Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ù†Øµ | Extracting Text Span\n",
    "doc2 = nlp('''\n",
    "Although commonly attributed to John Lennon from his song \"Beautiful Boy\",\n",
    "the phrase \"Life is what happens to us while we are making other plans\"\n",
    "was written by cartoonist Allen Saunders and published in Reader's Digest in 1957.\n",
    "''')\n",
    "\n",
    "life_quote = doc2[19:31]\n",
    "print(life_quote)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7dad9e",
   "metadata": {},
   "source": [
    "> ğŸ‡¸ğŸ‡¦ Ù‡Ù†Ø§ Ù†Ø³ØªØ®Ø±Ø¬ Ø¬Ù…Ù„Ø© ÙØ±Ø¹ÙŠØ© Ù…Ù† Ø§Ù„Ù†Øµ (Ù…Ù† Ø§Ù„ÙƒÙ„Ù…Ø© 19 Ø¥Ù„Ù‰ 31).\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ Here we extract a slice of the text from token 19 to 31.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a36b107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" | We | 're | moving | to | L.A. | ! | \" | "
     ]
    }
   ],
   "source": [
    "# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„ÙØµÙ„ Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„ÙƒÙ„Ù…Ø§Øª | Smart Tokenization Example\n",
    "mystring = '\"We\\'re moving to L.A.!\"'\n",
    "doc3 = nlp(mystring)\n",
    "\n",
    "for token in doc3:\n",
    "    print(token.text, end=' | ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c206bb",
   "metadata": {},
   "source": [
    "> ğŸ‡¸ğŸ‡¦ Ù„Ø§Ø­Ø¸ ÙƒÙŠÙ ÙŠØªÙ… ØªÙ‚Ø³ÙŠÙ… `\"Weâ€™re\"` Ø¥Ù„Ù‰ ÙƒÙ„Ù…ØªÙŠÙ† `We` Ùˆ `'re`ØŒ\n",
    "> ÙˆØ£ÙŠØ¶Ù‹Ø§ `L.A.` ØªÙØ¹ØªØ¨Ø± ÙƒÙ„Ù…Ø© ÙˆØ§Ø­Ø¯Ø© Ù„Ø£Ù† spaCy ØªØ¹Ø±Ù‘ÙÙ‡Ø§ ÙƒØ§Ø®ØªØµØ§Ø± Ù„Ù…Ø¯ÙŠÙ†Ø©.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ Notice that `\"Weâ€™re\"` becomes two tokens and `L.A.` remains one â€” handled intelligently by spaCy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9817c3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We\n",
      "'re\n",
      "here\n",
      "to\n",
      "help\n",
      "!\n",
      "Send\n",
      "snail\n",
      "-\n",
      "mail\n",
      ",\n",
      "email\n",
      "support@oursite.com\n",
      "or\n",
      "visit\n",
      "us\n",
      "at\n",
      "http://www.oursite.com\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "# Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ ÙˆØ§Ù„Ø±ÙˆØ§Ø¨Ø· | Handling Emails & URLs\n",
    "doc4 = nlp(u\"We're here to help! Send snail-mail, email support@oursite.com or visit us at http://www.oursite.com!\")\n",
    "for token in doc4:\n",
    "    print(token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3ed2da",
   "metadata": {},
   "source": [
    "> ğŸ‡¸ğŸ‡¦ Ù„Ø§Ø­Ø¸ Ø£Ù† spaCy ØªØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ (`support@oursite.com`)\n",
    "> ÙˆØ§Ù„Ø±ÙˆØ§Ø¨Ø· (`http://www.oursite.com`) ÙˆØªÙØµÙ„Ù‡Ø§ Ø¨Ø´ÙƒÙ„ ØµØ­ÙŠØ­ ÙƒØ¹Ù†Ø§ØµØ± Ù…Ø³ØªÙ‚Ù„Ø©.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ spaCy recognizes emails and URLs as separate tokens automatically.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41370d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "5\n",
      "km\n",
      "NYC\n",
      "cab\n",
      "ride\n",
      "costs\n",
      "$\n",
      "10.30\n"
     ]
    }
   ],
   "source": [
    "# Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ÙˆØ§Ù„Ø¹Ù…Ù„Ø§Øª | Numbers and Currency\n",
    "doc5 = nlp(u'A 5km NYC cab ride costs $10.30')\n",
    "for token in doc5:\n",
    "    print(token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d204da7d",
   "metadata": {},
   "source": [
    "> ğŸ‡¸ğŸ‡¦ ÙŠÙ…ÙŠØ² Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨ÙŠÙ† Ø§Ù„Ø±Ù‚Ù… ÙˆØ§Ù„ÙˆØ­Ø¯Ø© `$10.30` ÙˆÙŠÙÙ‡Ù… Ø£Ù† `$` Ù‡Ùˆ Ø±Ù…Ø² Ø¹Ù…Ù„Ø©.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ It correctly identifies `$10.30` as a currency amount and separates `$` from the digits.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70f2ba4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let\n",
      "'s\n",
      "visit\n",
      "St.\n",
      "Louis\n",
      "in\n",
      "the\n",
      "U.S.\n",
      "next\n",
      "year\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# Ø§Ø®ØªØµØ§Ø±Ø§Øª Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ ÙˆØ§Ù„Ù…ÙˆØ§Ù‚Ø¹ | Abbreviations\n",
    "doc6 = nlp(u\"Let's visit St. Louis in the U.S. next year.\")\n",
    "for token in doc6:\n",
    "    print(token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2e4dc9",
   "metadata": {},
   "source": [
    "> ğŸ‡¸ğŸ‡¦ ÙŠØ­Ø§ÙØ¸ Ø¹Ù„Ù‰ â€œSt. Louisâ€ Ùˆ â€œU.S.â€ ÙƒÙˆØ­Ø¯Ø§Øª Ù…ÙÙ‡ÙˆÙ…Ø© â€” Ø§Ø®ØªØµØ§Ø±Ø§Øª Ù…Ø¹Ø±ÙˆÙØ©.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ It keeps â€œSt. Louisâ€ and â€œU.S.â€ as meaningful single entities.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9461849",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'spacy.tokens.doc.Doc' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m doc7 \u001b[38;5;241m=\u001b[39m nlp(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMy dinner was horrible.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m doc8 \u001b[38;5;241m=\u001b[39m nlp(\u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYour dinner was delicious.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mdoc7\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m doc8[\u001b[38;5;241m3\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'spacy.tokens.doc.Doc' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "# Ø®Ø§ØµÙŠØ© Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© ÙÙ‚Ø· | Read-Only Tokens\n",
    "doc7 = nlp(u'My dinner was horrible.')\n",
    "doc8 = nlp(u'Your dinner was delicious.')\n",
    "doc7[3] = doc8[3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a5af2a",
   "metadata": {},
   "source": [
    "> âŒ Ù‡Ø°Ø§ Ø³ÙŠÙØ±Ø¬Ø¹ Ø§Ù„Ø®Ø·Ø£:\n",
    ">\n",
    "> ```\n",
    "> TypeError: 'spacy.tokens.doc.Doc' object does not support item assignment\n",
    "> ```\n",
    ">\n",
    "> ğŸ‡¸ğŸ‡¦ Ù„Ø£Ù† Ø¹Ù…Ù„ÙŠØ© **Tokenization** Ù…Ø®ØµÙ‘ØµØ© Ù„Ù„Ù‚Ø±Ø§Ø¡Ø© ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ ÙÙ‚Ø·ØŒ\n",
    "> ÙˆÙ„Ø§ ÙŠÙ…ÙƒÙ† ØªØ¹Ø¯ÙŠÙ„ Ø£Ùˆ Ø§Ø³ØªØ¨Ø¯Ø§Ù„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø¨Ø¹Ø¯ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØªÙˆÙƒÙ†Ø².\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ Tokenization is a **read-only process** â€” once text is tokenized,\n",
    "> you canâ€™t modify or reassign tokens directly.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f5fbd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'Mr.', 'Smith', ',', 'how', 'are', 'you', 'doing', 'today', '?', 'The', 'weather', 'is', 'great', ',', 'and', 'Python', 'is', 'awesome', '.', 'The', 'sky', 'is', 'pinkish-blue', '.', 'You', 'should', \"n't\", 'eat', 'cardboard', '.']\n"
     ]
    }
   ],
   "source": [
    "# Ø§Ø³ØªØ®Ø¯Ø§Ù… NLTK Ù„Ù„Ù…Ù‚Ø§Ø±Ù†Ø© | Comparing with NLTK\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "EXAMPLE_TEXT = \"\"\"\n",
    "Hello Mr. Smith, how are you doing today? The weather is great, \n",
    "and Python is awesome. The sky is pinkish-blue. You shouldn't eat cardboard.\n",
    "\"\"\"\n",
    "\n",
    "print(word_tokenize(EXAMPLE_TEXT))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f606a4",
   "metadata": {},
   "source": [
    "> ğŸ‡¸ğŸ‡¦ ØªÙ‚ÙˆÙ… NLTK Ø¨ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¬Ù…Ù„ Ø¥Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù†Ù‰ ÙˆÙ„ÙŠØ³ ÙÙ‚Ø· Ø§Ù„Ù…Ø³Ø§ÙØ§Øª.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ NLTK tokenizes text more intelligently than simple `split()` â€” it understands punctuation and contractions.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4df649f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thomas', 'Gradgrind', ',', 'sir', '.', 'A', 'man', 'of', 'realities', '.', 'A', 'man', 'of', 'facts', 'and', 'calculations', '.', 'A', 'man', 'who', 'proceeds', 'upon', 'the', 'principle', 'that', 'two', 'and', 'two', 'are', 'four', '...']\n"
     ]
    }
   ],
   "source": [
    "# Ø§Ø®ØªØ¨Ø§Ø± Ø£ÙƒØ¨Ø± Ù†Øµ Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ | Large English Text Example\n",
    "EXAMPLE_TEXT = '''\n",
    "Thomas Gradgrind, sir.  A man of realities.  A man of facts and calculations.  \n",
    "A man who proceeds upon the principle that two and two are four...\n",
    "'''\n",
    "print(word_tokenize(EXAMPLE_TEXT))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a5464f",
   "metadata": {},
   "source": [
    "> ğŸ‡¸ğŸ‡¦ Ù†Ù„Ø§Ø­Ø¸ Ø£Ù† `word_tokenize()` ÙŠÙØµÙ„ Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ… ÙˆØ§Ù„Ø¬Ù…Ù„ Ø¨Ø´ÙƒÙ„ Ù…Ø«Ø§Ù„ÙŠ.\n",
    "> ğŸ‡¬ğŸ‡§ The tokenizer accurately separates punctuation and words, unlike `split()`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f8da7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "------------------------\n",
      "[]\n",
      "====================================================\n",
      "['Thomas', 'Gradgrind,', 'sir.', 'A', 'man', 'of', 'realities.', 'A', 'man', 'of']\n",
      "------------------------\n",
      "['Thomas', 'Gradgrind', ',', 'sir', '.', 'A', 'man', 'of', 'realities', '.']\n",
      "====================================================\n",
      "['A', 'man', 'who', 'proceeds', 'upon', 'the', 'principle', 'that', 'two', 'and']\n",
      "------------------------\n",
      "['A', 'man', 'who', 'proceeds', 'upon', 'the', 'principle', 'that', 'two', 'and']\n",
      "====================================================\n",
      "[]\n",
      "------------------------\n",
      "[]\n",
      "====================================================\n"
     ]
    }
   ],
   "source": [
    "# Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† split() Ùˆ word_tokenize()\n",
    "for line in EXAMPLE_TEXT.split('\\n')[:20]:\n",
    "    print(line.split()[:10])\n",
    "    print('------------------------')\n",
    "    print(word_tokenize(line)[:10])\n",
    "    print('====================================================')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef268d7",
   "metadata": {},
   "source": [
    "> ğŸ‡¸ğŸ‡¦ Ø§Ù„ÙØ±Ù‚ ÙˆØ§Ø¶Ø­: `split()` ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„ÙØ±Ø§Øº ÙÙ‚Ø·ØŒ\n",
    "> Ø¨ÙŠÙ†Ù…Ø§ `word_tokenize()` ÙŠØ±Ø§Ø¹ÙŠ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù„ØºÙˆÙŠØ©.\n",
    "> ğŸ‡¬ğŸ‡§ `split()` breaks only by spaces, while `word_tokenize()` respects linguistic structure.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "620d1e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÙŠØ¹Ø¯\n",
      "xxx\n",
      "True\n",
      "False\n",
      "---------------\n",
      "Ø§Ù„Ø°ÙƒØ§Ø¡\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "---------------\n",
      "Ø§Ù„Ø¥ØµØ·Ù†Ø§Ø¹ÙŠ\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "---------------\n",
      "Ù…Ù†\n",
      "xx\n",
      "True\n",
      "False\n",
      "---------------\n",
      "Ø§Ù„Ø¹Ù„ÙˆÙ…\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "---------------\n",
      "Ø§Ù„ØªÙŠ\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "---------------\n",
      "ÙŠØªØ³Ø§Ø±Ø¹\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "---------------\n",
      "Ø§Ù„ØªØ·ÙˆØ±\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "---------------\n",
      "ÙÙŠÙ‡Ø§\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "---------------\n",
      "Ø¨Ø´ÙƒÙ„\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "---------------\n",
      "Ù„Ø§ÙØª\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "---------------\n",
      "Ù…Ù†Ø°\n",
      "xxx\n",
      "True\n",
      "False\n",
      "---------------\n",
      "Ø¹Ø§Ù…\n",
      "xxx\n",
      "True\n",
      "False\n",
      "---------------\n",
      "2005\n",
      "dddd\n",
      "False\n",
      "False\n",
      "---------------\n",
      "Ùˆ\n",
      "x\n",
      "True\n",
      "False\n",
      "---------------\n",
      "Ù„Ù…Ø¯Ø©\n",
      "xxxx\n",
      "True\n",
      "False\n",
      "---------------\n",
      "15\n",
      "dd\n",
      "False\n",
      "False\n",
      "---------------\n",
      "Ø³Ù†Ø©\n",
      "xxx\n",
      "True\n",
      "False\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# Ø£Ù…Ø«Ù„Ø© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… spaCy Ùˆ NLTK | Arabic Examples\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = nlp('ÙŠØ¹Ø¯ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø¥ØµØ·Ù†Ø§Ø¹ÙŠ Ù…Ù† Ø§Ù„Ø¹Ù„ÙˆÙ… Ø§Ù„ØªÙŠ ÙŠØªØ³Ø§Ø±Ø¹ Ø§Ù„ØªØ·ÙˆØ± ÙÙŠÙ‡Ø§ Ø¨Ø´ÙƒÙ„ Ù„Ø§ÙØª Ù…Ù†Ø° Ø¹Ø§Ù… 2005 Ùˆ Ù„Ù…Ø¯Ø© 15 Ø³Ù†Ø©')\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text)\n",
    "    print(token.shape_)\n",
    "    print(token.is_alpha)\n",
    "    print(token.is_stop)\n",
    "    print('---------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f884e8",
   "metadata": {},
   "source": [
    "> ğŸ‡¸ğŸ‡¦ spaCy Ù„Ø§ ØªØ¯Ø¹Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø±Ø³Ù…ÙŠÙ‹Ø§ ÙÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ `en_core_web_sm`ØŒ\n",
    "> Ù„Ø°Ø§ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ù‚Ø¯ Ù„Ø§ ØªÙƒÙˆÙ† Ø¯Ù‚ÙŠÙ‚Ø© Ø¬Ø¯Ù‹Ø§ØŒ ÙˆÙŠÙØ¶Ù‘Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙƒØªØ¨Ø© **CamelTools** Ø£Ùˆ **Stanza** Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ spaCyâ€™s default English model doesnâ€™t support Arabic; use `camel_tools` or `stanza` for better results.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2482107e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ØªØ·Ø¨ÙŠÙ‚ Ø¹Ø±Ø¨ÙŠ Ø¹Ù„Ù‰ Ù†Øµ Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠ | Arabic Example â€“ Al-Khwarizmi\n",
    "doc2 = nlp('''\n",
    "Ø£Ø¨Ùˆ Ø¹Ø¨Ø¯ Ø§Ù„Ù„Ù‡ Ù…Ø­Ù…Ø¯ Ø¨Ù† Ù…ÙˆØ³Ù‰ Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠ Ø¹Ø§Ù„Ù… Ø±ÙŠØ§Ø¶ÙŠØ§Øª ÙˆÙÙ„Ùƒ ÙˆØ¬ØºØ±Ø§ÙÙŠØ§ Ù…Ø³Ù„Ù…...\n",
    "''')\n",
    "life_quote = doc2[15:33]\n",
    "print(life_quote)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418b9939",
   "metadata": {},
   "source": [
    "> ğŸ‡¸ğŸ‡¦ ÙŠÙ…ÙƒÙ† ØªØ·Ø¨ÙŠÙ‚ Ù†ÙØ³ ÙÙƒØ±Ø© Ø§Ù„ØªÙ‚Ø·ÙŠØ¹ Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø¬Ø²Ø§Ø¡ Ù…Ø­Ø¯Ø¯Ø© Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ The same slicing approach works with Arabic text as well.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f72ac214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÙŠÙ…ÙƒÙ†Ùƒ\n",
      "Ù…Ø±Ø§Ø³Ù„ØªÙ†Ø§\n",
      "Ø¹Ù„Ù‰\n",
      "Ø§Ù„Ø¨Ø±ÙŠØ¯\n",
      "Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ\n",
      "info@hp.com\n",
      "Ø£Ùˆ\n",
      "Ø²ÙŠØ§Ø±Ø©\n",
      "Ù…ÙˆÙ‚Ø¹Ù†Ø§\n",
      "www.hp.com\n"
     ]
    }
   ],
   "source": [
    "# Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø¨Ø±ÙŠØ¯ ÙˆØ§Ù„Ù…ÙˆØ§Ù‚Ø¹ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©\n",
    "doc4 = nlp(u\"ÙŠÙ…ÙƒÙ†Ùƒ Ù…Ø±Ø§Ø³Ù„ØªÙ†Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ info@hp.com Ø£Ùˆ Ø²ÙŠØ§Ø±Ø© Ù…ÙˆÙ‚Ø¹Ù†Ø§ www.hp.com\")\n",
    "for token in doc4:\n",
    "    print(token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06b576a",
   "metadata": {},
   "source": [
    "> ğŸ‡¸ğŸ‡¦ Ù„Ø§Ø­Ø¸ Ø£Ù† spaCy ØªØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø±ÙŠØ¯ ÙˆØ§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ Ø­ØªÙ‰ ÙÙŠ Ù†Øµ Ø¹Ø±Ø¨ÙŠ.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ spaCy still detects emails and URLs correctly, even in Arabic sentences.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61d8a744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ø£Ø¨Ùˆ', 'Ø¹Ø¨Ø¯', 'Ø§Ù„Ù„Ù‡', 'Ù…Ø­Ù…Ø¯', 'Ø¨Ù†', 'Ù…ÙˆØ³Ù‰', 'Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠ', 'Ø¹Ø§Ù„Ù…', 'Ø±ÙŠØ§Ø¶ÙŠØ§Øª', 'ÙˆÙÙ„Ùƒ', '...']\n"
     ]
    }
   ],
   "source": [
    "# Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… NLTK\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "EXAMPLE_TEXT = \"\"\"\n",
    "Ø£Ø¨Ùˆ Ø¹Ø¨Ø¯ Ø§Ù„Ù„Ù‡ Ù…Ø­Ù…Ø¯ Ø¨Ù† Ù…ÙˆØ³Ù‰ Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠ Ø¹Ø§Ù„Ù… Ø±ÙŠØ§Ø¶ÙŠØ§Øª ÙˆÙÙ„Ùƒ...\n",
    "\"\"\"\n",
    "print(word_tokenize(EXAMPLE_TEXT))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75527e3d",
   "metadata": {},
   "source": [
    "> ğŸ‡¸ğŸ‡¦ NLTK ØªØªØ¹Ø§Ù…Ù„ Ø¬ÙŠØ¯Ù‹Ø§ Ù…Ø¹ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©ØŒ ÙˆØªÙØµÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø¯ÙˆÙ† Ø§Ù„Ø¥Ø®Ù„Ø§Ù„ Ø¨Ø§Ù„Ù…Ø¹Ù†Ù‰.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ NLTK can tokenize Arabic text reasonably well, though without deep linguistic understanding.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edf520f",
   "metadata": {},
   "source": [
    "## ğŸª„ Ø§Ù„Ø®Ù„Ø§ØµØ© | Summary\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù‚Ø³Ù… ØªØ¹Ù„Ù‘Ù…Ù†Ø§:\n",
    ">\n",
    "> * Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙƒØªØ¨Ø© **spaCy** Ù„ØªØ¬Ø²Ø¦Ø© Ø§Ù„Ù†Øµ ÙˆØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª.\n",
    "> * Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹ Ù…ÙƒØªØ¨Ø© **NLTK** ÙÙŠ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù†ØµÙˆØµ.\n",
    "> * Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙØ±ÙˆÙ‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„Ù„ØºØ§ØªØŒ Ø®ØµÙˆØµÙ‹Ø§ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ In this part, we learned:\n",
    ">\n",
    "> * How to tokenize and analyze text using **spaCy**.\n",
    "> * How to compare results with **NLTK**.\n",
    "> * The limitations and differences across languages.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbbb11f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# ğŸ§© Ø§Ù„Ù‚Ø³Ù… 2: ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¬Ù…Ù„ (Sentence Segmentation)\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ **Ù…Ù‚Ø¯Ù…Ø© Ø§Ù„Ù‚Ø³Ù…:**\n",
    "> Ù‡Ø°Ø§ Ø§Ù„Ù‚Ø³Ù… Ù‡Ùˆ Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø«Ø§Ù†ÙŠ Ù…Ù† \"Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù€ NLP\" ÙÙŠ Ø§Ù„ÙƒÙˆØ±Ø³ (Ø¨Ø¹Ø¯ Ø§Ù„Ù€ Tokenization).\n",
    "> Ø³Ù†ØªØ¹Ù„Ù‘Ù… ÙÙŠÙ‡ ÙƒÙŠÙ ÙŠØªÙ… **ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†ØµÙˆØµ Ø¥Ù„Ù‰ Ø¬Ù…Ù„ Ù…Ø³ØªÙ‚Ù„Ø©** Ø¨Ø·Ø±ÙŠÙ‚Ø© Ø°ÙƒÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø¯ÙˆØ§Øª Ù…Ø«Ù„ **spaCy** Ùˆ**NLTK**.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ **Section Introduction:**\n",
    "> This is the second part of the â€œNLP Toolsâ€ section in the course.\n",
    "> Here weâ€™ll learn how to **split text into sentences** intelligently using **spaCy** and **NLTK**.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  Ù…Ø§ Ù‡ÙŠ Ø¹Ù…Ù„ÙŠØ© ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¬Ù…Ù„ØŸ | What is Sentence Segmentation?\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ Ø¹Ù…Ù„ÙŠØ© **Segmentation** Ø£Ùˆ **ØªØ¬Ø²Ø¦Ø© Ø§Ù„Ø¬Ù…Ù„** Ù‡ÙŠ Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªÙŠ ØªØ³Ø¨Ù‚ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø­ÙˆÙŠØŒ\n",
    "> Ø­ÙŠØ« ÙŠØªÙ… ÙØµÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ø·ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø¬Ù…Ù„ Ù‚ØµÙŠØ±Ø© ÙŠÙ…ÙƒÙ† ØªØ­Ù„ÙŠÙ„Ù‡Ø§ ÙˆÙÙ‡Ù… Ù…Ø¹Ù†Ø§Ù‡Ø§.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ **Sentence segmentation** (or sentence boundary detection) splits a long text into shorter sentences that can be analyzed individually.\n",
    "\n",
    "---\n",
    "\n",
    "## âš™ï¸ ÙƒÙŠÙ ØªØ¹Ù…Ù„ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªÙ‚Ø³ÙŠÙ…ØŸ | How Does It Work?\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ ØºØ§Ù„Ø¨Ù‹Ø§ Ù…Ø§ ØªÙÙ‚Ø³Ù… Ø§Ù„Ø¬Ù…Ù„ Ø§Ø¹ØªÙ…Ø§Ø¯Ù‹Ø§ Ø¹Ù„Ù‰ Ø¹Ù„Ø§Ù…Ø§Øª ÙˆØ§Ø¶Ø­Ø© Ù…Ø«Ù„:\n",
    "> Ø§Ù„Ù†Ù‚Ø·Ø© (.)ØŒ Ø£Ùˆ Ø¹Ù„Ø§Ù…Ø© Ø§Ù„Ø§Ø³ØªÙÙ‡Ø§Ù… (?)ØŒ Ø£Ùˆ Ø§Ù„ØªØ¹Ø¬Ø¨ (!).\n",
    ">\n",
    "> Ù„ÙƒÙ† Ø£Ø­ÙŠØ§Ù†Ù‹Ø§ **Ù„ÙŠØ³Øª ÙƒÙ„ Ø§Ù„Ù†Ù‚Ø§Ø· Ù†Ù‡Ø§ÙŠØ© Ø¬Ù…Ù„Ø©** â€”\n",
    "> ÙÙ…Ø«Ù„Ù‹Ø§ ÙÙŠ â€œDr. Smithâ€ Ø§Ù„Ù†Ù‚Ø·Ø© Ù„Ø§ ØªØ¹Ù†ÙŠ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø¬Ù…Ù„Ø©.\n",
    "> Ù„Ø°Ù„Ùƒ ØªÙØ³ØªØ®Ø¯Ù… Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ø°ÙƒÙŠØ© Ø£Ùˆ Ø­ØªÙ‰ **Ù†Ù…Ø§Ø°Ø¬ ØªØ¹Ù„Ù… Ø¢Ù„ÙŠ (ML)** Ù„ØªØ­Ø¯ÙŠØ¯ Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¹Ù„Ø§Ù…Ø© **Ù†Ù‡Ø§ÙŠØ© Ø¬Ù…Ù„Ø© (EOS)** Ø£Ù… Ù„Ø§.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ Sentences are usually divided by clear punctuation marks like `.` `?` `!`.\n",
    "> But not all dots mark the end of a sentence â€”\n",
    "> for example, â€œDr. Smithâ€ is **not** an end.\n",
    "> ML-based models or linguistic rules can be used to detect true **End of Sentence (EOS)** boundaries.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c014593d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is another sentence.\n",
      "This is the last sentence.\n"
     ]
    }
   ],
   "source": [
    "# Ø§Ù„ØªØ¬Ø²Ø¦Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… spaCy | Sentence Segmentation with spaCy\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc1 = nlp(u'This is the first sentence. This is another sentence. This is the last sentence.')\n",
    "\n",
    "for sent in doc1.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca2bfb9",
   "metadata": {},
   "source": [
    "## ğŸ§  ÙØ­Øµ Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„ÙØ±Ø¯ÙŠØ© | Inspecting Sentence Boundaries\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ ÙŠÙ…ÙƒÙ†Ù†Ø§ Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ÙƒÙ„Ù…Ø© Ù…Ø¹ÙŠÙ†Ø© Ù‡ÙŠ Ø¨Ø¯Ø§ÙŠØ© Ø¬Ù…Ù„Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… `is_sent_start`.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ We can check if a specific token marks the start of a sentence using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c91a0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This True\n"
     ]
    }
   ],
   "source": [
    "print(doc1[6], doc1[6].is_sent_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76880a6",
   "metadata": {},
   "source": [
    "> âš ï¸ **ØªÙ†Ø¨ÙŠÙ‡:**\n",
    "> `doc.sents` Ù„ÙŠØ³Øª Ù‚Ø§Ø¦Ù…Ø© (list) Ø¨Ù„ **Ù…ÙˆÙ„Ù‘Ø¯ (generator)**ØŒ\n",
    "> Ù„Ø°Ø§ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„Ù‰ Ø¹Ù†Ø§ØµØ±Ù‡ Ù…Ø¨Ø§Ø´Ø±Ø© Ø¨Ù‡Ø°Ø§ Ø§Ù„Ø´ÙƒÙ„:\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e36a652",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'generator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdoc1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msents\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)  \u001b[38;5;66;03m# âŒ Error\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(doc1.sents[0])  # âŒ Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a3ce05",
   "metadata": {},
   "source": [
    "> Ø¨Ù„ ÙŠØ¬Ø¨ ØªØ­ÙˆÙŠÙ„Ù‡ Ø¥Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø©:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ee7c818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This is the first sentence."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(doc1.sents)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23e25be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[This is the first sentence., This is another sentence., This is the last sentence.]\n",
      "6 11\n"
     ]
    }
   ],
   "source": [
    "# Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¬Ù…Ù„ ÙˆØªØ­Ù„ÙŠÙ„Ù‡Ø§ | Extracting and Analyzing Sentences\n",
    "doc_sents = [sent for sent in doc1.sents]\n",
    "print(doc_sents)\n",
    "print(doc_sents[1].start, doc_sents[1].end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa0f6cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True  This\n",
      "False  is\n",
      "False  a\n",
      "False  sentence\n",
      "False  .\n",
      "True  that\n",
      "False  is\n",
      "False  a\n",
      "False  sentence\n",
      "False  .\n",
      "True  here\n",
      "False  is\n",
      "False  a\n",
      "False  sentence\n",
      "False  .\n"
     ]
    }
   ],
   "source": [
    "# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¨Ø¯Ø§ÙŠØ§Øª Ø§Ù„Ø¬Ù…Ù„ | Checking Sentence Start Flags\n",
    "doc2 = nlp(u'This is a sentence. that is a sentence. here is a sentence.')\n",
    "\n",
    "for token in doc2:\n",
    "    print(token.is_sent_start, ' '+token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f602966d",
   "metadata": {},
   "source": [
    "## ğŸ¯ ØªØ¹Ø¯ÙŠÙ„ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªÙ‚Ø³ÙŠÙ… | Custom Sentence Boundaries\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ Ø£Ø­ÙŠØ§Ù†Ù‹Ø§ Ù†Ø­ØªØ§Ø¬ Ù„ØªØºÙŠÙŠØ± Ø·Ø±ÙŠÙ‚Ø© spaCy ÙÙŠ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¬Ù…Ù„.\n",
    "> Ù…Ø«Ù„Ù‹Ø§ ÙÙŠ Ø§Ù„Ù…Ø«Ø§Ù„ Ø§Ù„ØªØ§Ù„ÙŠØŒ Ù†Ø±ÙŠØ¯ Ø£Ù† ÙŠÙØµÙ„ Ø§Ù„Ø¬Ù…Ù„ Ø¹Ù†Ø¯ Ø§Ù„Ù€ `;` (Ø§Ù„Ø³ÙŠÙ…ÙŠ ÙƒÙˆÙ„Ù†).\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ Sometimes you may want to modify spaCyâ€™s sentence segmentation rules â€”\n",
    "> for example, to split sentences at `;`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28374b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'custom_boundaries',\n",
       " 'parser',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'ner']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.language import Language\n",
    "\n",
    "@Language.component(\"custom_boundaries\")\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == ';':\n",
    "            doc[token.i+1].is_sent_start = True\n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe(\"custom_boundaries\", before='parser')\n",
    "nlp.pipe_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0d8f648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Management is doing things right;\n",
      "leadership is doing the right things.\"\n",
      "-Peter Drucker\n"
     ]
    }
   ],
   "source": [
    "doc4 = nlp(u'\"Management is doing things right; leadership is doing the right things.\" -Peter Drucker')\n",
    "for sent in doc4.sents:\n",
    "    print(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0bb5bbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hello Mr. Smith, how are you doing today?\n",
      "----------------------\n",
      "The weather is great, \n",
      "and Python is awesome.\n",
      "----------------------\n",
      "The sky is pinkish-blue.\n",
      "----------------------\n",
      "You shouldn't eat cardboard.\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "# ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¬Ù…Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… NLTK | Sentence Tokenization with NLTK\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "EXAMPLE_TEXT = \"\"\"\n",
    "Hello Mr. Smith, how are you doing today? The weather is great, \n",
    "and Python is awesome. The sky is pinkish-blue. You shouldn't eat cardboard.\n",
    "\"\"\"\n",
    "\n",
    "for s in sent_tokenize(EXAMPLE_TEXT):\n",
    "    print(s)\n",
    "    print('----------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4485e40e",
   "metadata": {},
   "source": [
    "> ğŸ‡¸ğŸ‡¦ Ù„Ø§Ø­Ø¸ Ø£Ù† NLTK Ø£ÙŠØ¶Ù‹Ø§ ØªØªØ¹Ø§Ù…Ù„ Ø¨Ø°ÙƒØ§Ø¡ Ù…Ø¹ Ø§Ù„Ù†Ù‚Ø§Ø· Ø¯Ø§Ø®Ù„ Ø§Ù„Ø§Ø®ØªØµØ§Ø±Ø§Øª Ù…Ø«Ù„ \"Mr.\"\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ Notice how NLTK correctly handles abbreviations like â€œMr.â€ without breaking the sentence.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8df9f34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nHello Mr. Smith, how are you doing today?',\n",
       " 'The weather is great, \\nand Python is awesome.',\n",
       " 'The sky is pinkish-blue.',\n",
       " \"You shouldn't eat cardboard.\"]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ø§Ø³ØªØ®Ø¯Ø§Ù… PunktSentenceTokenizer Ø§Ù„Ù…Ø®ØµÙ‘Øµ | Custom Punkt Tokenizer\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(EXAMPLE_TEXT)\n",
    "tokenized = custom_sent_tokenizer.tokenize(EXAMPLE_TEXT)\n",
    "tokenized[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2ec037",
   "metadata": {},
   "source": [
    "## ğŸ—£ï¸ ØªØ·Ø¨ÙŠÙ‚ Ø¹Ù„Ù‰ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© | Arabic Sentence Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b1e1b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ù‡Ø°Ù‡ Ù‡ÙŠ Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠ ., Ù‡Ø°Ù‡ Ù‡ÙŠ Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ© , ÙˆØ§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„Ø«Ø§Ù„Ø«Ø©\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp('Ù‡Ø°Ù‡ Ù‡ÙŠ Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠ ., Ù‡Ø°Ù‡ Ù‡ÙŠ Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ© , ÙˆØ§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„Ø«Ø§Ù„Ø«Ø©')\n",
    "\n",
    "for sent in doc1.sents:\n",
    "    print(sent)\n",
    "    print('-------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b5c910",
   "metadata": {},
   "source": [
    "> ğŸ‡¸ğŸ‡¦ ÙÙŠ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©ØŒ Ù„Ø§ ØªØ²Ø§Ù„ Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªÙ‚Ø³ÙŠÙ… ØªÙˆØ§Ø¬Ù‡ Ø¨Ø¹Ø¶ Ø§Ù„ØµØ¹ÙˆØ¨Ø§ØªØŒ\n",
    "> Ø®Ø§ØµØ© Ø¨Ø³Ø¨Ø¨ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¹Ù„Ø§Ù…Ø§Øª ØªØ±Ù‚ÙŠÙ… ØºÙŠØ± Ù…Ù†ØªØ¸Ù…Ø© Ø£Ùˆ Ø§Ù„ØªØ¨Ø§Ø³ Ø§Ù„Ø³ÙŠØ§Ù‚.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ In Arabic, sentence segmentation is still challenging due to punctuation inconsistencies and contextual ambiguity.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a6612f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ø£Ø¨Ùˆ Ø¹Ø¨Ø¯ Ø§Ù„Ù„Ù‡ Ù…Ø­Ù…Ø¯ Ø¨Ù† Ù…ÙˆØ³Ù‰ Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠ Ø¹Ø§Ù„Ù… Ø±ÙŠØ§Ø¶ÙŠØ§Øª ÙˆÙÙ„Ùƒ\n",
      "ÙˆØ¬ØºØ±Ø§ÙÙŠØ§ Ù…Ø³Ù„Ù….\n",
      "----------------------\n",
      "ÙŠÙƒÙ†Ù‰ Ø¨Ø§Ø³Ù… Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠ ÙˆØ£Ø¨ÙŠ Ø¬Ø¹ÙØ±.\n",
      "----------------------\n",
      "Ù‚ÙŠÙ„ Ø£Ù†Ù‡ ÙˆÙ„Ø¯ Ø­ÙˆØ§Ù„ÙŠ 164Ù‡Ù€ 781Ù… (ÙˆÙ‡Ùˆ ØºÙŠØ± Ù…Ø¤ÙƒØ¯)...\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "# ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¬Ù…Ù„ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… NLTK | Sentence segmentation for Arabic using NLTK\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "EXAMPLE_TEXT = '''\n",
    "Ø£Ø¨Ùˆ Ø¹Ø¨Ø¯ Ø§Ù„Ù„Ù‡ Ù…Ø­Ù…Ø¯ Ø¨Ù† Ù…ÙˆØ³Ù‰ Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠ Ø¹Ø§Ù„Ù… Ø±ÙŠØ§Ø¶ÙŠØ§Øª ÙˆÙÙ„Ùƒ\n",
    "ÙˆØ¬ØºØ±Ø§ÙÙŠØ§ Ù…Ø³Ù„Ù…. ÙŠÙƒÙ†Ù‰ Ø¨Ø§Ø³Ù… Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠ ÙˆØ£Ø¨ÙŠ Ø¬Ø¹ÙØ±. Ù‚ÙŠÙ„ Ø£Ù†Ù‡ ÙˆÙ„Ø¯ Ø­ÙˆØ§Ù„ÙŠ 164Ù‡Ù€ 781Ù… (ÙˆÙ‡Ùˆ ØºÙŠØ± Ù…Ø¤ÙƒØ¯)...\n",
    "'''\n",
    "\n",
    "for s in sent_tokenize(EXAMPLE_TEXT):\n",
    "    print(s)\n",
    "    print('----------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5438c1f6",
   "metadata": {},
   "source": [
    "## ğŸ§  Ù…Ù„Ø§Ø­Ø¸Ø© ØªØ­Ù„ÙŠÙ„ÙŠØ© | Analytical Note\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ ÙÙŠ Ø§Ù„Ù„ØºØ§Øª ÙƒØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©ØŒ ØªØ¹ØªÙ…Ø¯ Ø£Ø¯ÙˆØ§Øª Ù…Ø«Ù„ spaCy Ø¹Ù„Ù‰ Ù†Ù…Ø§Ø°Ø¬ Ù„ØºÙˆÙŠØ© Ø¬Ø§Ù‡Ø²Ø© Ù„ØªØ­Ø¯ÙŠØ¯ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø¬Ù…Ù„Ø©.\n",
    "> Ø£Ù…Ø§ ÙÙŠ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©ØŒ ÙØºØ§Ù„Ø¨Ù‹Ø§ ØªØ­ØªØ§Ø¬ Ù„ØªØ®ØµÙŠØµ Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø¯ÙˆØ§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù„ØªÙ†Ø¬Ø­ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªÙ‚Ø³ÙŠÙ… Ø¨Ø¯Ù‚Ø©.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ In English, spaCy relies on pre-trained models to detect sentence boundaries.\n",
    "> In Arabic, additional customization or specialized models may be required for accurate results.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fd0ddc",
   "metadata": {},
   "source": [
    "## ğŸ·ï¸ **ØªØ­Ù„ÙŠÙ„ Ø£Ø¬Ø²Ø§Ø¡ Ø§Ù„ÙƒÙ„Ø§Ù… (Part of Speech Tagging - POS)**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  Ù…Ù‚Ø¯Ù…Ø© | Introduction\n",
    "\n",
    "ğŸ‡¸ğŸ‡¦\n",
    "Ø§Ù„Ù€ **POS Tagging** Ù‡Ùˆ ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ ÙƒÙ„ ÙƒÙ„Ù…Ø© ÙÙŠ Ø§Ù„Ø¬Ù…Ù„Ø© Ù…Ù† Ø§Ù„Ù†Ø§Ø­ÙŠØ© Ø§Ù„Ù†Ø­ÙˆÙŠØ© (Ø§Ø³Ù… â€“ ÙØ¹Ù„ â€“ ØµÙØ© â€“ Ø¸Ø±Ù...).\n",
    "ÙˆÙŠØªÙ… Ù‡Ø°Ø§ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ø¹ØªÙ…Ø§Ø¯Ù‹Ø§ Ø¹Ù„Ù‰ **Ø§Ù„Ø³ÙŠØ§Ù‚** Ø§Ù„Ø°ÙŠ ØªØ¸Ù‡Ø± ÙÙŠÙ‡ Ø§Ù„ÙƒÙ„Ù…Ø©ØŒ ÙˆÙ„ÙŠØ³ ÙÙ‚Ø· Ø¹Ù„Ù‰ Ø´ÙƒÙ„Ù‡Ø§.\n",
    "ÙÙ…Ø«Ù„Ø§Ù‹ ÙƒÙ„Ù…Ø© **â€œplayâ€** ÙŠÙ…ÙƒÙ† Ø£Ù† ØªÙƒÙˆÙ† **Ø§Ø³Ù…Ù‹Ø§** (a play) Ø£Ùˆ **ÙØ¹Ù„Ù‹Ø§** (to play) Ø­Ø³Ø¨ Ù…ÙˆÙ‚Ø¹Ù‡Ø§ ÙÙŠ Ø§Ù„Ø¬Ù…Ù„Ø©.\n",
    "\n",
    "ğŸ‡¬ğŸ‡§\n",
    "**POS Tagging** means classifying each word in a sentence according to its grammatical role â€”\n",
    "such as **noun**, **verb**, **adjective**, or **adverb**.\n",
    "It depends on the **context**, not just the word form.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§± Ø£Ù‚Ø³Ø§Ù… Ø§Ù„ÙƒÙ„Ù…Ø§Øª | Word Classes\n",
    "\n",
    "| ğŸ‡¸ğŸ‡¦ Ø§Ù„Ù†ÙˆØ¹ (Type)                                                                           | ğŸ‡¸ğŸ‡¦ Ù†ÙˆØ¹ Ø§Ù„ÙØ¦Ø© (Category Type) | ğŸ‡¬ğŸ‡§ Example (Ù…Ø«Ø§Ù„)  |\n",
    "| ------------------------------------------------------------------------------------------- | ------------------------------ | -------------------- |\n",
    "| Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ØŒ Ø§Ù„Ø£ÙØ¹Ø§Ù„ØŒ Ø§Ù„ØµÙØ§ØªØŒ Ø§Ù„Ø£Ø­ÙˆØ§Ù„ â€” Nouns, Verbs, Adjectives, Adverbs                       | ÙØ¦Ø§Øª Ù…ÙØªÙˆØ­Ø© (Open Classes)     | grow, cat, beautiful |\n",
    "| Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªØ¹Ø±ÙŠÙØŒ Ø§Ù„Ø¶Ù…Ø§Ø¦Ø±ØŒ Ø­Ø±ÙˆÙ Ø§Ù„Ø¬Ø±ØŒ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· â€” Articles, Pronouns, Prepositions, Conjunctions | ÙØ¦Ø§Øª Ù…ØºÙ„Ù‚Ø© (Closed Classes)    | the, he, in, and     |\n",
    "\n",
    "---\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù…ÙØªÙˆØ­Ø© ØªØªØºÙŠØ± ÙˆØªØ²Ø¯Ø§Ø¯ Ù…Ø¹ Ø§Ù„ÙˆÙ‚ØªØŒ Ø¨ÙŠÙ†Ù…Ø§ Ø§Ù„Ù…ØºÙ„Ù‚Ø© Ø«Ø§Ø¨ØªØ© ØªÙ‚Ø±ÙŠØ¨Ù‹Ø§.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ Open classes expand over time, while closed ones remain mostly fixed.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ’¬ Ù…Ù„Ø§Ø­Ø¸Ø© ØªØ­Ù„ÙŠÙ„ÙŠØ© | Analytical Note\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„ÙˆØ§Ø­Ø¯Ø© Ù‚Ø¯ ØªÙ†ØªÙ…ÙŠ Ù„Ø£ÙƒØ«Ø± Ù…Ù† Ù†ÙˆØ¹ Ù†Ø­ÙˆÙŠ Ø­Ø³Ø¨ Ù…ÙˆÙ‚Ø¹Ù‡Ø§ ÙÙŠ Ø§Ù„Ø¬Ù…Ù„Ø©.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ A single word can belong to multiple parts of speech depending on its sentence position.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c938e2a",
   "metadata": {},
   "source": [
    "## âš™ï¸ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1ac6c44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words is   :  The\n",
      "POS is   :  90 === DET === determiner\n",
      "Dep is   :  415 === det === determiner\n",
      "Tag is   :  15267657372422890137 === DT === determiner\n",
      "-----------------------\n",
      "Words is   :  son\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  430 === nsubjpass === nominal subject (passive)\n",
      "Tag is   :  15308085513773655218 === NN === noun, singular or mass\n",
      "-----------------------\n",
      "Words is   :  of\n",
      "POS is   :  85 === ADP === adposition\n",
      "Dep is   :  443 === prep === prepositional modifier\n",
      "Tag is   :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "-----------------------\n",
      "Words is   :  a\n",
      "POS is   :  90 === DET === determiner\n",
      "Dep is   :  415 === det === determiner\n",
      "Tag is   :  15267657372422890137 === DT === determiner\n",
      "-----------------------\n",
      "Words is   :  salesman\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  439 === pobj === object of preposition\n",
      "Tag is   :  15308085513773655218 === NN === noun, singular or mass\n",
      "-----------------------\n",
      "Words is   :  who\n",
      "POS is   :  95 === PRON === pronoun\n",
      "Dep is   :  429 === nsubj === nominal subject\n",
      "Tag is   :  4808651922106831370 === WP === wh-pronoun, personal\n",
      "-----------------------\n",
      "Words is   :  later\n",
      "POS is   :  86 === ADV === adverb\n",
      "Dep is   :  400 === advmod === adverbial modifier\n",
      "Tag is   :  164681854541413346 === RB === adverb\n",
      "-----------------------\n",
      "Words is   :  operated\n",
      "POS is   :  100 === VERB === verb\n",
      "Dep is   :  447 === relcl === relative clause modifier\n",
      "Tag is   :  17109001835818727656 === VBD === verb, past tense\n",
      "-----------------------\n",
      "Words is   :  an\n",
      "POS is   :  90 === DET === determiner\n",
      "Dep is   :  415 === det === determiner\n",
      "Tag is   :  15267657372422890137 === DT === determiner\n",
      "-----------------------\n",
      "Words is   :  electrochemical\n",
      "POS is   :  84 === ADJ === adjective\n",
      "Dep is   :  402 === amod === adjectival modifier\n",
      "Tag is   :  10554686591937588953 === JJ === adjective (English), other noun-modifier (Chinese)\n",
      "-----------------------\n",
      "Words is   :  factory\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  416 === dobj === direct object\n",
      "Tag is   :  15308085513773655218 === NN === noun, singular or mass\n",
      "-----------------------\n",
      "Words is   :  ,\n",
      "POS is   :  97 === PUNCT === punctuation\n",
      "Dep is   :  445 === punct === punctuation\n",
      "Tag is   :  2593208677638477497 === , === punctuation mark, comma\n",
      "-----------------------\n",
      "Words is   :  \n",
      "\n",
      "POS is   :  103 === SPACE === space\n",
      "Dep is   :  414 === dep === unclassified dependent\n",
      "Tag is   :  6893682062797376370 === _SP === whitespace\n",
      "-----------------------\n",
      "Words is   :  instein\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  403 === appos === appositional modifier\n",
      "Tag is   :  15308085513773655218 === NN === noun, singular or mass\n",
      "-----------------------\n",
      "Words is   :  was\n",
      "POS is   :  87 === AUX === auxiliary\n",
      "Dep is   :  406 === auxpass === auxiliary (passive)\n",
      "Tag is   :  17109001835818727656 === VBD === verb, past tense\n",
      "-----------------------\n",
      "Words is   :  born\n",
      "POS is   :  100 === VERB === verb\n",
      "Dep is   :  8206900633647566924 === ROOT === root\n",
      "Tag is   :  3822385049556375858 === VBN === verb, past participle\n",
      "-----------------------\n",
      "Words is   :  in\n",
      "POS is   :  85 === ADP === adposition\n",
      "Dep is   :  443 === prep === prepositional modifier\n",
      "Tag is   :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "-----------------------\n",
      "Words is   :  the\n",
      "POS is   :  90 === DET === determiner\n",
      "Dep is   :  415 === det === determiner\n",
      "Tag is   :  15267657372422890137 === DT === determiner\n",
      "-----------------------\n",
      "Words is   :  German\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Empire\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  439 === pobj === object of preposition\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ,\n",
      "POS is   :  97 === PUNCT === punctuation\n",
      "Dep is   :  445 === punct === punctuation\n",
      "Tag is   :  2593208677638477497 === , === punctuation mark, comma\n",
      "-----------------------\n",
      "Words is   :  but\n",
      "POS is   :  89 === CCONJ === coordinating conjunction\n",
      "Dep is   :  407 === cc === coordinating conjunction\n",
      "Tag is   :  17571114184892886314 === CC === conjunction, coordinating\n",
      "-----------------------\n",
      "Words is   :  moved\n",
      "POS is   :  100 === VERB === verb\n",
      "Dep is   :  410 === conj === conjunct\n",
      "Tag is   :  17109001835818727656 === VBD === verb, past tense\n",
      "-----------------------\n",
      "Words is   :  to\n",
      "POS is   :  85 === ADP === adposition\n",
      "Dep is   :  443 === prep === prepositional modifier\n",
      "Tag is   :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "-----------------------\n",
      "Words is   :  Switzerland\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  439 === pobj === object of preposition\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  in\n",
      "POS is   :  85 === ADP === adposition\n",
      "Dep is   :  443 === prep === prepositional modifier\n",
      "Tag is   :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "-----------------------\n",
      "Words is   :  1895\n",
      "POS is   :  93 === NUM === numeral\n",
      "Dep is   :  439 === pobj === object of preposition\n",
      "Tag is   :  8427216679587749980 === CD === cardinal number\n",
      "-----------------------\n",
      "Words is   :  and\n",
      "POS is   :  89 === CCONJ === coordinating conjunction\n",
      "Dep is   :  407 === cc === coordinating conjunction\n",
      "Tag is   :  17571114184892886314 === CC === conjunction, coordinating\n",
      "-----------------------\n",
      "Words is   :  \n",
      "\n",
      "POS is   :  103 === SPACE === space\n",
      "Dep is   :  414 === dep === unclassified dependent\n",
      "Tag is   :  6893682062797376370 === _SP === whitespace\n",
      "-----------------------\n",
      "Words is   :  renounced\n",
      "POS is   :  100 === VERB === verb\n",
      "Dep is   :  410 === conj === conjunct\n",
      "Tag is   :  17109001835818727656 === VBD === verb, past tense\n",
      "-----------------------\n",
      "Words is   :  his\n",
      "POS is   :  95 === PRON === pronoun\n",
      "Dep is   :  440 === poss === possession modifier\n",
      "Tag is   :  4062917326063685704 === PRP$ === pronoun, possessive\n",
      "-----------------------\n",
      "Words is   :  German\n",
      "POS is   :  84 === ADJ === adjective\n",
      "Dep is   :  402 === amod === adjectival modifier\n",
      "Tag is   :  10554686591937588953 === JJ === adjective (English), other noun-modifier (Chinese)\n",
      "-----------------------\n",
      "Words is   :  citizenship\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  416 === dobj === direct object\n",
      "Tag is   :  15308085513773655218 === NN === noun, singular or mass\n",
      "-----------------------\n",
      "Words is   :  in\n",
      "POS is   :  85 === ADP === adposition\n",
      "Dep is   :  443 === prep === prepositional modifier\n",
      "Tag is   :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "-----------------------\n",
      "Words is   :  1896\n",
      "POS is   :  93 === NUM === numeral\n",
      "Dep is   :  439 === pobj === object of preposition\n",
      "Tag is   :  8427216679587749980 === CD === cardinal number\n",
      "-----------------------\n",
      "Words is   :  .\n",
      "POS is   :  97 === PUNCT === punctuation\n",
      "Dep is   :  445 === punct === punctuation\n",
      "Tag is   :  12646065887601541794 === . === punctuation mark, sentence closer\n",
      "-----------------------\n",
      "Words is   :  Specializing\n",
      "POS is   :  100 === VERB === verb\n",
      "Dep is   :  399 === advcl === adverbial clause modifier\n",
      "Tag is   :  1534113631682161808 === VBG === verb, gerund or present participle\n",
      "-----------------------\n",
      "Words is   :  in\n",
      "POS is   :  85 === ADP === adposition\n",
      "Dep is   :  443 === prep === prepositional modifier\n",
      "Tag is   :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "-----------------------\n",
      "Words is   :  physics\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  439 === pobj === object of preposition\n",
      "Tag is   :  15308085513773655218 === NN === noun, singular or mass\n",
      "-----------------------\n",
      "Words is   :  and\n",
      "POS is   :  89 === CCONJ === coordinating conjunction\n",
      "Dep is   :  407 === cc === coordinating conjunction\n",
      "Tag is   :  17571114184892886314 === CC === conjunction, coordinating\n",
      "-----------------------\n",
      "Words is   :  \n",
      "\n",
      "POS is   :  103 === SPACE === space\n",
      "Dep is   :  414 === dep === unclassified dependent\n",
      "Tag is   :  6893682062797376370 === _SP === whitespace\n",
      "-----------------------\n",
      "Words is   :  mathematics\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  410 === conj === conjunct\n",
      "Tag is   :  783433942507015291 === NNS === noun, plural\n",
      "-----------------------\n",
      "Words is   :  ,\n",
      "POS is   :  97 === PUNCT === punctuation\n",
      "Dep is   :  445 === punct === punctuation\n",
      "Tag is   :  2593208677638477497 === , === punctuation mark, comma\n",
      "-----------------------\n",
      "Words is   :  he\n",
      "POS is   :  95 === PRON === pronoun\n",
      "Dep is   :  429 === nsubj === nominal subject\n",
      "Tag is   :  13656873538139661788 === PRP === pronoun, personal\n",
      "-----------------------\n",
      "Words is   :  received\n",
      "POS is   :  100 === VERB === verb\n",
      "Dep is   :  8206900633647566924 === ROOT === root\n",
      "Tag is   :  17109001835818727656 === VBD === verb, past tense\n",
      "-----------------------\n",
      "Words is   :  his\n",
      "POS is   :  95 === PRON === pronoun\n",
      "Dep is   :  440 === poss === possession modifier\n",
      "Tag is   :  4062917326063685704 === PRP$ === pronoun, possessive\n",
      "-----------------------\n",
      "Words is   :  academic\n",
      "POS is   :  84 === ADJ === adjective\n",
      "Dep is   :  402 === amod === adjectival modifier\n",
      "Tag is   :  10554686591937588953 === JJ === adjective (English), other noun-modifier (Chinese)\n",
      "-----------------------\n",
      "Words is   :  teaching\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15308085513773655218 === NN === noun, singular or mass\n",
      "-----------------------\n",
      "Words is   :  diploma\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  416 === dobj === direct object\n",
      "Tag is   :  15308085513773655218 === NN === noun, singular or mass\n",
      "-----------------------\n",
      "Words is   :  from\n",
      "POS is   :  85 === ADP === adposition\n",
      "Dep is   :  443 === prep === prepositional modifier\n",
      "Tag is   :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "-----------------------\n",
      "Words is   :  the\n",
      "POS is   :  90 === DET === determiner\n",
      "Dep is   :  415 === det === determiner\n",
      "Tag is   :  15267657372422890137 === DT === determiner\n",
      "-----------------------\n",
      "Words is   :  Swiss\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  \n",
      "\n",
      "POS is   :  103 === SPACE === space\n",
      "Dep is   :  414 === dep === unclassified dependent\n",
      "Tag is   :  6893682062797376370 === _SP === whitespace\n",
      "-----------------------\n",
      "Words is   :  Federal\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Polytechnic\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  School\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  439 === pobj === object of preposition\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  (\n",
      "POS is   :  97 === PUNCT === punctuation\n",
      "Dep is   :  445 === punct === punctuation\n",
      "Tag is   :  17111077179131903759 === -LRB- === left round bracket\n",
      "-----------------------\n",
      "Words is   :  German\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  403 === appos === appositional modifier\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  :\n",
      "POS is   :  97 === PUNCT === punctuation\n",
      "Dep is   :  445 === punct === punctuation\n",
      "Tag is   :  11532473245541075862 === : === punctuation mark, colon or ellipsis\n",
      "-----------------------\n",
      "Words is   :  eidgenÃ¶ssische\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15308085513773655218 === NN === noun, singular or mass\n",
      "-----------------------\n",
      "Words is   :  polytechnische\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15308085513773655218 === NN === noun, singular or mass\n",
      "-----------------------\n",
      "Words is   :  Schule\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  403 === appos === appositional modifier\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  )\n",
      "POS is   :  97 === PUNCT === punctuation\n",
      "Dep is   :  445 === punct === punctuation\n",
      "Tag is   :  2465883113906300949 === -RRB- === right round bracket\n",
      "-----------------------\n",
      "Words is   :  \n",
      "\n",
      "POS is   :  103 === SPACE === space\n",
      "Dep is   :  414 === dep === unclassified dependent\n",
      "Tag is   :  6893682062797376370 === _SP === whitespace\n",
      "-----------------------\n",
      "Words is   :  in\n",
      "POS is   :  85 === ADP === adposition\n",
      "Dep is   :  443 === prep === prepositional modifier\n",
      "Tag is   :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "-----------------------\n",
      "Words is   :  ZÃ¼rich\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  439 === pobj === object of preposition\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  in\n",
      "POS is   :  85 === ADP === adposition\n",
      "Dep is   :  443 === prep === prepositional modifier\n",
      "Tag is   :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "-----------------------\n",
      "Words is   :  1900\n",
      "POS is   :  93 === NUM === numeral\n",
      "Dep is   :  439 === pobj === object of preposition\n",
      "Tag is   :  8427216679587749980 === CD === cardinal number\n",
      "-----------------------\n",
      "Words is   :  .\n",
      "POS is   :  97 === PUNCT === punctuation\n",
      "Dep is   :  445 === punct === punctuation\n",
      "Tag is   :  12646065887601541794 === . === punctuation mark, sentence closer\n",
      "-----------------------\n",
      "Words is   :  The\n",
      "POS is   :  90 === DET === determiner\n",
      "Dep is   :  415 === det === determiner\n",
      "Tag is   :  15267657372422890137 === DT === determiner\n",
      "-----------------------\n",
      "Words is   :  following\n",
      "POS is   :  84 === ADJ === adjective\n",
      "Dep is   :  402 === amod === adjectival modifier\n",
      "Tag is   :  10554686591937588953 === JJ === adjective (English), other noun-modifier (Chinese)\n",
      "-----------------------\n",
      "Words is   :  year\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  428 === npadvmod === noun phrase as adverbial modifier\n",
      "Tag is   :  15308085513773655218 === NN === noun, singular or mass\n",
      "-----------------------\n",
      "Words is   :  ,\n",
      "POS is   :  97 === PUNCT === punctuation\n",
      "Dep is   :  445 === punct === punctuation\n",
      "Tag is   :  2593208677638477497 === , === punctuation mark, comma\n",
      "-----------------------\n",
      "Words is   :  he\n",
      "POS is   :  95 === PRON === pronoun\n",
      "Dep is   :  429 === nsubj === nominal subject\n",
      "Tag is   :  13656873538139661788 === PRP === pronoun, personal\n",
      "-----------------------\n",
      "Words is   :  acquired\n",
      "POS is   :  100 === VERB === verb\n",
      "Dep is   :  8206900633647566924 === ROOT === root\n",
      "Tag is   :  17109001835818727656 === VBD === verb, past tense\n",
      "-----------------------\n",
      "Words is   :  Swiss\n",
      "POS is   :  84 === ADJ === adjective\n",
      "Dep is   :  402 === amod === adjectival modifier\n",
      "Tag is   :  10554686591937588953 === JJ === adjective (English), other noun-modifier (Chinese)\n",
      "-----------------------\n",
      "Words is   :  citizenship\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  416 === dobj === direct object\n",
      "Tag is   :  15308085513773655218 === NN === noun, singular or mass\n",
      "-----------------------\n",
      "Words is   :  ,\n",
      "POS is   :  97 === PUNCT === punctuation\n",
      "Dep is   :  445 === punct === punctuation\n",
      "Tag is   :  2593208677638477497 === , === punctuation mark, comma\n",
      "-----------------------\n",
      "Words is   :  which\n",
      "POS is   :  95 === PRON === pronoun\n",
      "Dep is   :  416 === dobj === direct object\n",
      "Tag is   :  17202369883303991778 === WDT === wh-determiner\n",
      "-----------------------\n",
      "Words is   :  \n",
      "\n",
      "POS is   :  103 === SPACE === space\n",
      "Dep is   :  414 === dep === unclassified dependent\n",
      "Tag is   :  6893682062797376370 === _SP === whitespace\n",
      "-----------------------\n",
      "Words is   :  he\n",
      "POS is   :  95 === PRON === pronoun\n",
      "Dep is   :  429 === nsubj === nominal subject\n",
      "Tag is   :  13656873538139661788 === PRP === pronoun, personal\n",
      "-----------------------\n",
      "Words is   :  kept\n",
      "POS is   :  100 === VERB === verb\n",
      "Dep is   :  447 === relcl === relative clause modifier\n",
      "Tag is   :  17109001835818727656 === VBD === verb, past tense\n",
      "-----------------------\n",
      "Words is   :  for\n",
      "POS is   :  85 === ADP === adposition\n",
      "Dep is   :  443 === prep === prepositional modifier\n",
      "Tag is   :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "-----------------------\n",
      "Words is   :  his\n",
      "POS is   :  95 === PRON === pronoun\n",
      "Dep is   :  440 === poss === possession modifier\n",
      "Tag is   :  4062917326063685704 === PRP$ === pronoun, possessive\n",
      "-----------------------\n",
      "Words is   :  entire\n",
      "POS is   :  84 === ADJ === adjective\n",
      "Dep is   :  402 === amod === adjectival modifier\n",
      "Tag is   :  10554686591937588953 === JJ === adjective (English), other noun-modifier (Chinese)\n",
      "-----------------------\n",
      "Words is   :  life\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  439 === pobj === object of preposition\n",
      "Tag is   :  15308085513773655218 === NN === noun, singular or mass\n",
      "-----------------------\n",
      "Words is   :  .\n",
      "POS is   :  97 === PUNCT === punctuation\n",
      "Dep is   :  445 === punct === punctuation\n",
      "Tag is   :  12646065887601541794 === . === punctuation mark, sentence closer\n",
      "-----------------------\n",
      "Words is   :  After\n",
      "POS is   :  85 === ADP === adposition\n",
      "Dep is   :  443 === prep === prepositional modifier\n",
      "Tag is   :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "-----------------------\n",
      "Words is   :  initially\n",
      "POS is   :  86 === ADV === adverb\n",
      "Dep is   :  400 === advmod === adverbial modifier\n",
      "Tag is   :  164681854541413346 === RB === adverb\n",
      "-----------------------\n",
      "Words is   :  struggling\n",
      "POS is   :  100 === VERB === verb\n",
      "Dep is   :  438 === pcomp === complement of preposition\n",
      "Tag is   :  1534113631682161808 === VBG === verb, gerund or present participle\n",
      "-----------------------\n",
      "Words is   :  to\n",
      "POS is   :  94 === PART === particle\n",
      "Dep is   :  405 === aux === auxiliary\n",
      "Tag is   :  5595707737748328492 === TO === infinitival \"to\"\n",
      "-----------------------\n",
      "Words is   :  find\n",
      "POS is   :  100 === VERB === verb\n",
      "Dep is   :  450 === xcomp === open clausal complement\n",
      "Tag is   :  14200088355797579614 === VB === verb, base form\n",
      "-----------------------\n",
      "Words is   :  work\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  416 === dobj === direct object\n",
      "Tag is   :  15308085513773655218 === NN === noun, singular or mass\n",
      "-----------------------\n",
      "Words is   :  ,\n",
      "POS is   :  97 === PUNCT === punctuation\n",
      "Dep is   :  445 === punct === punctuation\n",
      "Tag is   :  2593208677638477497 === , === punctuation mark, comma\n",
      "-----------------------\n",
      "Words is   :  from\n",
      "POS is   :  85 === ADP === adposition\n",
      "Dep is   :  443 === prep === prepositional modifier\n",
      "Tag is   :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "-----------------------\n",
      "Words is   :  \n",
      "\n",
      "POS is   :  103 === SPACE === space\n",
      "Dep is   :  414 === dep === unclassified dependent\n",
      "Tag is   :  6893682062797376370 === _SP === whitespace\n",
      "-----------------------\n",
      "Words is   :  1902\n",
      "POS is   :  93 === NUM === numeral\n",
      "Dep is   :  439 === pobj === object of preposition\n",
      "Tag is   :  8427216679587749980 === CD === cardinal number\n",
      "-----------------------\n",
      "Words is   :  to\n",
      "POS is   :  85 === ADP === adposition\n",
      "Dep is   :  443 === prep === prepositional modifier\n",
      "Tag is   :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "-----------------------\n",
      "Words is   :  1909\n",
      "POS is   :  93 === NUM === numeral\n",
      "Dep is   :  439 === pobj === object of preposition\n",
      "Tag is   :  8427216679587749980 === CD === cardinal number\n",
      "-----------------------\n",
      "Words is   :  he\n",
      "POS is   :  95 === PRON === pronoun\n",
      "Dep is   :  430 === nsubjpass === nominal subject (passive)\n",
      "Tag is   :  13656873538139661788 === PRP === pronoun, personal\n",
      "-----------------------\n",
      "Words is   :  was\n",
      "POS is   :  87 === AUX === auxiliary\n",
      "Dep is   :  406 === auxpass === auxiliary (passive)\n",
      "Tag is   :  17109001835818727656 === VBD === verb, past tense\n",
      "-----------------------\n",
      "Words is   :  employed\n",
      "POS is   :  100 === VERB === verb\n",
      "Dep is   :  8206900633647566924 === ROOT === root\n",
      "Tag is   :  3822385049556375858 === VBN === verb, past participle\n",
      "-----------------------\n",
      "Words is   :  as\n",
      "POS is   :  85 === ADP === adposition\n",
      "Dep is   :  443 === prep === prepositional modifier\n",
      "Tag is   :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "-----------------------\n",
      "Words is   :  a\n",
      "POS is   :  90 === DET === determiner\n",
      "Dep is   :  415 === det === determiner\n",
      "Tag is   :  15267657372422890137 === DT === determiner\n",
      "-----------------------\n",
      "Words is   :  patent\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15308085513773655218 === NN === noun, singular or mass\n",
      "-----------------------\n",
      "Words is   :  examiner\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  439 === pobj === object of preposition\n",
      "Tag is   :  15308085513773655218 === NN === noun, singular or mass\n",
      "-----------------------\n",
      "Words is   :  at\n",
      "POS is   :  85 === ADP === adposition\n",
      "Dep is   :  443 === prep === prepositional modifier\n",
      "Tag is   :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "-----------------------\n",
      "Words is   :  the\n",
      "POS is   :  90 === DET === determiner\n",
      "Dep is   :  415 === det === determiner\n",
      "Tag is   :  15267657372422890137 === DT === determiner\n",
      "-----------------------\n",
      "Words is   :  Swiss\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Patent\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Office\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  439 === pobj === object of preposition\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  \n",
      "\n",
      "POS is   :  103 === SPACE === space\n",
      "Dep is   :  414 === dep === unclassified dependent\n",
      "Tag is   :  6893682062797376370 === _SP === whitespace\n",
      "-----------------------\n",
      "Words is   :  in\n",
      "POS is   :  85 === ADP === adposition\n",
      "Dep is   :  443 === prep === prepositional modifier\n",
      "Tag is   :  1292078113972184607 === IN === conjunction, subordinating or preposition\n",
      "-----------------------\n",
      "Words is   :  Bern\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  439 === pobj === object of preposition\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  .\n",
      "POS is   :  97 === PUNCT === punctuation\n",
      "Dep is   :  445 === punct === punctuation\n",
      "Tag is   :  12646065887601541794 === . === punctuation mark, sentence closer\n",
      "-----------------------\n",
      "Words is   :  \n",
      "\n",
      "\n",
      "POS is   :  103 === SPACE === space\n",
      "Dep is   :  414 === dep === unclassified dependent\n",
      "Tag is   :  6893682062797376370 === _SP === whitespace\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ù…Ø±ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ | Load model & analyze text\n",
    "# ØªØ­Ù…ÙŠÙ„ Ù…ÙƒØªØ¨Ø© spaCy ÙˆØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ Ø§Ù„ØµØºÙŠØ±\n",
    "# Load spaCy and the small English model\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Ù†Øµ Ø·ÙˆÙŠÙ„ Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ÙˆØ³Ù… Ø§Ù„Ù†Ø­ÙˆÙŠ ÙˆØ§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ù†Ø­ÙˆÙŠØ©\n",
    "# A long paragraph to test POS tags and syntactic dependencies\n",
    "doc1 = nlp('''The son of a salesman who later operated an electrochemical factory, \n",
    "instein was born in the German Empire, but moved to Switzerland in 1895 and \n",
    "renounced his German citizenship in 1896. Specializing in physics and\n",
    "mathematics, he received his academic teaching diploma from the Swiss \n",
    "Federal Polytechnic School (German: eidgenÃ¶ssische polytechnische Schule) \n",
    "in ZÃ¼rich in 1900. The following year, he acquired Swiss citizenship, which\n",
    "he kept for his entire life. After initially struggling to find work, from \n",
    "1902 to 1909 he was employed as a patent examiner at the Swiss Patent Office\n",
    "in Bern.\n",
    "\n",
    "''')\n",
    "\n",
    "# Ø§Ø³ØªØ¹Ø±Ø§Ø¶ ÙƒÙ„ ØªÙˆÙƒÙ† Ù…Ø¹ POS / DEP / TAG ÙˆØ´Ø±Ø­Ù‡Ø§\n",
    "# Iterate tokens to show POS / DEP / TAG plus explanations\n",
    "for token in doc1:\n",
    "    print('Words is   : ' , token.text)\n",
    "    print('POS is   : ' , token.pos ,'===',token.pos_  , '===', spacy.explain(token.pos_))\n",
    "    print('Dep is   : ' , token.dep , '===',token.dep_, '===', spacy.explain(token.dep_))\n",
    "    print('Tag is   : ' , token.tag , '===',token.tag_, '===', spacy.explain(token.tag_))\n",
    "    print('-----------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fd4ce5",
   "metadata": {},
   "source": [
    "> ğŸ“ ğŸ‡¸ğŸ‡¦ **Ù…Ù„Ø§Ø­Ø¸Ø©:** `pos_` ØªØ¹Ø·ÙŠ Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø¹Ø§Ù… (Ù…Ø«Ù„Ø§Ù‹ VERB)ØŒ Ø¨ÙŠÙ†Ù…Ø§ `tag_` ØªØ¹Ø·ÙŠ **ØªÙØµÙŠÙ„Ø§Ù‹ Ø¯Ù‚ÙŠÙ‚Ù‹Ø§** (Ù…Ø«Ù„ VBD = ÙØ¹Ù„ Ù…Ø§Ø¶Ù).\n",
    "> ğŸ“ ğŸ‡¬ğŸ‡§ **Note:** `pos_` is a coarse tag (e.g., VERB) while `tag_` is a **fine-grained** tag (e.g., VBD = past tense verb).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9efd883e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The          DET      DT     determiner\n",
      "son          NOUN     NN     noun, singular or mass\n",
      "of           ADP      IN     conjunction, subordinating or preposition\n",
      "a            DET      DT     determiner\n",
      "salesman     NOUN     NN     noun, singular or mass\n",
      "who          PRON     WP     wh-pronoun, personal\n",
      "later        ADV      RB     adverb\n",
      "operated     VERB     VBD    verb, past tense\n",
      "an           DET      DT     determiner\n",
      "electrochemical ADJ      JJ     adjective (English), other noun-modifier (Chinese)\n",
      "factory      NOUN     NN     noun, singular or mass\n",
      ",            PUNCT    ,      punctuation mark, comma\n",
      "\n",
      "            SPACE    _SP    whitespace\n",
      "instein      NOUN     NN     noun, singular or mass\n",
      "was          AUX      VBD    verb, past tense\n",
      "born         VERB     VBN    verb, past participle\n",
      "in           ADP      IN     conjunction, subordinating or preposition\n",
      "the          DET      DT     determiner\n",
      "German       PROPN    NNP    noun, proper singular\n",
      "Empire       PROPN    NNP    noun, proper singular\n",
      ",            PUNCT    ,      punctuation mark, comma\n",
      "but          CCONJ    CC     conjunction, coordinating\n",
      "moved        VERB     VBD    verb, past tense\n",
      "to           ADP      IN     conjunction, subordinating or preposition\n",
      "Switzerland  PROPN    NNP    noun, proper singular\n",
      "in           ADP      IN     conjunction, subordinating or preposition\n",
      "1895         NUM      CD     cardinal number\n",
      "and          CCONJ    CC     conjunction, coordinating\n",
      "\n",
      "            SPACE    _SP    whitespace\n",
      "renounced    VERB     VBD    verb, past tense\n",
      "his          PRON     PRP$   pronoun, possessive\n",
      "German       ADJ      JJ     adjective (English), other noun-modifier (Chinese)\n",
      "citizenship  NOUN     NN     noun, singular or mass\n",
      "in           ADP      IN     conjunction, subordinating or preposition\n",
      "1896         NUM      CD     cardinal number\n",
      ".            PUNCT    .      punctuation mark, sentence closer\n",
      "Specializing VERB     VBG    verb, gerund or present participle\n",
      "in           ADP      IN     conjunction, subordinating or preposition\n",
      "physics      NOUN     NN     noun, singular or mass\n",
      "and          CCONJ    CC     conjunction, coordinating\n",
      "\n",
      "            SPACE    _SP    whitespace\n",
      "mathematics  NOUN     NNS    noun, plural\n",
      ",            PUNCT    ,      punctuation mark, comma\n",
      "he           PRON     PRP    pronoun, personal\n",
      "received     VERB     VBD    verb, past tense\n",
      "his          PRON     PRP$   pronoun, possessive\n",
      "academic     ADJ      JJ     adjective (English), other noun-modifier (Chinese)\n",
      "teaching     NOUN     NN     noun, singular or mass\n",
      "diploma      NOUN     NN     noun, singular or mass\n",
      "from         ADP      IN     conjunction, subordinating or preposition\n",
      "the          DET      DT     determiner\n",
      "Swiss        PROPN    NNP    noun, proper singular\n",
      "\n",
      "            SPACE    _SP    whitespace\n",
      "Federal      PROPN    NNP    noun, proper singular\n",
      "Polytechnic  PROPN    NNP    noun, proper singular\n",
      "School       PROPN    NNP    noun, proper singular\n",
      "(            PUNCT    -LRB-  left round bracket\n",
      "German       PROPN    NNP    noun, proper singular\n",
      ":            PUNCT    :      punctuation mark, colon or ellipsis\n",
      "eidgenÃ¶ssische NOUN     NN     noun, singular or mass\n",
      "polytechnische NOUN     NN     noun, singular or mass\n",
      "Schule       PROPN    NNP    noun, proper singular\n",
      ")            PUNCT    -RRB-  right round bracket\n",
      "\n",
      "            SPACE    _SP    whitespace\n",
      "in           ADP      IN     conjunction, subordinating or preposition\n",
      "ZÃ¼rich       PROPN    NNP    noun, proper singular\n",
      "in           ADP      IN     conjunction, subordinating or preposition\n",
      "1900         NUM      CD     cardinal number\n",
      ".            PUNCT    .      punctuation mark, sentence closer\n",
      "The          DET      DT     determiner\n",
      "following    ADJ      JJ     adjective (English), other noun-modifier (Chinese)\n",
      "year         NOUN     NN     noun, singular or mass\n",
      ",            PUNCT    ,      punctuation mark, comma\n",
      "he           PRON     PRP    pronoun, personal\n",
      "acquired     VERB     VBD    verb, past tense\n",
      "Swiss        ADJ      JJ     adjective (English), other noun-modifier (Chinese)\n",
      "citizenship  NOUN     NN     noun, singular or mass\n",
      ",            PUNCT    ,      punctuation mark, comma\n",
      "which        PRON     WDT    wh-determiner\n",
      "\n",
      "            SPACE    _SP    whitespace\n",
      "he           PRON     PRP    pronoun, personal\n",
      "kept         VERB     VBD    verb, past tense\n",
      "for          ADP      IN     conjunction, subordinating or preposition\n",
      "his          PRON     PRP$   pronoun, possessive\n",
      "entire       ADJ      JJ     adjective (English), other noun-modifier (Chinese)\n",
      "life         NOUN     NN     noun, singular or mass\n",
      ".            PUNCT    .      punctuation mark, sentence closer\n",
      "After        ADP      IN     conjunction, subordinating or preposition\n",
      "initially    ADV      RB     adverb\n",
      "struggling   VERB     VBG    verb, gerund or present participle\n",
      "to           PART     TO     infinitival \"to\"\n",
      "find         VERB     VB     verb, base form\n",
      "work         NOUN     NN     noun, singular or mass\n",
      ",            PUNCT    ,      punctuation mark, comma\n",
      "from         ADP      IN     conjunction, subordinating or preposition\n",
      "\n",
      "            SPACE    _SP    whitespace\n",
      "1902         NUM      CD     cardinal number\n",
      "to           ADP      IN     conjunction, subordinating or preposition\n",
      "1909         NUM      CD     cardinal number\n",
      "he           PRON     PRP    pronoun, personal\n",
      "was          AUX      VBD    verb, past tense\n",
      "employed     VERB     VBN    verb, past participle\n",
      "as           ADP      IN     conjunction, subordinating or preposition\n",
      "a            DET      DT     determiner\n",
      "patent       NOUN     NN     noun, singular or mass\n",
      "examiner     NOUN     NN     noun, singular or mass\n",
      "at           ADP      IN     conjunction, subordinating or preposition\n",
      "the          DET      DT     determiner\n",
      "Swiss        PROPN    NNP    noun, proper singular\n",
      "Patent       PROPN    NNP    noun, proper singular\n",
      "Office       PROPN    NNP    noun, proper singular\n",
      "\n",
      "            SPACE    _SP    whitespace\n",
      "in           ADP      IN     conjunction, subordinating or preposition\n",
      "Bern         PROPN    NNP    noun, proper singular\n",
      ".            PUNCT    .      punctuation mark, sentence closer\n",
      "\n",
      "\n",
      "           SPACE    _SP    whitespace\n"
     ]
    }
   ],
   "source": [
    "# Ø·Ø¨Ø§Ø¹Ø© ØµÙ ÙˆØ§Ø­Ø¯ Ù…Ù†Ø³Ù‘Ù‚ (Ù†Øµ â€“ POS â€“ TAG â€“ Ø§Ù„ÙˆØµÙ) | Pretty row print\n",
    "for token in doc1:\n",
    "    print(f'{token.text:{12}} {token.pos_:{8}} {token.tag_:{6}} {spacy.explain(token.tag_)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a1f9f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read       VERB     VBP    verb, non-3rd person singular present\n",
      "read       VERB     VBD    verb, past tense\n"
     ]
    }
   ],
   "source": [
    "# ØªÙ…ÙŠÙŠØ² Ø§Ù„Ø²Ù…Ù† Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚ (read: Ù…Ø¶Ø§Ø±Ø¹/Ù…Ø§Ø¶Ù) | Tense disambiguation by context\n",
    "# Ù…Ø¶Ø§Ø±Ø¹ / Present\n",
    "doc = nlp(u'I read book now.')\n",
    "r = doc[1]\n",
    "print(f'{r.text:{10}} {r.pos_:{8}} {r.tag_:{6}} {spacy.explain(r.tag_)}')  # VBP: present\n",
    "\n",
    "# Ù…Ø§Ø¶Ù / Past\n",
    "doc = nlp(u'I read a book on NLP.')\n",
    "r = doc[1]\n",
    "print(f'{r.text:{10}} {r.pos_:{8}} {r.tag_:{6}} {spacy.explain(r.tag_)}')  # VBD: past\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd54545d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84. ADJ  : 6\n",
      "85. ADP  : 16\n",
      "86. ADV  : 2\n",
      "87. AUX  : 2\n",
      "89. CCONJ: 3\n",
      "90. DET  : 8\n",
      "92. NOUN : 17\n",
      "93. NUM  : 5\n",
      "94. PART : 1\n",
      "95. PRON : 9\n",
      "96. PROPN: 14\n",
      "97. PUNCT: 13\n",
      "100. VERB : 11\n",
      "103. SPACE: 9\n",
      "164681854541413346. RB  : 2\n",
      "783433942507015291. NNS : 1\n",
      "1292078113972184607. IN  : 16\n",
      "1534113631682161808. VBG : 2\n",
      "2465883113906300949. -RRB-: 1\n",
      "2593208677638477497. ,   : 6\n",
      "3822385049556375858. VBN : 2\n",
      "4062917326063685704. PRP$: 3\n",
      "4808651922106831370. WP  : 1\n",
      "5595707737748328492. TO  : 1\n",
      "6893682062797376370. _SP : 9\n",
      "8427216679587749980. CD  : 5\n",
      "10554686591937588953. JJ  : 6\n",
      "11532473245541075862. :   : 1\n",
      "12646065887601541794. .   : 4\n",
      "13656873538139661788. PRP : 4\n",
      "14200088355797579614. VB  : 1\n",
      "15267657372422890137. DT  : 8\n",
      "15308085513773655218. NN  : 16\n",
      "15794550382381185553. NNP : 14\n",
      "17109001835818727656. VBD : 8\n",
      "17111077179131903759. -LRB-: 1\n",
      "17202369883303991778. WDT : 1\n",
      "17571114184892886314. CC  : 3\n",
      "399. advcl: 1\n",
      "400. advmod: 2\n",
      "402. amod: 6\n",
      "403. appos: 3\n",
      "405. aux : 1\n",
      "406. auxpass: 2\n",
      "407. cc  : 3\n",
      "410. conj: 3\n",
      "414. dep : 9\n",
      "415. det : 8\n",
      "416. dobj: 6\n",
      "428. npadvmod: 1\n",
      "429. nsubj: 4\n",
      "430. nsubjpass: 2\n",
      "438. pcomp: 1\n",
      "439. pobj: 15\n",
      "440. poss: 3\n",
      "443. prep: 16\n",
      "445. punct: 13\n",
      "447. relcl: 2\n",
      "450. xcomp: 1\n",
      "7037928807040764755. compound: 10\n",
      "8206900633647566924. ROOT: 4\n"
     ]
    }
   ],
   "source": [
    "# Ø¥Ø­ØµØ§Ø¡Ø§Øª Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ (POS/TAG/DEP) | Document-level counts\n",
    "\n",
    "# Ø¹Ø¯Ù‘ Ø§Ù„ØªÙˆØ²ÙŠØ¹Ø§Øª Ø­Ø³Ø¨ POS/TAG/DEP\n",
    "# Count distributions by POS/TAG/DEP\n",
    "\n",
    "# POS counts\n",
    "POS_counts = doc1.count_by(spacy.attrs.POS)\n",
    "for k,v in sorted(POS_counts.items()):\n",
    "    print(f'{k}. {doc1.vocab[k].text:{5}}: {v}')\n",
    "\n",
    "# TAG counts\n",
    "TAG_counts = doc1.count_by(spacy.attrs.TAG)\n",
    "for k,v in sorted(TAG_counts.items()):\n",
    "    print(f'{k}. {doc1.vocab[k].text:{4}}: {v}')\n",
    "\n",
    "# DEP counts\n",
    "DEP_counts = doc1.count_by(spacy.attrs.DEP)\n",
    "for k,v in sorted(DEP_counts.items()):\n",
    "    print(f'{k}. {doc1.vocab[k].text:{4}}: {v}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a501af66",
   "metadata": {},
   "source": [
    "> ğŸ‡¸ğŸ‡¦ Ù…ÙÙŠØ¯ Ù„ÙÙ‡Ù… â€œØ¨ØµÙ…Ø©â€ Ù†Øµ Ù…Ø§ (ÙƒØ«Ø±Ø© Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ØŸ ÙƒØ«Ø±Ø© Ø§Ù„Ø£ÙØ¹Ø§Ù„ØŸ).\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ Useful to understand a textâ€™s â€œsignatureâ€ (more nouns? more verbs?).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f11922f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger_eng')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\shosh/nltk_data'\n    - 'c:\\\\Users\\\\shosh\\\\.conda\\\\envs\\\\NLP\\\\nltk_data'\n    - 'c:\\\\Users\\\\shosh\\\\.conda\\\\envs\\\\NLP\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\shosh\\\\.conda\\\\envs\\\\NLP\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\shosh\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMoses supposes his toeses are roses but moses supposes erroneously\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Show word, tag, and tag meaning using spacy.explain (general description)\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w , m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword : (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mw\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), type : (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) , means :  (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspacy\u001b[38;5;241m.\u001b[39mexplain(m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\shosh\\.conda\\envs\\NLP\\lib\\site-packages\\nltk\\tag\\__init__.py:168\u001b[0m, in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset, lang)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpos_tag\u001b[39m(tokens, tagset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m    Use NLTK's currently recommended part of speech tagger to\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03m    tag the given list of tokens.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;124;03m    :rtype: list(tuple(str, str))\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m     tagger \u001b[38;5;241m=\u001b[39m \u001b[43m_get_tagger\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _pos_tag(tokens, tagset, tagger, lang)\n",
      "File \u001b[1;32mc:\\Users\\shosh\\.conda\\envs\\NLP\\lib\\site-packages\\nltk\\tag\\__init__.py:110\u001b[0m, in \u001b[0;36m_get_tagger\u001b[1;34m(lang)\u001b[0m\n\u001b[0;32m    108\u001b[0m     tagger \u001b[38;5;241m=\u001b[39m PerceptronTagger(lang\u001b[38;5;241m=\u001b[39mlang)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 110\u001b[0m     tagger \u001b[38;5;241m=\u001b[39m \u001b[43mPerceptronTagger\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tagger\n",
      "File \u001b[1;32mc:\\Users\\shosh\\.conda\\envs\\NLP\\lib\\site-packages\\nltk\\tag\\perceptron.py:180\u001b[0m, in \u001b[0;36mPerceptronTagger.__init__\u001b[1;34m(self, load, lang, loc)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m=\u001b[39m path_join(\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTRAINED_TAGGER_PATH, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTAGGER_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlang\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    178\u001b[0m )\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load:\n\u001b[1;32m--> 180\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shosh\\.conda\\envs\\NLP\\lib\\site-packages\\nltk\\tag\\perceptron.py:277\u001b[0m, in \u001b[0;36mPerceptronTagger.load_from_json\u001b[1;34m(self, lang, loc)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_from_json\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m\"\u001b[39m, loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;66;03m# Automatically find path to the tagger if location is not specified.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m loc:\n\u001b[1;32m--> 277\u001b[0m         loc \u001b[38;5;241m=\u001b[39m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtaggers/averaged_perceptron_tagger_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_param\u001b[39m(json_file):\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path_join(loc, json_file)) \u001b[38;5;28;01mas\u001b[39;00m fin:\n",
      "File \u001b[1;32mc:\\Users\\shosh\\.conda\\envs\\NLP\\lib\\site-packages\\nltk\\data.py:579\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    577\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    578\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 579\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger_eng')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\shosh/nltk_data'\n    - 'c:\\\\Users\\\\shosh\\\\.conda\\\\envs\\\\NLP\\\\nltk_data'\n    - 'c:\\\\Users\\\\shosh\\\\.conda\\\\envs\\\\NLP\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\shosh\\\\.conda\\\\envs\\\\NLP\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\shosh\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# ÙˆØ³Ù… Ù†Ø­ÙˆÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… NLTK | POS tagging with NLTK\n",
    "import nltk\n",
    "from nltk.corpus import state_union\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "text = 'Moses supposes his toeses are roses but moses supposes erroneously'\n",
    "\n",
    "# Show word, tag, and tag meaning using spacy.explain (general description)\n",
    "for w , m in nltk.pos_tag(nltk.word_tokenize(text)):\n",
    "    print(f'word : ({w}), type : ({m}) , means :  ({spacy.explain(m)})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2223845f",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger_eng')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\shosh/nltk_data'\n    - 'c:\\\\Users\\\\shosh\\\\.conda\\\\envs\\\\NLP\\\\nltk_data'\n    - 'c:\\\\Users\\\\shosh\\\\.conda\\\\envs\\\\NLP\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\shosh\\\\.conda\\\\envs\\\\NLP\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\shosh\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m tokenized[:\u001b[38;5;241m10\u001b[39m]  \u001b[38;5;66;03m# Ù„Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø³Ø±ÙŠØ¹ / quick peek\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tokenized[:\u001b[38;5;241m5\u001b[39m]:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m w , m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword : (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mw\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m), type : (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) , means :  (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspacy\u001b[38;5;241m.\u001b[39mexplain(m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-----------------------------------------------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\shosh\\.conda\\envs\\NLP\\lib\\site-packages\\nltk\\tag\\__init__.py:168\u001b[0m, in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset, lang)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpos_tag\u001b[39m(tokens, tagset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m    Use NLTK's currently recommended part of speech tagger to\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;124;03m    tag the given list of tokens.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;124;03m    :rtype: list(tuple(str, str))\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m     tagger \u001b[38;5;241m=\u001b[39m \u001b[43m_get_tagger\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _pos_tag(tokens, tagset, tagger, lang)\n",
      "File \u001b[1;32mc:\\Users\\shosh\\.conda\\envs\\NLP\\lib\\site-packages\\nltk\\tag\\__init__.py:110\u001b[0m, in \u001b[0;36m_get_tagger\u001b[1;34m(lang)\u001b[0m\n\u001b[0;32m    108\u001b[0m     tagger \u001b[38;5;241m=\u001b[39m PerceptronTagger(lang\u001b[38;5;241m=\u001b[39mlang)\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 110\u001b[0m     tagger \u001b[38;5;241m=\u001b[39m \u001b[43mPerceptronTagger\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tagger\n",
      "File \u001b[1;32mc:\\Users\\shosh\\.conda\\envs\\NLP\\lib\\site-packages\\nltk\\tag\\perceptron.py:180\u001b[0m, in \u001b[0;36mPerceptronTagger.__init__\u001b[1;34m(self, load, lang, loc)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m=\u001b[39m path_join(\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTRAINED_TAGGER_PATH, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTAGGER_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlang\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    178\u001b[0m )\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load:\n\u001b[1;32m--> 180\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shosh\\.conda\\envs\\NLP\\lib\\site-packages\\nltk\\tag\\perceptron.py:277\u001b[0m, in \u001b[0;36mPerceptronTagger.load_from_json\u001b[1;34m(self, lang, loc)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_from_json\u001b[39m(\u001b[38;5;28mself\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m\"\u001b[39m, loc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;66;03m# Automatically find path to the tagger if location is not specified.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m loc:\n\u001b[1;32m--> 277\u001b[0m         loc \u001b[38;5;241m=\u001b[39m \u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtaggers/averaged_perceptron_tagger_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlang\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_param\u001b[39m(json_file):\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path_join(loc, json_file)) \u001b[38;5;28;01mas\u001b[39;00m fin:\n",
      "File \u001b[1;32mc:\\Users\\shosh\\.conda\\envs\\NLP\\lib\\site-packages\\nltk\\data.py:579\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    577\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[0;32m    578\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 579\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93maveraged_perceptron_tagger_eng\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('averaged_perceptron_tagger_eng')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtaggers/averaged_perceptron_tagger_eng\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\shosh/nltk_data'\n    - 'c:\\\\Users\\\\shosh\\\\.conda\\\\envs\\\\NLP\\\\nltk_data'\n    - 'c:\\\\Users\\\\shosh\\\\.conda\\\\envs\\\\NLP\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\shosh\\\\.conda\\\\envs\\\\NLP\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\shosh\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# Ù…Ø«Ø§Ù„ Ù†Øµ Ø·ÙˆÙŠÙ„ (NLTK) | Longer sample (NLTK)\n",
    "\n",
    "# Ù†Øµ Ø·ÙˆÙŠÙ„ Ù„Ø§Ø®ØªØ¨Ø§Ø± Punkt + pos_tag\n",
    "# Longer paragraph to test Punkt + pos_tag\n",
    "text = '''\n",
    "Thomas Gradgrind, sir.  A man of realities.  A man of facts and calculations.  A man who proceeds upon the principle that\n",
    "two and two are four, and nothing over, and who is not to be talked into allowing for anything over.  Thomas Gradgrind, \n",
    "sirâ€”peremptorily Thomasâ€”Thomas Gradgrind.  With a rule and a pair of scales, and the multiplication table always in his pocket, \n",
    "sir, ready to weigh and measure any parcel of human nature, and tell you exactly what it comes to.  It is a mere question of\n",
    "figures, a case of simple arithmetic.  You might hope to get some other nonsensical belief into the head of George Gradgrind, or Augustus Gradgrind, or John Gradgrind, or Joseph Gradgrind (all supposititious, non-existent persons), but into the head of Thomas Gradgrindâ€”no, sir!\n",
    "\n",
    "In such terms Mr. Gradgrind always mentally introduced himself, whether to his private circle of acquaintance, or to the public in general.  In such terms, no doubt, substituting the words â€˜boys and girls,â€™ for â€˜sir,â€™ Thomas Gradgrind now presented Thomas Gradgrind to the little pitchers before him, who were to be filled so full of facts.\n",
    "'''\n",
    "\n",
    "# ØªÙ‚Ø³ÙŠÙ… Ø¥Ù„Ù‰ Ø¬Ù…Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Punkt Ø«Ù… ÙˆØ³Ù… ÙƒÙ„ Ø¬Ù…Ù„Ø©\n",
    "# Sentence tokenize using Punkt then POS tag each sentence\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(text)\n",
    "tokenized = custom_sent_tokenizer.tokenize(text)\n",
    "tokenized[:10]  # Ù„Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø³Ø±ÙŠØ¹ / quick peek\n",
    "\n",
    "for i in tokenized[:5]:\n",
    "    for w , m in nltk.pos_tag(nltk.word_tokenize(i)):\n",
    "        print(f'word : ({w}), type : ({m}) , means :  ({spacy.explain(m)})')\n",
    "    print('-----------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2201e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package state_union to\n",
      "[nltk_data]     C:\\Users\\shosh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\state_union.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('state_union')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "642479cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\shosh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fded1373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word : (PRESIDENT), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (GEORGE), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (W.), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (BUSH), type : (NNP) , means :  (noun, proper singular)\n",
      "word : ('S), type : (POS) , means :  (possessive ending)\n",
      "word : (ADDRESS), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (BEFORE), type : (IN) , means :  (conjunction, subordinating or preposition)\n",
      "word : (A), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (JOINT), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (SESSION), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (OF), type : (IN) , means :  (conjunction, subordinating or preposition)\n",
      "word : (THE), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (CONGRESS), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (ON), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (THE), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (STATE), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (OF), type : (IN) , means :  (conjunction, subordinating or preposition)\n",
      "word : (THE), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (UNION), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (January), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (31), type : (CD) , means :  (cardinal number)\n",
      "word : (,), type : (,) , means :  (punctuation mark, comma)\n",
      "word : (2006), type : (CD) , means :  (cardinal number)\n",
      "word : (THE), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (PRESIDENT), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (:), type : (:) , means :  (punctuation mark, colon or ellipsis)\n",
      "word : (Thank), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (you), type : (PRP) , means :  (pronoun, personal)\n",
      "word : (all), type : (DT) , means :  (determiner)\n",
      "word : (.), type : (.) , means :  (punctuation mark, sentence closer)\n",
      "-----------------------------------------------\n",
      "word : (Mr.), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (Speaker), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (,), type : (,) , means :  (punctuation mark, comma)\n",
      "word : (Vice), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (President), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (Cheney), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (,), type : (,) , means :  (punctuation mark, comma)\n",
      "word : (members), type : (NNS) , means :  (noun, plural)\n",
      "word : (of), type : (IN) , means :  (conjunction, subordinating or preposition)\n",
      "word : (Congress), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (,), type : (,) , means :  (punctuation mark, comma)\n",
      "word : (members), type : (NNS) , means :  (noun, plural)\n",
      "word : (of), type : (IN) , means :  (conjunction, subordinating or preposition)\n",
      "word : (the), type : (DT) , means :  (determiner)\n",
      "word : (Supreme), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (Court), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (and), type : (CC) , means :  (conjunction, coordinating)\n",
      "word : (diplomatic), type : (JJ) , means :  (adjective (English), other noun-modifier (Chinese))\n",
      "word : (corps), type : (NN) , means :  (noun, singular or mass)\n",
      "word : (,), type : (,) , means :  (punctuation mark, comma)\n",
      "word : (distinguished), type : (JJ) , means :  (adjective (English), other noun-modifier (Chinese))\n",
      "word : (guests), type : (NNS) , means :  (noun, plural)\n",
      "word : (,), type : (,) , means :  (punctuation mark, comma)\n",
      "word : (and), type : (CC) , means :  (conjunction, coordinating)\n",
      "word : (fellow), type : (JJ) , means :  (adjective (English), other noun-modifier (Chinese))\n",
      "word : (citizens), type : (NNS) , means :  (noun, plural)\n",
      "word : (:), type : (:) , means :  (punctuation mark, colon or ellipsis)\n",
      "word : (Today), type : (VB) , means :  (verb, base form)\n",
      "word : (our), type : (PRP$) , means :  (pronoun, possessive)\n",
      "word : (nation), type : (NN) , means :  (noun, singular or mass)\n",
      "word : (lost), type : (VBD) , means :  (verb, past tense)\n",
      "word : (a), type : (DT) , means :  (determiner)\n",
      "word : (beloved), type : (VBN) , means :  (verb, past participle)\n",
      "word : (,), type : (,) , means :  (punctuation mark, comma)\n",
      "word : (graceful), type : (JJ) , means :  (adjective (English), other noun-modifier (Chinese))\n",
      "word : (,), type : (,) , means :  (punctuation mark, comma)\n",
      "word : (courageous), type : (JJ) , means :  (adjective (English), other noun-modifier (Chinese))\n",
      "word : (woman), type : (NN) , means :  (noun, singular or mass)\n",
      "word : (who), type : (WP) , means :  (wh-pronoun, personal)\n",
      "word : (called), type : (VBD) , means :  (verb, past tense)\n",
      "word : (America), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (to), type : (TO) , means :  (infinitival \"to\")\n",
      "word : (its), type : (PRP$) , means :  (pronoun, possessive)\n",
      "word : (founding), type : (NN) , means :  (noun, singular or mass)\n",
      "word : (ideals), type : (NNS) , means :  (noun, plural)\n",
      "word : (and), type : (CC) , means :  (conjunction, coordinating)\n",
      "word : (carried), type : (VBD) , means :  (verb, past tense)\n",
      "word : (on), type : (IN) , means :  (conjunction, subordinating or preposition)\n",
      "word : (a), type : (DT) , means :  (determiner)\n",
      "word : (noble), type : (JJ) , means :  (adjective (English), other noun-modifier (Chinese))\n",
      "word : (dream), type : (NN) , means :  (noun, singular or mass)\n",
      "word : (.), type : (.) , means :  (punctuation mark, sentence closer)\n",
      "-----------------------------------------------\n",
      "word : (Tonight), type : (NN) , means :  (noun, singular or mass)\n",
      "word : (we), type : (PRP) , means :  (pronoun, personal)\n",
      "word : (are), type : (VBP) , means :  (verb, non-3rd person singular present)\n",
      "word : (comforted), type : (VBN) , means :  (verb, past participle)\n",
      "word : (by), type : (IN) , means :  (conjunction, subordinating or preposition)\n",
      "word : (the), type : (DT) , means :  (determiner)\n",
      "word : (hope), type : (NN) , means :  (noun, singular or mass)\n",
      "word : (of), type : (IN) , means :  (conjunction, subordinating or preposition)\n",
      "word : (a), type : (DT) , means :  (determiner)\n",
      "word : (glad), type : (JJ) , means :  (adjective (English), other noun-modifier (Chinese))\n",
      "word : (reunion), type : (NN) , means :  (noun, singular or mass)\n",
      "word : (with), type : (IN) , means :  (conjunction, subordinating or preposition)\n",
      "word : (the), type : (DT) , means :  (determiner)\n",
      "word : (husband), type : (NN) , means :  (noun, singular or mass)\n",
      "word : (who), type : (WP) , means :  (wh-pronoun, personal)\n",
      "word : (was), type : (VBD) , means :  (verb, past tense)\n",
      "word : (taken), type : (VBN) , means :  (verb, past participle)\n",
      "word : (so), type : (RB) , means :  (adverb)\n",
      "word : (long), type : (RB) , means :  (adverb)\n",
      "word : (ago), type : (RB) , means :  (adverb)\n",
      "word : (,), type : (,) , means :  (punctuation mark, comma)\n",
      "word : (and), type : (CC) , means :  (conjunction, coordinating)\n",
      "word : (we), type : (PRP) , means :  (pronoun, personal)\n",
      "word : (are), type : (VBP) , means :  (verb, non-3rd person singular present)\n",
      "word : (grateful), type : (JJ) , means :  (adjective (English), other noun-modifier (Chinese))\n",
      "word : (for), type : (IN) , means :  (conjunction, subordinating or preposition)\n",
      "word : (the), type : (DT) , means :  (determiner)\n",
      "word : (good), type : (JJ) , means :  (adjective (English), other noun-modifier (Chinese))\n",
      "word : (life), type : (NN) , means :  (noun, singular or mass)\n",
      "word : (of), type : (IN) , means :  (conjunction, subordinating or preposition)\n",
      "word : (Coretta), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (Scott), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (King), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (.), type : (.) , means :  (punctuation mark, sentence closer)\n",
      "-----------------------------------------------\n",
      "word : ((), type : (() , means :  (None)\n",
      "word : (Applause), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (.), type : (.) , means :  (punctuation mark, sentence closer)\n",
      "word : ()), type : ()) , means :  (None)\n",
      "-----------------------------------------------\n",
      "word : (President), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (George), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (W.), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (Bush), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (reacts), type : (VBZ) , means :  (verb, 3rd person singular present)\n",
      "word : (to), type : (TO) , means :  (infinitival \"to\")\n",
      "word : (applause), type : (VB) , means :  (verb, base form)\n",
      "word : (during), type : (IN) , means :  (conjunction, subordinating or preposition)\n",
      "word : (his), type : (PRP$) , means :  (pronoun, possessive)\n",
      "word : (State), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (of), type : (IN) , means :  (conjunction, subordinating or preposition)\n",
      "word : (the), type : (DT) , means :  (determiner)\n",
      "word : (Union), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (Address), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (at), type : (IN) , means :  (conjunction, subordinating or preposition)\n",
      "word : (the), type : (DT) , means :  (determiner)\n",
      "word : (Capitol), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (,), type : (,) , means :  (punctuation mark, comma)\n",
      "word : (Tuesday), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (,), type : (,) , means :  (punctuation mark, comma)\n",
      "word : (Jan), type : (NNP) , means :  (noun, proper singular)\n",
      "word : (.), type : (.) , means :  (punctuation mark, sentence closer)\n",
      "-----------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shosh\\.conda\\envs\\NLP\\lib\\site-packages\\spacy\\glossary.py:20: UserWarning: [W118] Term '(' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n",
      "c:\\Users\\shosh\\.conda\\envs\\NLP\\lib\\site-packages\\spacy\\glossary.py:20: UserWarning: [W118] Term ')' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n"
     ]
    }
   ],
   "source": [
    "# ØªØ¯Ø±ÙŠØ¨ Punkt Ø¹Ù„Ù‰ Ù†Øµ Ø±Ø¦Ø§Ø³ÙŠ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ) | Train Punkt on State of the Union (optional)\n",
    "import re\n",
    "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
    "sample_text = state_union.raw(\"2006-GWBush.txt\")\n",
    "\n",
    "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
    "tokenized = custom_sent_tokenizer.tokenize(sample_text)\n",
    "\n",
    "for i in tokenized[:5]:\n",
    "    for w , m in nltk.pos_tag(nltk.word_tokenize(i)):\n",
    "        print(f'word : ({w}), type : ({m}) , means :  ({spacy.explain(m)})')\n",
    "    print('-----------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd2db0e",
   "metadata": {},
   "source": [
    "> ğŸ” ğŸ‡¸ğŸ‡¦ **Ù…Ù‚Ø§Ø±Ù†Ø© Ø³Ø±ÙŠØ¹Ø©:** ØªØ±Ø¬Ù‘Ù… NLTK Ø§Ù„ÙˆØ³ÙˆÙ… Ø¨Ù†Ø¸Ø§Ù… Penn TreebankØŒ Ø¨ÙŠÙ†Ù…Ø§ `spacy.pos_` ØªØ¹Ø·ÙŠ Universal POS.\n",
    ">\n",
    "> ğŸ” ğŸ‡¬ğŸ‡§ **Quick compare:** NLTK uses Penn Treebank tags; `spacy.pos_` uses Universal POS.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7eccf2",
   "metadata": {},
   "source": [
    "## 6) Ù…Ø«Ø§Ù„ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (spaCy) | Arabic sample (spaCy)\n",
    "\n",
    "> âš ï¸ ğŸ‡¸ğŸ‡¦ Ø¯Ø¹Ù… Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙŠ `en_core_web_sm` Ù…Ø­Ø¯ÙˆØ¯ Ø¬Ø¯Ù‹Ø§Ø› Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ØªØ¬Ø±ÙŠØ¨ÙŠØ©.\n",
    ">\n",
    "> âš ï¸ ğŸ‡¬ğŸ‡§ Arabic support in `en_core_web_sm` is very limited; results are "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f10df0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words is   :  Ø¶Ù…Øª\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  429 === nsubj === nominal subject\n",
      "Tag is   :  15308085513773655218 === NN === noun, singular or mass\n",
      "-----------------------\n",
      "Words is   :  Ù…Ø¤Ù„ÙØ§Øª\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  428 === npadvmod === noun phrase as adverbial modifier\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠ\n",
      "POS is   :  100 === VERB === verb\n",
      "Dep is   :  8206900633647566924 === ROOT === root\n",
      "Tag is   :  17109001835818727656 === VBD === verb, past tense\n",
      "-----------------------\n",
      "Words is   :  ÙƒØªØ§Ø¨\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  416 === dobj === direct object\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ø¬Ù…Ø¹\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ÙˆØ§Ù„ØªÙØ±ÙŠÙ‚\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  \n",
      "\n",
      "POS is   :  103 === SPACE === space\n",
      "Dep is   :  414 === dep === unclassified dependent\n",
      "Tag is   :  6893682062797376370 === _SP === whitespace\n",
      "-----------------------\n",
      "Words is   :  ÙÙŠ\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  429 === nsubj === nominal subject\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ø­Ø³Ø§Ø¨\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ù‡Ù†Ø¯ÙŠ\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ØŒ\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ÙˆÙƒØªØ§Ø¨\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø±Ø³Ù…\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ø±Ø¨Ø¹\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  408 === ccomp === clausal complement\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ù…Ø¹Ù…ÙˆØ±\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ØŒ\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ÙˆÙƒØªØ§Ø¨\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ØªÙ‚ÙˆÙŠÙ…\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ø¨Ù„Ø¯Ø§Ù†\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ØŒ\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ÙˆÙƒØªØ§Ø¨\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ø¹Ù…Ù„\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  416 === dobj === direct object\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø¨Ø§Ù„Ø£Ø³Ø·Ø±Ù„Ø§Ø¨\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ØŒ\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  \n",
      "\n",
      "POS is   :  103 === SPACE === space\n",
      "Dep is   :  414 === dep === unclassified dependent\n",
      "Tag is   :  6893682062797376370 === _SP === whitespace\n",
      "-----------------------\n",
      "Words is   :  ÙˆÙƒØªØ§Ø¨\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  416 === dobj === direct object\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  \"\n",
      "POS is   :  97 === PUNCT === punctuation\n",
      "Dep is   :  445 === punct === punctuation\n",
      "Tag is   :  4969857429396651903 === `` === opening quotation mark\n",
      "-----------------------\n",
      "Words is   :  ØµÙˆØ±Ø©\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  426 === nmod === modifier of nominal\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ø£Ø±Ø¶\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  426 === nmod === modifier of nominal\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  \"\n",
      "POS is   :  97 === PUNCT === punctuation\n",
      "Dep is   :  445 === punct === punctuation\n",
      "Tag is   :  14143520107006108953 === '' === closing quotation mark\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ø°ÙŠ\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ø¹ØªÙ…Ø¯\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ÙÙŠÙ‡\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø¹Ù„Ù‰\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ÙƒØªØ§Ø¨\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  429 === nsubj === nominal subject\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ù…Ø¬Ø³Ø·ÙŠ\n",
      "POS is   :  86 === ADV === adverb\n",
      "Dep is   :  400 === advmod === adverbial modifier\n",
      "Tag is   :  164681854541413346 === RB === adverb\n",
      "-----------------------\n",
      "Words is   :  Ù„Ø¨Ø·Ù„ÙŠÙ…ÙˆØ³\n",
      "POS is   :  100 === VERB === verb\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  9188597074677201817 === VBP === verb, non-3rd person singular present\n",
      "-----------------------\n",
      "Words is   :  Ù…Ø¹\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø¥Ø¶Ø§ÙØ§Øª\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ÙˆØ´Ø±ÙˆØ­\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15308085513773655218 === NN === noun, singular or mass\n",
      "-----------------------\n",
      "Words is   :  \n",
      "\n",
      "POS is   :  103 === SPACE === space\n",
      "Dep is   :  414 === dep === unclassified dependent\n",
      "Tag is   :  6893682062797376370 === _SP === whitespace\n",
      "-----------------------\n",
      "Words is   :  ÙˆØªØ¹Ù„ÙŠÙ‚Ø§Øª\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ØŒ\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ÙˆØ£Ø¹Ø§Ø¯\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ÙƒØªØ§Ø¨Ø©\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ÙƒØªØ§Ø¨\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„ÙÙ„Ùƒ\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  426 === nmod === modifier of nominal\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ù‡Ù†Ø¯ÙŠ\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15308085513773655218 === NN === noun, singular or mass\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ù…Ø¹Ø±ÙˆÙ\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15308085513773655218 === NN === noun, singular or mass\n",
      "-----------------------\n",
      "Words is   :  Ø¨Ø§Ø³Ù…\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  429 === nsubj === nominal subject\n",
      "Tag is   :  15308085513773655218 === NN === noun, singular or mass\n",
      "-----------------------\n",
      "Words is   :  \"\n",
      "POS is   :  97 === PUNCT === punctuation\n",
      "Dep is   :  445 === punct === punctuation\n",
      "Tag is   :  4969857429396651903 === `` === opening quotation mark\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ø³Ù†Ø¯\n",
      "POS is   :  100 === VERB === verb\n",
      "Dep is   :  408 === ccomp === clausal complement\n",
      "Tag is   :  13927759927860985106 === VBZ === verb, 3rd person singular present\n",
      "-----------------------\n",
      "Words is   :  Ù‡Ù†Ø¯\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„ÙƒØ¨ÙŠØ±\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  426 === nmod === modifier of nominal\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  \"\n",
      "POS is   :  97 === PUNCT === punctuation\n",
      "Dep is   :  445 === punct === punctuation\n",
      "Tag is   :  14143520107006108953 === '' === closing quotation mark\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ø°ÙŠ\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  426 === nmod === modifier of nominal\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ØªØ±Ø¬Ù…\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15308085513773655218 === NN === noun, singular or mass\n",
      "-----------------------\n",
      "Words is   :  Ø¥Ù„Ù‰\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ù„ØºØ©\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  416 === dobj === direct object\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  \n",
      "\n",
      "POS is   :  103 === SPACE === space\n",
      "Dep is   :  414 === dep === unclassified dependent\n",
      "Tag is   :  6893682062797376370 === _SP === whitespace\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø²Ù…Ù†\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ø®Ù„ÙŠÙØ©\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ù…Ù†ØµÙˆØ±\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ÙØ£Ø¹Ø§Ø¯\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠ\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ÙƒØªØ§Ø¨ØªÙ‡\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  429 === nsubj === nominal subject\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ÙˆØ£Ø¶Ø§Ù\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  8206900633647566924 === ROOT === root\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø¥Ù„ÙŠÙ‡\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  443 === prep === prepositional modifier\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ÙˆØ³Ù…ÙŠ\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ÙƒØªØ§Ø¨Ù‡\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  429 === nsubj === nominal subject\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  \"\n",
      "POS is   :  97 === PUNCT === punctuation\n",
      "Dep is   :  445 === punct === punctuation\n",
      "Tag is   :  4969857429396651903 === `` === opening quotation mark\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ø³Ù†Ø¯\n",
      "POS is   :  100 === VERB === verb\n",
      "Dep is   :  410 === conj === conjunct\n",
      "Tag is   :  13927759927860985106 === VBZ === verb, 3rd person singular present\n",
      "-----------------------\n",
      "Words is   :  Ù‡Ù†Ø¯\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„ØµØºÙŠØ±\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  416 === dobj === direct object\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  \"\n",
      "POS is   :  97 === PUNCT === punctuation\n",
      "Dep is   :  445 === punct === punctuation\n",
      "Tag is   :  14143520107006108953 === '' === closing quotation mark\n",
      "-----------------------\n",
      "Words is   :  .\n",
      "POS is   :  97 === PUNCT === punctuation\n",
      "Dep is   :  445 === punct === punctuation\n",
      "Tag is   :  12646065887601541794 === . === punctuation mark, sentence closer\n",
      "-----------------------\n",
      "Words is   :  \n",
      "\n",
      "\n",
      "POS is   :  103 === SPACE === space\n",
      "Dep is   :  414 === dep === unclassified dependent\n",
      "Tag is   :  6893682062797376370 === _SP === whitespace\n",
      "-----------------------\n",
      "Words is   :  ÙˆÙ‚Ø¯\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15308085513773655218 === NN === noun, singular or mass\n",
      "-----------------------\n",
      "Words is   :  Ø¹Ø±Ø¶\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15308085513773655218 === NN === noun, singular or mass\n",
      "-----------------------\n",
      "Words is   :  ÙÙŠ\n",
      "POS is   :  91 === INTJ === interjection\n",
      "Dep is   :  402 === amod === adjectival modifier\n",
      "Tag is   :  3252815442139690129 === UH === interjection\n",
      "-----------------------\n",
      "Words is   :  ÙƒØªØ§Ø¨\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ù…Ø®ØªØµØ±\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  8206900633647566924 === ROOT === root\n",
      "Tag is   :  15308085513773655218 === NN === noun, singular or mass\n",
      "-----------------------\n",
      "Words is   :  ÙÙŠ\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø­Ø³Ø§Ø¨\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ø¬Ø¨Ø±\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ÙˆØ§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø©\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø£ÙˆÙ„\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø­Ù„\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ù…Ù†Ù‡Ø¬ÙŠ\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  \n",
      "\n",
      "POS is   :  103 === SPACE === space\n",
      "Dep is   :  414 === dep === unclassified dependent\n",
      "Tag is   :  6893682062797376370 === _SP === whitespace\n",
      "-----------------------\n",
      "Words is   :  Ù„Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  402 === amod === adjectival modifier\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ø®Ø·ÙŠØ©\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15308085513773655218 === NN === noun, singular or mass\n",
      "-----------------------\n",
      "Words is   :  ÙˆØ§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  403 === appos === appositional modifier\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„ØªØ±Ø¨ÙŠØ¹ÙŠØ©\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ù…Ø³ØªØ¹Ù…Ù„Ø§\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ÙÙŠ\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  8206900633647566924 === ROOT === root\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø°Ù„Ùƒ\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  429 === nsubj === nominal subject\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ø·Ø±ÙŠÙ‚Ø©\n",
      "POS is   :  100 === VERB === verb\n",
      "Dep is   :  8206900633647566924 === ROOT === root\n",
      "Tag is   :  13927759927860985106 === VBZ === verb, 3rd person singular present\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ©\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø¨Ø§Ø³Ù…\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø¥ÙƒÙ…Ø§Ù„\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ù…Ø±Ø¨Ø¹\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  416 === dobj === direct object\n",
      "Tag is   :  783433942507015291 === NNS === noun, plural\n",
      "-----------------------\n",
      "Words is   :  .\n",
      "POS is   :  97 === PUNCT === punctuation\n",
      "Dep is   :  445 === punct === punctuation\n",
      "Tag is   :  12646065887601541794 === . === punctuation mark, sentence closer\n",
      "-----------------------\n",
      "Words is   :  ÙˆÙŠØ¹ØªØ¨Ø±\n",
      "POS is   :  100 === VERB === verb\n",
      "Dep is   :  8206900633647566924 === ROOT === root\n",
      "Tag is   :  14200088355797579614 === VB === verb, base form\n",
      "-----------------------\n",
      "Words is   :  Ù…Ø¤Ø³Ø³\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø¹Ù„Ù…\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ø¬Ø¨Ø±\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  416 === dobj === direct object\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ØŒ\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  403 === appos === appositional modifier\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  \n",
      "\n",
      "POS is   :  103 === SPACE === space\n",
      "Dep is   :  414 === dep === unclassified dependent\n",
      "Tag is   :  6893682062797376370 === _SP === whitespace\n",
      "-----------------------\n",
      "Words is   :  (\n",
      "POS is   :  97 === PUNCT === punctuation\n",
      "Dep is   :  445 === punct === punctuation\n",
      "Tag is   :  17111077179131903759 === -LRB- === left round bracket\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ù„Ù‚Ø¨\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ø°ÙŠ\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ÙŠØªÙ‚Ø§Ø³Ù…Ù‡\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ù…Ø¹\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø¯ÙŠÙˆÙØ§Ù†ØªÙˆØ³\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  416 === dobj === direct object\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  )\n",
      "POS is   :  97 === PUNCT === punctuation\n",
      "Dep is   :  445 === punct === punctuation\n",
      "Tag is   :  2465883113906300949 === -RRB- === right round bracket\n",
      "-----------------------\n",
      "Words is   :  ÙÙŠ\n",
      "POS is   :  89 === CCONJ === coordinating conjunction\n",
      "Dep is   :  414 === dep === unclassified dependent\n",
      "Tag is   :  17571114184892886314 === CC === conjunction, coordinating\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ù‚Ø±Ù†\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  414 === dep === unclassified dependent\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ø«Ø§Ù†ÙŠ\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø¹Ø´Ø±\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  403 === appos === appositional modifier\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ØŒ\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ÙˆÙ„Ù‚Ø¯\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ù‚Ø¯Ù…Øª\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ØªØ±Ø¬Ù…Ø§Øª\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ù„Ø§ØªÙŠÙ†ÙŠØ©\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø¹Ù†\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø­Ø³Ø§Ø¨Ù‡\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø¹Ù„Ù‰\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  429 === nsubj === nominal subject\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ø£Ø±Ù‚Ø§Ù…\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  400 === advmod === adverbial modifier\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ù‡Ù†Ø¯ÙŠØ©\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ØŒ\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  \n",
      "\n",
      "POS is   :  103 === SPACE === space\n",
      "Dep is   :  414 === dep === unclassified dependent\n",
      "Tag is   :  6893682062797376370 === _SP === whitespace\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ù†Ø¸Ø§Ù…\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  429 === nsubj === nominal subject\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ø¹Ø´Ø±ÙŠ\n",
      "POS is   :  100 === VERB === verb\n",
      "Dep is   :  8206900633647566924 === ROOT === root\n",
      "Tag is   :  14200088355797579614 === VB === verb, base form\n",
      "-----------------------\n",
      "Words is   :  Ø¥Ù„Ù‰\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ø¹Ø§Ù„Ù…\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  416 === dobj === direct object\n",
      "Tag is   :  783433942507015291 === NNS === noun, plural\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„ØºØ±Ø¨ÙŠ\n",
      "POS is   :  84 === ADJ === adjective\n",
      "Dep is   :  400 === advmod === adverbial modifier\n",
      "Tag is   :  10554686591937588953 === JJ === adjective (English), other noun-modifier (Chinese)\n",
      "-----------------------\n",
      "Words is   :  .\n",
      "POS is   :  97 === PUNCT === punctuation\n",
      "Dep is   :  445 === punct === punctuation\n",
      "Tag is   :  12646065887601541794 === . === punctuation mark, sentence closer\n",
      "-----------------------\n",
      "Words is   :  Ù†Ù‚Ø­\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  429 === nsubj === nominal subject\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠ\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ÙƒØªØ§Ø¨\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„Ø¬ØºØ±Ø§ÙÙŠØ§\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ù„ÙƒÙ„Ø§ÙˆØ¯ÙŠÙˆØ³\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø¨Ø·Ù„ÙŠÙ…ÙˆØ³\n",
      "POS is   :  92 === NOUN === noun\n",
      "Dep is   :  416 === dobj === direct object\n",
      "Tag is   :  15308085513773655218 === NN === noun, singular or mass\n",
      "-----------------------\n",
      "Words is   :  ÙˆÙƒØªØ¨\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ÙÙŠ\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  415 === det === determiner\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø¹Ù„Ù…\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  Ø§Ù„ÙÙ„Ùƒ\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  7037928807040764755 === compound === compound\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  ÙˆØ§Ù„ØªÙ†Ø¬ÙŠÙ…\n",
      "POS is   :  96 === PROPN === proper noun\n",
      "Dep is   :  8206900633647566924 === ROOT === root\n",
      "Tag is   :  15794550382381185553 === NNP === noun, proper singular\n",
      "-----------------------\n",
      "Words is   :  .\n",
      "POS is   :  97 === PUNCT === punctuation\n",
      "Dep is   :  445 === punct === punctuation\n",
      "Tag is   :  12646065887601541794 === . === punctuation mark, sentence closer\n",
      "-----------------------\n",
      "Words is   :  \n",
      "\n",
      "POS is   :  103 === SPACE === space\n",
      "Dep is   :  414 === dep === unclassified dependent\n",
      "Tag is   :  6893682062797376370 === _SP === whitespace\n",
      "-----------------------\n",
      "Ø¶Ù…Øª          NOUN     NN     noun, singular or mass\n",
      "Ù…Ø¤Ù„ÙØ§Øª       PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠ    VERB     VBD    verb, past tense\n",
      "ÙƒØªØ§Ø¨         PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ø¬Ù…Ø¹        PROPN    NNP    noun, proper singular\n",
      "ÙˆØ§Ù„ØªÙØ±ÙŠÙ‚     PROPN    NNP    noun, proper singular\n",
      "\n",
      "            SPACE    _SP    whitespace\n",
      "ÙÙŠ           PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ø­Ø³Ø§Ø¨       PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ù‡Ù†Ø¯ÙŠ       PROPN    NNP    noun, proper singular\n",
      "ØŒ            PROPN    NNP    noun, proper singular\n",
      "ÙˆÙƒØªØ§Ø¨        PROPN    NNP    noun, proper singular\n",
      "Ø±Ø³Ù…          PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ø±Ø¨Ø¹        PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ù…Ø¹Ù…ÙˆØ±      PROPN    NNP    noun, proper singular\n",
      "ØŒ            PROPN    NNP    noun, proper singular\n",
      "ÙˆÙƒØªØ§Ø¨        PROPN    NNP    noun, proper singular\n",
      "ØªÙ‚ÙˆÙŠÙ…        PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ø¨Ù„Ø¯Ø§Ù†      PROPN    NNP    noun, proper singular\n",
      "ØŒ            PROPN    NNP    noun, proper singular\n",
      "ÙˆÙƒØªØ§Ø¨        PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ø¹Ù…Ù„        PROPN    NNP    noun, proper singular\n",
      "Ø¨Ø§Ù„Ø£Ø³Ø·Ø±Ù„Ø§Ø¨   PROPN    NNP    noun, proper singular\n",
      "ØŒ            PROPN    NNP    noun, proper singular\n",
      "\n",
      "            SPACE    _SP    whitespace\n",
      "ÙˆÙƒØªØ§Ø¨        PROPN    NNP    noun, proper singular\n",
      "\"            PUNCT    ``     opening quotation mark\n",
      "ØµÙˆØ±Ø©         PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ø£Ø±Ø¶        PROPN    NNP    noun, proper singular\n",
      "\"            PUNCT    ''     closing quotation mark\n",
      "Ø§Ù„Ø°ÙŠ         PROPN    NNP    noun, proper singular\n",
      "Ø§Ø¹ØªÙ…Ø¯        PROPN    NNP    noun, proper singular\n",
      "ÙÙŠÙ‡          PROPN    NNP    noun, proper singular\n",
      "Ø¹Ù„Ù‰          PROPN    NNP    noun, proper singular\n",
      "ÙƒØªØ§Ø¨         PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ù…Ø¬Ø³Ø·ÙŠ      ADV      RB     adverb\n",
      "Ù„Ø¨Ø·Ù„ÙŠÙ…ÙˆØ³     VERB     VBP    verb, non-3rd person singular present\n",
      "Ù…Ø¹           PROPN    NNP    noun, proper singular\n",
      "Ø¥Ø¶Ø§ÙØ§Øª       PROPN    NNP    noun, proper singular\n",
      "ÙˆØ´Ø±ÙˆØ­        NOUN     NN     noun, singular or mass\n",
      "\n",
      "            SPACE    _SP    whitespace\n",
      "ÙˆØªØ¹Ù„ÙŠÙ‚Ø§Øª     PROPN    NNP    noun, proper singular\n",
      "ØŒ            PROPN    NNP    noun, proper singular\n",
      "ÙˆØ£Ø¹Ø§Ø¯        PROPN    NNP    noun, proper singular\n",
      "ÙƒØªØ§Ø¨Ø©        PROPN    NNP    noun, proper singular\n",
      "ÙƒØªØ§Ø¨         PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„ÙÙ„Ùƒ        PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ù‡Ù†Ø¯ÙŠ       NOUN     NN     noun, singular or mass\n",
      "Ø§Ù„Ù…Ø¹Ø±ÙˆÙ      NOUN     NN     noun, singular or mass\n",
      "Ø¨Ø§Ø³Ù…         NOUN     NN     noun, singular or mass\n",
      "\"            PUNCT    ``     opening quotation mark\n",
      "Ø§Ù„Ø³Ù†Ø¯        VERB     VBZ    verb, 3rd person singular present\n",
      "Ù‡Ù†Ø¯          PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„ÙƒØ¨ÙŠØ±       PROPN    NNP    noun, proper singular\n",
      "\"            PUNCT    ''     closing quotation mark\n",
      "Ø§Ù„Ø°ÙŠ         PROPN    NNP    noun, proper singular\n",
      "ØªØ±Ø¬Ù…         NOUN     NN     noun, singular or mass\n",
      "Ø¥Ù„Ù‰          PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ù„ØºØ©        PROPN    NNP    noun, proper singular\n",
      "\n",
      "            SPACE    _SP    whitespace\n",
      "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©      PROPN    NNP    noun, proper singular\n",
      "Ø²Ù…Ù†          PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ø®Ù„ÙŠÙØ©      PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ù…Ù†ØµÙˆØ±      PROPN    NNP    noun, proper singular\n",
      "ÙØ£Ø¹Ø§Ø¯        PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠ    PROPN    NNP    noun, proper singular\n",
      "ÙƒØªØ§Ø¨ØªÙ‡       PROPN    NNP    noun, proper singular\n",
      "ÙˆØ£Ø¶Ø§Ù        PROPN    NNP    noun, proper singular\n",
      "Ø¥Ù„ÙŠÙ‡         PROPN    NNP    noun, proper singular\n",
      "ÙˆØ³Ù…ÙŠ         PROPN    NNP    noun, proper singular\n",
      "ÙƒØªØ§Ø¨Ù‡        PROPN    NNP    noun, proper singular\n",
      "\"            PUNCT    ``     opening quotation mark\n",
      "Ø§Ù„Ø³Ù†Ø¯        VERB     VBZ    verb, 3rd person singular present\n",
      "Ù‡Ù†Ø¯          PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„ØµØºÙŠØ±       PROPN    NNP    noun, proper singular\n",
      "\"            PUNCT    ''     closing quotation mark\n",
      ".            PUNCT    .      punctuation mark, sentence closer\n",
      "\n",
      "\n",
      "           SPACE    _SP    whitespace\n",
      "ÙˆÙ‚Ø¯          NOUN     NN     noun, singular or mass\n",
      "Ø¹Ø±Ø¶          NOUN     NN     noun, singular or mass\n",
      "ÙÙŠ           INTJ     UH     interjection\n",
      "ÙƒØªØ§Ø¨         PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ù…Ø®ØªØµØ±      NOUN     NN     noun, singular or mass\n",
      "ÙÙŠ           PROPN    NNP    noun, proper singular\n",
      "Ø­Ø³Ø§Ø¨         PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ø¬Ø¨Ø±        PROPN    NNP    noun, proper singular\n",
      "ÙˆØ§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø©    PROPN    NNP    noun, proper singular\n",
      "Ø£ÙˆÙ„          PROPN    NNP    noun, proper singular\n",
      "Ø­Ù„           PROPN    NNP    noun, proper singular\n",
      "Ù…Ù†Ù‡Ø¬ÙŠ        PROPN    NNP    noun, proper singular\n",
      "\n",
      "            SPACE    _SP    whitespace\n",
      "Ù„Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª    PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ø®Ø·ÙŠØ©       NOUN     NN     noun, singular or mass\n",
      "ÙˆØ§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª   PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„ØªØ±Ø¨ÙŠØ¹ÙŠØ©    PROPN    NNP    noun, proper singular\n",
      "Ù…Ø³ØªØ¹Ù…Ù„Ø§      PROPN    NNP    noun, proper singular\n",
      "ÙÙŠ           PROPN    NNP    noun, proper singular\n",
      "Ø°Ù„Ùƒ          PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ø·Ø±ÙŠÙ‚Ø©      VERB     VBZ    verb, 3rd person singular present\n",
      "Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ©     PROPN    NNP    noun, proper singular\n",
      "Ø¨Ø§Ø³Ù…         PROPN    NNP    noun, proper singular\n",
      "Ø¥ÙƒÙ…Ø§Ù„        PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ù…Ø±Ø¨Ø¹       NOUN     NNS    noun, plural\n",
      ".            PUNCT    .      punctuation mark, sentence closer\n",
      "ÙˆÙŠØ¹ØªØ¨Ø±       VERB     VB     verb, base form\n",
      "Ù…Ø¤Ø³Ø³         PROPN    NNP    noun, proper singular\n",
      "Ø¹Ù„Ù…          PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ø¬Ø¨Ø±        PROPN    NNP    noun, proper singular\n",
      "ØŒ            PROPN    NNP    noun, proper singular\n",
      "\n",
      "            SPACE    _SP    whitespace\n",
      "(            PUNCT    -LRB-  left round bracket\n",
      "Ø§Ù„Ù„Ù‚Ø¨        PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ø°ÙŠ         PROPN    NNP    noun, proper singular\n",
      "ÙŠØªÙ‚Ø§Ø³Ù…Ù‡      PROPN    NNP    noun, proper singular\n",
      "Ù…Ø¹           PROPN    NNP    noun, proper singular\n",
      "Ø¯ÙŠÙˆÙØ§Ù†ØªÙˆØ³    PROPN    NNP    noun, proper singular\n",
      ")            PUNCT    -RRB-  right round bracket\n",
      "ÙÙŠ           CCONJ    CC     conjunction, coordinating\n",
      "Ø§Ù„Ù‚Ø±Ù†        PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ø«Ø§Ù†ÙŠ       PROPN    NNP    noun, proper singular\n",
      "Ø¹Ø´Ø±          PROPN    NNP    noun, proper singular\n",
      "ØŒ            PROPN    NNP    noun, proper singular\n",
      "ÙˆÙ„Ù‚Ø¯         PROPN    NNP    noun, proper singular\n",
      "Ù‚Ø¯Ù…Øª         PROPN    NNP    noun, proper singular\n",
      "ØªØ±Ø¬Ù…Ø§Øª       PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ù„Ø§ØªÙŠÙ†ÙŠØ©    PROPN    NNP    noun, proper singular\n",
      "Ø¹Ù†           PROPN    NNP    noun, proper singular\n",
      "Ø­Ø³Ø§Ø¨Ù‡        PROPN    NNP    noun, proper singular\n",
      "Ø¹Ù„Ù‰          PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ø£Ø±Ù‚Ø§Ù…      PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ù‡Ù†Ø¯ÙŠØ©      PROPN    NNP    noun, proper singular\n",
      "ØŒ            PROPN    NNP    noun, proper singular\n",
      "\n",
      "            SPACE    _SP    whitespace\n",
      "Ø§Ù„Ù†Ø¸Ø§Ù…       PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ø¹Ø´Ø±ÙŠ       VERB     VB     verb, base form\n",
      "Ø¥Ù„Ù‰          PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ø¹Ø§Ù„Ù…       NOUN     NNS    noun, plural\n",
      "Ø§Ù„ØºØ±Ø¨ÙŠ       ADJ      JJ     adjective (English), other noun-modifier (Chinese)\n",
      ".            PUNCT    .      punctuation mark, sentence closer\n",
      "Ù†Ù‚Ø­          PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠ    PROPN    NNP    noun, proper singular\n",
      "ÙƒØªØ§Ø¨         PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„Ø¬ØºØ±Ø§ÙÙŠØ§    PROPN    NNP    noun, proper singular\n",
      "Ù„ÙƒÙ„Ø§ÙˆØ¯ÙŠÙˆØ³    PROPN    NNP    noun, proper singular\n",
      "Ø¨Ø·Ù„ÙŠÙ…ÙˆØ³      NOUN     NN     noun, singular or mass\n",
      "ÙˆÙƒØªØ¨         PROPN    NNP    noun, proper singular\n",
      "ÙÙŠ           PROPN    NNP    noun, proper singular\n",
      "Ø¹Ù„Ù…          PROPN    NNP    noun, proper singular\n",
      "Ø§Ù„ÙÙ„Ùƒ        PROPN    NNP    noun, proper singular\n",
      "ÙˆØ§Ù„ØªÙ†Ø¬ÙŠÙ…     PROPN    NNP    noun, proper singular\n",
      ".            PUNCT    .      punctuation mark, sentence closer\n",
      "\n",
      "            SPACE    _SP    whitespace\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc1 = nlp('''Ø¶Ù…Øª Ù…Ø¤Ù„ÙØ§Øª Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠ ÙƒØªØ§Ø¨ Ø§Ù„Ø¬Ù…Ø¹ ÙˆØ§Ù„ØªÙØ±ÙŠÙ‚\n",
    "ÙÙŠ Ø§Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ù‡Ù†Ø¯ÙŠØŒ ÙˆÙƒØªØ§Ø¨ Ø±Ø³Ù… Ø§Ù„Ø±Ø¨Ø¹ Ø§Ù„Ù…Ø¹Ù…ÙˆØ±ØŒ ÙˆÙƒØªØ§Ø¨ ØªÙ‚ÙˆÙŠÙ… Ø§Ù„Ø¨Ù„Ø¯Ø§Ù†ØŒ ÙˆÙƒØªØ§Ø¨ Ø§Ù„Ø¹Ù…Ù„ Ø¨Ø§Ù„Ø£Ø³Ø·Ø±Ù„Ø§Ø¨ØŒ \n",
    "ÙˆÙƒØªØ§Ø¨ \"ØµÙˆØ±Ø© Ø§Ù„Ø£Ø±Ø¶ \" Ø§Ù„Ø°ÙŠ Ø§Ø¹ØªÙ…Ø¯ ÙÙŠÙ‡ Ø¹Ù„Ù‰ ÙƒØªØ§Ø¨ Ø§Ù„Ù…Ø¬Ø³Ø·ÙŠ Ù„Ø¨Ø·Ù„ÙŠÙ…ÙˆØ³ Ù…Ø¹ Ø¥Ø¶Ø§ÙØ§Øª ÙˆØ´Ø±ÙˆØ­\n",
    "ÙˆØªØ¹Ù„ÙŠÙ‚Ø§ØªØŒ ÙˆØ£Ø¹Ø§Ø¯ ÙƒØªØ§Ø¨Ø© ÙƒØªØ§Ø¨ Ø§Ù„ÙÙ„Ùƒ Ø§Ù„Ù‡Ù†Ø¯ÙŠ Ø§Ù„Ù…Ø¹Ø±ÙˆÙ Ø¨Ø§Ø³Ù… \"Ø§Ù„Ø³Ù†Ø¯ Ù‡Ù†Ø¯ Ø§Ù„ÙƒØ¨ÙŠØ±\" Ø§Ù„Ø°ÙŠ ØªØ±Ø¬Ù… Ø¥Ù„Ù‰ Ø§Ù„Ù„ØºØ©\n",
    "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø²Ù…Ù† Ø§Ù„Ø®Ù„ÙŠÙØ© Ø§Ù„Ù…Ù†ØµÙˆØ± ÙØ£Ø¹Ø§Ø¯ Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠ ÙƒØªØ§Ø¨ØªÙ‡ ÙˆØ£Ø¶Ø§Ù Ø¥Ù„ÙŠÙ‡ ÙˆØ³Ù…ÙŠ ÙƒØªØ§Ø¨Ù‡ \"Ø§Ù„Ø³Ù†Ø¯ Ù‡Ù†Ø¯ Ø§Ù„ØµØºÙŠØ±\".\n",
    "\n",
    "ÙˆÙ‚Ø¯ Ø¹Ø±Ø¶ ÙÙŠ ÙƒØªØ§Ø¨ Ø§Ù„Ù…Ø®ØªØµØ± ÙÙŠ Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¬Ø¨Ø± ÙˆØ§Ù„Ù…Ù‚Ø§Ø¨Ù„Ø© Ø£ÙˆÙ„ Ø­Ù„ Ù…Ù†Ù‡Ø¬ÙŠ\n",
    "Ù„Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ø§Ù„Ø®Ø·ÙŠØ© ÙˆØ§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø§Øª Ø§Ù„ØªØ±Ø¨ÙŠØ¹ÙŠØ© Ù…Ø³ØªØ¹Ù…Ù„Ø§ ÙÙŠ Ø°Ù„Ùƒ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ© Ø¨Ø§Ø³Ù… Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„Ù…Ø±Ø¨Ø¹. ÙˆÙŠØ¹ØªØ¨Ø± Ù…Ø¤Ø³Ø³ Ø¹Ù„Ù… Ø§Ù„Ø¬Ø¨Ø±ØŒ\n",
    "(Ø§Ù„Ù„Ù‚Ø¨ Ø§Ù„Ø°ÙŠ ÙŠØªÙ‚Ø§Ø³Ù…Ù‡ Ù…Ø¹ Ø¯ÙŠÙˆÙØ§Ù†ØªÙˆØ³) ÙÙŠ Ø§Ù„Ù‚Ø±Ù† Ø§Ù„Ø«Ø§Ù†ÙŠ Ø¹Ø´Ø±ØŒ ÙˆÙ„Ù‚Ø¯ Ù‚Ø¯Ù…Øª ØªØ±Ø¬Ù…Ø§Øª Ø§Ù„Ù„Ø§ØªÙŠÙ†ÙŠØ© Ø¹Ù† Ø­Ø³Ø§Ø¨Ù‡ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù‡Ù†Ø¯ÙŠØ©ØŒ \n",
    "Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø¹Ø´Ø±ÙŠ Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø§Ù„Ù… Ø§Ù„ØºØ±Ø¨ÙŠ. Ù†Ù‚Ø­ Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠ ÙƒØªØ§Ø¨ Ø§Ù„Ø¬ØºØ±Ø§ÙÙŠØ§ Ù„ÙƒÙ„Ø§ÙˆØ¯ÙŠÙˆØ³ Ø¨Ø·Ù„ÙŠÙ…ÙˆØ³ ÙˆÙƒØªØ¨ ÙÙŠ Ø¹Ù„Ù… Ø§Ù„ÙÙ„Ùƒ ÙˆØ§Ù„ØªÙ†Ø¬ÙŠÙ….\n",
    "''')\n",
    "\n",
    "# Ø¹Ø±Ø¶ Ø§Ù„Ø®ØµØ§Ø¦Øµ Ù„ÙƒÙ„ ØªÙˆÙƒÙ† (ØªÙ‚Ø±ÙŠØ¨ÙŠ)\n",
    "# Show per-token properties (approximate)\n",
    "for token in doc1:\n",
    "    print('Words is   : ' , token.text)\n",
    "    print('POS is   : ' , token.pos ,'===',token.pos_  , '===', spacy.explain(token.pos_))\n",
    "    print('Dep is   : ' , token.dep , '===',token.dep_, '===', spacy.explain(token.dep_))\n",
    "    print('Tag is   : ' , token.tag , '===',token.tag_, '===', spacy.explain(token.tag_))\n",
    "    print('-----------------------')\n",
    "\n",
    "# ØªÙ†Ø³ÙŠÙ‚ ØµÙÙ‘ÙŠ Ø¹Ø±Ø¨ÙŠ (ØªÙ‚Ø±ÙŠØ¨ÙŠ)\n",
    "# Pretty row print (approximate for Arabic)\n",
    "for token in doc1:\n",
    "    print(f'{token.text:{12}} {token.pos_:{8}} {token.tag_:{6}} {spacy.explain(token.tag_)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a10853",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "## 7) ØªØ°ÙƒÙŠØ± Ù…Ù‡Ù… | Important reminder\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ **POS â‰  Ø«Ø§Ø¨Øª Ù„Ù„ÙƒÙ„Ù…Ø©** â€” Ù†ÙØ³ Ø§Ù„ÙƒÙ„Ù…Ø© Ù‚Ø¯ ØªØªØ¨Ø¯Ù‘Ù„ ÙˆØ³ÙˆÙ…Ù‡Ø§ Ø­Ø³Ø¨ Ø§Ù„Ø³ÙŠØ§Ù‚.\n",
    "> ğŸ‡¬ğŸ‡§ **POS is not fixed per word** â€” the same token can receive different tags based on context.\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¯Ù‚Ù‘Ø©: Ø±Ø§Ù‚Ø¨ Ø³ÙŠØ§Ù‚ Ø§Ù„ÙƒÙ„Ù…Ø©ØŒ Ø§Ù„Ø­Ø±ÙˆÙ Ø§Ù„ÙƒØ¨ÙŠØ±Ø©/Ø§Ù„ØµØºÙŠØ±Ø©ØŒ Ø§Ù„Ù„ÙˆØ§Ø­Ù‚ ÙˆØ§Ù„Ø³Ø§Ø¨Ù‚Ø©ØŒ ÙˆØ¬ÙˆØ¯ Ø£Ø±Ù‚Ø§Ù…â€¦\n",
    "> ğŸ‡¬ğŸ‡§ To improve accuracy: consider context, casing, prefixes/suffixes, numbers, etc.\n",
    "\n",
    "---\n",
    "\n",
    "## 8) Ø±ÙˆØ§Ø¨Ø· Ù…Ø±Ø¬Ø¹ÙŠØ© | Reference\n",
    "\n",
    "* spaCy POS Tagging: [https://spacy.io/api/annotation#pos-tagging](https://spacy.io/api/annotation#pos-tagging)\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Ø®Ù„Ø§ØµØ© Ø³Ø±ÙŠØ¹Ø© | Quick wrap-up\n",
    "\n",
    "* ğŸ‡¸ğŸ‡¦ Ø§Ø³ØªØ®Ø¯Ù… `pos_` Ù„Ù„ØµÙ†Ù Ø§Ù„Ø¹Ø§Ù… Ùˆ`tag_` Ù„Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©ØŒ Ùˆ`dep_` Ù„Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ù†Ø­ÙˆÙŠØ©.\n",
    "* ğŸ‡¬ğŸ‡§ Use `pos_` for coarse tags, `tag_` for fine-grained details, and `dep_` for syntactic relations.\n",
    "\n",
    "---\n",
    "\n",
    "### âš™ï¸ Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨ÙŠÙ† `pos_` Ùˆ `tag_` Ùˆ `dep_`\n",
    "\n",
    "| Ø§Ù„Ø®Ø§ØµÙŠØ© | ğŸ‡¸ğŸ‡¦ Ø§Ù„Ù…Ø¹Ù†Ù‰ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ | ğŸ‡¬ğŸ‡§ Ø§Ù„Ù…Ø¹Ù†Ù‰ Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© | ğŸ‡¸ğŸ‡¦ Ù…Ø§Ø°Ø§ ØªØµÙØŸ / ğŸ‡¬ğŸ‡§ What it describes            | ğŸ§  Ù…Ø«Ø§Ù„                                                                     |\n",
    "| ------- | ------------------- | ----------------------- | -------------------------------------------------- | --------------------------------------------------------------------------- |\n",
    "| `pos_`  | Ø§Ù„Ù†ÙˆØ¹ Ø§Ù„Ø¹Ø§Ù… Ù„Ù„ÙƒÙ„Ù…Ø©  | Coarse Part of Speech   | ØªØµÙ†ÙŠÙ Ø§Ù„ÙƒÙ„Ù…Ø© Ø¶Ù…Ù† Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„ÙƒØ¨Ø±Ù‰ Ù…Ø«Ù„ Ø§Ø³Ù… / ÙØ¹Ù„ / ØµÙØ© | `NOUN`, `VERB`, `ADJ`, `ADV`, `PRON`                                        |\n",
    "| `tag_`  | Ø§Ù„Ù†ÙˆØ¹ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ      | Fine-grained POS Tag    | ÙŠØ¶ÙŠÙ ØªÙØ§ØµÙŠÙ„ ØµØ±ÙÙŠØ© Ù…Ø«Ù„ Ø§Ù„Ø²Ù…Ù† Ø£Ùˆ Ø§Ù„Ø¹Ø¯Ø¯ Ø£Ùˆ Ø§Ù„Ø­Ø§Ù„Ø©     | `NN` (Ø§Ø³Ù… Ù…ÙØ±Ø¯), `NNS` (Ø¬Ù…Ø¹), `VBD` (ÙØ¹Ù„ Ù…Ø§Ø¶Ù), `VBP` (Ù…Ø¶Ø§Ø±Ø¹)               |\n",
    "| `dep_`  | Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø§Ù„Ù†Ø­ÙˆÙŠØ©     | Syntactic Dependency    | ÙŠÙˆØ¶Ø­ Ø¹Ù„Ø§Ù‚Ø© Ø§Ù„ÙƒÙ„Ù…Ø© Ø¨ØºÙŠØ±Ù‡Ø§ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø¬Ù…Ù„Ø©               | `nsubj` (ÙØ§Ø¹Ù„), `dobj` (Ù…ÙØ¹ÙˆÙ„ Ø¨Ù‡), `prep` (Ø­Ø±Ù Ø¬Ø±), `amod` (ØµÙØ© ØªØ§Ø¨Ø¹Ø© Ù„Ø§Ø³Ù…) |\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### ğŸ§© Ù…Ø«Ø§Ù„ ØªÙˆØ¶ÙŠØ­ÙŠ\n",
    "\n",
    "**Ø§Ù„Ø¬Ù…Ù„Ø©:**\n",
    "\n",
    "> ğŸ± *The cat eats fish.*\n",
    "\n",
    "| Ø§Ù„ÙƒÙ„Ù…Ø© | `pos_` (Ø§Ù„Ù†ÙˆØ¹ Ø§Ù„Ø¹Ø§Ù…) | `tag_` (Ø§Ù„Ù†ÙˆØ¹ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ)     | `dep_` (Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø§Ù„Ù†Ø­ÙˆÙŠØ©) |\n",
    "| ------ | -------------------- | --------------------------- | ------------------------ |\n",
    "| The    | DET (Ø£Ø¯Ø§Ø© ØªØ¹Ø±ÙŠÙ)     | DT (determiner)             | det (ØªØ­Ø¯Ø¯ Ø§Ù„Ø§Ø³Ù…)         |\n",
    "| cat    | NOUN (Ø§Ø³Ù…)           | NN (Ø§Ø³Ù… Ù…ÙØ±Ø¯)               | nsubj (ÙØ§Ø¹Ù„)             |\n",
    "| eats   | VERB (ÙØ¹Ù„)           | VBZ (ÙØ¹Ù„ Ù…Ø¶Ø§Ø±Ø¹ â€“ Ù…ÙØ±Ø¯ ØºØ§Ø¦Ø¨) | ROOT (Ø§Ù„ÙØ¹Ù„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ)     |\n",
    "| fish   | NOUN (Ø§Ø³Ù…)           | NN (Ø§Ø³Ù… Ù…ÙØ±Ø¯)               | dobj (Ù…ÙØ¹ÙˆÙ„ Ø¨Ù‡)          |\n",
    "\n",
    "\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ Ù†Ø±Ù‰ Ø£Ù† `pos_` ÙŠØµÙ Ù†ÙˆØ¹ Ø§Ù„ÙƒÙ„Ù…Ø© Ø¨Ø´ÙƒÙ„ Ø¹Ø§Ù…ØŒ Ùˆ`tag_` ÙŠØ¶ÙŠÙ ØªÙØ§ØµÙŠÙ„ ØµØ±ÙÙŠØ© (Ù…Ø«Ù„ Ø§Ù„Ø²Ù…Ù† Ø£Ùˆ Ø§Ù„Ø¹Ø¯Ø¯)ØŒ Ùˆ`dep_` ÙŠÙˆØ¶Ø­ Ø¹Ù„Ø§Ù‚Ø© Ø§Ù„ÙƒÙ„Ù…Ø© Ø¨ØºÙŠØ±Ù‡Ø§ ÙÙŠ Ø§Ù„Ø¬Ù…Ù„Ø©.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ As shown, `pos_` gives the general part of speech, `tag_` adds grammatical detail (like tense or number), and `dep_` shows how the word relates to others in the sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcac740",
   "metadata": {},
   "source": [
    "## ğŸ§© Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ø±Ø§Ø¨Ø¹ | Part 4 : Stemming & Lemmatization   \n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§  Ø§Ù„Ù…Ù‚Ø¯Ù‘Ù…Ø© | Introduction\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ **Ø§Ù„ØªØ¬Ø°ÙŠØ± (Stemming)** Ùˆ **Ø§Ù„Ø¥Ø±Ø¬Ø§Ø¹ Ù„Ù„Ù…ØµØ¯Ø± (Lemmatization)** Ù‡Ù…Ø§ Ø¹Ù…Ù„ÙŠØªØ§Ù† Ø£Ø³Ø§Ø³ÙŠØªØ§Ù† ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© (NLP).\n",
    "> Ø§Ù„ØºØ±Ø¶ Ù…Ù†Ù‡Ù…Ø§ Ù‡Ùˆ **ØªÙ‚Ù„ÙŠÙ„ ØªÙ†ÙˆØ¹ Ø§Ù„ÙƒÙ„Ù…Ø§Øª** Ø¨Ø¥Ø±Ø¬Ø§Ø¹Ù‡Ø§ Ø¥Ù„Ù‰ Ø£ØµÙ„ ÙˆØ§Ø­Ø¯ ÙŠÙ…Ø«Ù„ Ù…Ø¹Ù†Ø§Ù‡Ø§ Ø§Ù„Ø¬ÙˆÙ‡Ø±ÙŠ.\n",
    "> Ù…Ø«Ù„Ù‹Ø§:\n",
    ">\n",
    "> * (run, running, ran, runs) â†’ **run**\n",
    "> * (ÙƒØªØ¨ØŒ ÙƒØ§ØªØ¨ØŒ Ù…ÙƒØªÙˆØ¨ØŒ ÙƒØªØ§Ø¨Ø©) â†’ **ÙƒØªØ¨**\n",
    "\n",
    "> ğŸ‡¬ğŸ‡§ **Stemming** and **Lemmatization** are core preprocessing steps in NLP.\n",
    "> Their purpose is to **reduce word variations** to a single, meaningful base form.\n",
    "> For example:\n",
    ">\n",
    "> * (run, running, ran, runs) â†’ **run**\n",
    "> * (ÙƒØªØ¨ØŒ ÙƒØ§ØªØ¨ØŒ Ù…ÙƒØªÙˆØ¨ØŒ ÙƒØªØ§Ø¨Ø©) â†’ **ÙƒØªØ¨**\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“˜ ğŸ‡¸ğŸ‡¦ Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† Ø§Ù„ØªØ¬Ø°ÙŠØ± ÙˆØ§Ù„Ø¥Ø±Ø¬Ø§Ø¹ Ù„Ù„Ù…ØµØ¯Ø±\n",
    "\n",
    "### ğŸ“˜ ğŸ‡¬ğŸ‡§ Difference Between Stemming and Lemmatization\n",
    "\n",
    "| Ø§Ù„Ù…ÙÙ‡ÙˆÙ… (Concept)              | ğŸ‡¸ğŸ‡¦ Ø§Ù„ØªØ¬Ø°ÙŠØ± (Stemming)                                                                       | ğŸ‡¬ğŸ‡§ Ø§Ù„Ø¥Ø±Ø¬Ø§Ø¹ Ù„Ù„Ù…ØµØ¯Ø± (Lemmatization)                               |\n",
    "| ------------------------------ | --------------------------------------------------------------------------------------------- | ----------------------------------------------------------------- |\n",
    "| Ø§Ù„ÙÙƒØ±Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© / Core Idea    | Ø­Ø°Ù Ø§Ù„Ù„ÙˆØ§Ø­Ù‚ ÙˆØ§Ù„Ø²ÙˆØ§Ø¦Ø¯ Ø¯ÙˆÙ† ÙÙ‡Ù… Ø§Ù„Ù…Ø¹Ù†Ù‰ â€“ Removes prefixes/suffixes without understanding meaning | ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ ÙˆØ§Ù„Ù…Ø¹Ø§Ù†ÙŠ Ø§Ù„Ù„ØºÙˆÙŠØ© â€“ Based on grammar and meaning |\n",
    "| Ø§Ù„Ø¯Ù‚Ø© / Accuracy               | Ø³Ø±ÙŠØ¹Ø© Ù„ÙƒÙ†Ù‡Ø§ ØºÙŠØ± Ø¯Ù‚ÙŠÙ‚Ø© â€“ Fast but less accurate                                                | Ø£Ø¨Ø·Ø£ Ù„ÙƒÙ†Ù‡Ø§ Ø£Ø¯Ù‚ â€“ Slower but more precise                          |\n",
    "| ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ / Based on           | Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø´ÙƒÙ„ÙŠØ© (Rules) â€“ Form-based rules                                                    | Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù†Ø­ÙˆÙŠØ© + Ø§Ù„Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„Ù„ØºÙˆÙŠ â€“ Grammar + lexical dictionary   |\n",
    "| Ù…Ø«Ø§Ù„ Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ / English Example | â€œstudiesâ€ â†’ â€œstudiâ€ âŒ                                                                         | â€œstudiesâ€ â†’ â€œstudyâ€ âœ…                                             |\n",
    "| Ù…Ø«Ø§Ù„ Ø¹Ø±Ø¨ÙŠ / Arabic Example     | â€œÙŠÙƒØªØ¨ÙˆÙ†â€ â†’ â€œÙŠÙƒØªØ¨â€ âœ…                                                                           | â€œÙ…ÙƒØªÙˆØ¨â€ â†’ â€œÙƒØªØ¨â€ âœ… (Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…Ø¹Ù†Ù‰ / meaning-aware)                  |\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ Ø¨Ø§Ø®ØªØµØ§Ø±: Ø§Ù„Ù€ **Stemming** ÙŠÙ‚ØµÙ‘ Ø§Ù„ÙƒÙ„Ù…Ø©ØŒ Ø¨ÙŠÙ†Ù…Ø§ **Lemmatization** ÙŠÙÙ‡Ù…Ù‡Ø§.\n",
    "> ğŸ‡¬ğŸ‡§ In short: **Stemming** cuts words, while **Lemmatization** understands them.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§­ ğŸ‡¸ğŸ‡¦ Ù„Ù…Ø§Ø°Ø§ Ù†Ø³ØªØ®Ø¯Ù…Ù‡Ø§ØŸ | ğŸ‡¬ğŸ‡§ Why Do We Use Them?\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµØŒ Ù‚Ø¯ ØªØ¸Ù‡Ø± Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„ÙˆØ§Ø­Ø¯Ø© Ø¨Ø¹Ø¯Ø© Ø£Ø´ÙƒØ§Ù„ (Ø¬Ù…Ø¹ØŒ Ù…Ø§Ø¶ÙŠØŒ Ù…Ø¶Ø§Ø±Ø¹...).\n",
    "> Ø¨Ø¯ÙˆÙ† ØªØ¬Ø°ÙŠØ± Ø£Ùˆ Ø¥Ø±Ø¬Ø§Ø¹ Ù„Ù„Ù…ØµØ¯Ø±ØŒ ØªØ¹ØªØ¨Ø± Ø§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© ÙƒÙ„ Ø´ÙƒÙ„ ÙƒÙƒÙ„Ù…Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù…Ø®ØªÙ„ÙØ© â€” Ù…Ù…Ø§ ÙŠØ¤Ø¯ÙŠ Ø¥Ù„Ù‰ ØªØ¶Ø®ÙŠÙ… Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª (Vocabulary Explosion).\n",
    "> Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ØªØ¬Ø°ÙŠØ±ØŒ Ù†Ù‚Ù„Ù„ Ø§Ù„ØªÙƒØ±Ø§Ø± ÙˆÙ†Ø­Ø³Ù‘Ù† Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ© ÙˆÙ„ØºØ§Øª Ø§Ù„ØªØ¹Ù„Ù‘Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ In text analysis, the same concept may appear in many surface forms (plural, tense, etc.).\n",
    "> Without normalization, the model treats each as a different word, inflating the vocabulary.\n",
    "> Stemming/Lemmatization reduces redundancy and improves accuracy in NLP models.\n",
    "\n",
    "---\n",
    "\n",
    "### âš™ï¸ ğŸ‡¸ğŸ‡¦ Ø®Ø·ÙˆØ§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙŠØ© Ø§Ù„Ù…Ø±ØªØ¨Ø·Ø© Ø¨Ù‡Ø§ | ğŸ‡¬ğŸ‡§ Text Normalization Workflow\n",
    "\n",
    "| Ø§Ù„Ø®Ø·ÙˆØ©                           | ğŸ‡¸ğŸ‡¦ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©                               | ğŸ‡¬ğŸ‡§ English                              |\n",
    "| -------------------------------- | ------------------------------------------- | ----------------------------------------- |\n",
    "| 1ï¸âƒ£ **Normalization**            | Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø±Ù…ÙˆØ² ÙˆØ§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø²Ø§Ø¦Ø¯Ø© ÙˆØªÙˆØ­ÙŠØ¯ Ø§Ù„ÙƒØªØ§Ø¨Ø© | Remove extra symbols and unify formatting |\n",
    "| 2ï¸âƒ£ **Case Folding**             | ØªØ­ÙˆÙŠÙ„ ÙƒÙ„ Ø§Ù„Ù†Øµ Ù„Ø­Ø±ÙˆÙ ØµØºÙŠØ±Ø© (small letters)   | Convert text to lowercase                 |\n",
    "| 3ï¸âƒ£ **Tokenization**             | ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª Ø£Ùˆ Ø¬Ù…Ù„                 | Split text into words/sentences           |\n",
    "| 4ï¸âƒ£ **Stemming / Lemmatization** | Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„ÙƒÙ„Ù…Ø© Ø¥Ù„Ù‰ Ø£ØµÙ„Ù‡Ø§ Ø£Ùˆ Ø¬Ø°Ø±Ù‡Ø§             | Reduce words to their base/root form      |\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¬ ğŸ‡¸ğŸ‡¦ Ø§Ù„ØªØ·ÙˆÙ‘Ø± ÙÙŠ 2025 | ğŸ‡¬ğŸ‡§ Progress as of 2025\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦\n",
    "> Ø®Ù„Ø§Ù„ Ø§Ù„Ø³Ù†ÙˆØ§Øª Ø§Ù„Ø£Ø®ÙŠØ±Ø©ØŒ ØªØ·ÙˆÙ‘Ø±Øª Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù€ **Lemmatization** Ø¨Ø´ÙƒÙ„ ÙƒØ¨ÙŠØ± Ø¨ÙØ¶Ù„ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø¹Ù…ÙŠÙ‚Ø© Ù…Ø«Ù„ **spaCy v3+**ØŒ\n",
    "> ÙˆØ¯Ù…Ø¬ ØªÙ‚Ù†ÙŠØ§Øª **Transformers** Ù…Ø«Ù„ **BERT Lemmatizer** Ùˆ**CamemBERT** Ùˆ**AraBERT** Ù„Ù„ØºØ§Øª ØºÙŠØ± Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©.\n",
    "> Ù‡Ø°Ù‡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø£ØµØ¨Ø­Øª ØªÙÙ‡Ù… **Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ**ØŒ ÙØªØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„ÙƒÙ„Ù…Ø© ÙˆÙÙ‚ Ù…Ø¹Ù†Ø§Ù‡Ø§ ÙÙŠ Ø§Ù„Ø¬Ù…Ù„Ø©.\n",
    ">\n",
    "> Ø¹Ù„Ù‰ Ø³Ø¨ÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„ØŒ ÙƒÙ„Ù…Ø© *â€œmeetingâ€* ÙÙŠ Ø¬Ù…Ù„Ø© *â€œI am meeting Johnâ€* ØªÙÙÙ‡Ù… ÙƒÙ€ **ÙØ¹Ù„** (meet)ØŒ\n",
    "> Ø¨ÙŠÙ†Ù…Ø§ ÙÙŠ *â€œThe meeting was longâ€* ØªÙÙÙ‡Ù… ÙƒÙ€ **Ø§Ø³Ù…** (meeting).\n",
    ">\n",
    "> Ø£Ù…Ø§ ÙÙŠ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©ØŒ ÙÙ‚Ø¯ Ø¨Ø±Ø²Øª Ø£Ø¯ÙˆØ§Øª Ù…Ø«Ù„ **CAMeL Tools** Ùˆ**Farasa Lemmatizer** Ùˆ**AraMorph**ØŒ\n",
    "> ÙˆÙ…Ø¹ Ø¹Ø§Ù… 2025 Ø£ØµØ¨Ø­Øª Ù‚Ø§Ø¯Ø±Ø© Ø¹Ù„Ù‰ ØªØ­Ù‚ÙŠÙ‚ Ø¯Ù‚Ù‘Ø© ØªØªØ¬Ø§ÙˆØ² **90%** ÙÙŠ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø±Ø³Ù…ÙŠØ©.\n",
    "\n",
    "> ğŸ‡¬ğŸ‡§\n",
    "> In recent years, **lemmatization tools** have improved thanks to **deep learning models** like **spaCy v3+**,\n",
    "> and **transformer-based lemmatizers** such as **BERT Lemmatizer** and **AraBERT** for non-English languages.\n",
    "> These models understand **context**, distinguishing between parts of speech dynamically.\n",
    ">\n",
    "> For example, *â€œmeetingâ€* â†’ *meet* (verb) in â€œI am meeting Johnâ€,\n",
    "> but *â€œmeetingâ€* â†’ *meeting* (noun) in â€œThe meeting was long.â€\n",
    ">\n",
    "> Arabic lemmatization has also advanced with tools like **CAMeL Tools** and **Farasa**,\n",
    "> achieving over **90% accuracy** on Modern Standard Arabic (MSA) text.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§© ğŸ‡¸ğŸ‡¦ Ø®Ù„Ø§ØµØ© ØªÙ…Ù‡ÙŠØ¯ÙŠØ© | ğŸ‡¬ğŸ‡§ Summary Before Code\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ **Ø¨Ø§Ø®ØªØµØ§Ø±:**\n",
    "> Ø§Ù„ØªØ¬Ø°ÙŠØ± ÙˆØ§Ù„Ø¥Ø±Ø¬Ø§Ø¹ Ù„Ù„Ù…ØµØ¯Ø± Ù‡Ù…Ø§ Ø¬Ø²Ø¡ Ù…Ù† Ù…Ø±Ø­Ù„Ø© ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ ÙˆØªØ­Ø¶ÙŠØ±Ù‡Ø§ Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù„ØºÙˆÙŠØ©.\n",
    "> Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ†Ù‡Ù…Ø§ Ø£Ù† Ø§Ù„ØªØ¬Ø°ÙŠØ± Ø³Ø±ÙŠØ¹ ÙˆØºÙŠØ± Ø¯Ù‚ÙŠÙ‚ØŒ Ø£Ù…Ø§ Ø§Ù„Ø¥Ø±Ø¬Ø§Ø¹ Ù„Ù„Ù…ØµØ¯Ø± ÙÙ‡Ùˆ Ø£Ø¨Ø·Ø£ Ù„ÙƒÙ†Ù‡ ÙŠÙÙ‡Ù… Ø§Ù„Ù…Ø¹Ù†Ù‰ ÙˆÙŠÙØ³ØªØ®Ø¯Ù… ÙÙŠ Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø°ÙƒÙŠØ© Ø§Ù„Ø­Ø¯ÙŠØ«Ø©.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ **In short:**\n",
    "> Stemming and Lemmatization are crucial for cleaning and normalizing text before NLP modeling.\n",
    "> Stemming is fast but shallow; Lemmatization is slower but semantically aware and widely used in modern AI systems.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e1d0263a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run --> run\n",
      "runner --> runner\n",
      "running --> run\n",
      "ran --> ran\n",
      "runs --> run\n",
      "easily --> easili\n",
      "fairly --> fairli\n"
     ]
    }
   ],
   "source": [
    "# Import NLTK and use Porter Stemmer to find word stems\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "p_stemmer = PorterStemmer()\n",
    "words = ['run','runner','running','ran','runs','easily','fairly']\n",
    "\n",
    "for word in words:\n",
    "    print(word + ' --> ' + p_stemmer.stem(word))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed6bec9",
   "metadata": {},
   "source": [
    "Some words are correctly stemmed, while others lose proper endings due to rule-based trimming.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "43f55c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run --> run\n",
      "runner --> runner\n",
      "running --> run\n",
      "ran --> ran\n",
      "runs --> run\n",
      "easily --> easili\n",
      "fairly --> fair\n"
     ]
    }
   ],
   "source": [
    "# Using Snowball Stemmer for improved English stemming accuracy\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "s_stemmer = SnowballStemmer(language='english')\n",
    "words = ['run','runner','running','ran','runs','easily','fairly']\n",
    "\n",
    "for word in words:\n",
    "    print(word + ' --> ' + s_stemmer.stem(word))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2b8783",
   "metadata": {},
   "source": [
    "> Notice that â€œfairlyâ€ is now properly reduced to â€œfairâ€.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39977379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generous --> generous\n",
      "generous --> gener\n",
      "---------------------------------------\n",
      "generation --> generat\n",
      "generation --> gener\n",
      "---------------------------------------\n",
      "generously --> generous\n",
      "generously --> gener\n",
      "---------------------------------------\n",
      "generate --> generat\n",
      "generate --> gener\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Compare the stemming results between Porter and Snowball Stemmer\n",
    "\n",
    "words = ['generous','generation','generously','generate']\n",
    "\n",
    "for word in words:\n",
    "    print(word + ' --> ' + s_stemmer.stem(word))\n",
    "    print(word + ' --> ' + p_stemmer.stem(word))\n",
    "    print('---------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe68ef",
   "metadata": {},
   "source": [
    "> Snowball preserves meaning better, while Porter sometimes overcuts the stem.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "99fe8a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¹ Porter Stemmer Results:\n",
      "Word: is         --> is\n",
      "Word: was        --> wa\n",
      "Word: be         --> be\n",
      "Word: been       --> been\n",
      "Word: are        --> are\n",
      "Word: were       --> were\n",
      "\n",
      "ğŸ”¹ Lancaster Stemmer Results:\n",
      "Word: is         --> is\n",
      "Word: was        --> was\n",
      "Word: be         --> be\n",
      "Word: been       --> been\n",
      "Word: are        --> ar\n",
      "Word: were       --> wer\n"
     ]
    }
   ],
   "source": [
    "# Comparing two different Stemmers in NLTK\n",
    "\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "ps = PorterStemmer()\n",
    "ls = LancasterStemmer()\n",
    "\n",
    "words = [\"is\",\"was\",\"be\",\"been\",\"are\",\"were\"]\n",
    "\n",
    "print(\"ğŸ”¹ Porter Stemmer Results:\")\n",
    "for w in words:\n",
    "    print(f'Word: {w:10} --> {ps.stem(w)}')\n",
    "\n",
    "print(\"\\nğŸ”¹ Lancaster Stemmer Results:\")\n",
    "for w in words:\n",
    "    print(f'Word: {w:10} --> {ls.stem(w)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de6ed87",
   "metadata": {},
   "source": [
    "> Lancaster is more aggressive than Porter, trimming too much sometimes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "871d6487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "had        --> had\n",
      "you        --> you\n",
      "booked     --> book\n",
      "the        --> the\n",
      "air        --> air\n",
      "booking    --> book\n",
      "yet        --> yet\n",
      "?          --> ?\n",
      "if         --> if\n",
      "not        --> not\n",
      ",          --> ,\n",
      "try        --> tri\n",
      "to         --> to\n",
      "book       --> book\n",
      "it         --> it\n",
      "ASAP       --> asap\n",
      "since      --> sinc\n",
      "booking    --> book\n",
      "will       --> will\n",
      "be         --> be\n",
      "out        --> out\n",
      "of         --> of\n",
      "books      --> book\n"
     ]
    }
   ],
   "source": [
    "# Applying stemming on a complete English sentence\n",
    "\n",
    "sentence = 'had you booked the air booking yet? if not, try to book it ASAP since booking will be out of books'\n",
    "words = word_tokenize(sentence)\n",
    "\n",
    "for w in words:\n",
    "    print(f'{w:10} --> {ps.stem(w)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11332a1",
   "metadata": {},
   "source": [
    "> ğŸ‡¬ğŸ‡§ All variations of â€œbookâ€ are normalized to the same base â€œbookâ€.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2960b4c",
   "metadata": {},
   "source": [
    "### **Comparing Multiple Words**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6474a1d",
   "metadata": {},
   "source": [
    "word_list = [\"friend\", \"friendship\", \"friends\", \"stabil\", \"destabilize\",\n",
    "             \"misunderstanding\", \"railroad\", \"moonlight\", \"football\"]\n",
    "\n",
    "print(\"{0:20}{1:20}{2:20}\".format(\"Word\",\"Porter Stemmer\",\"Lancaster Stemmer\"))\n",
    "for word in word_list:\n",
    "    print(\"{0:20}{1:20}{2:20}\".format(word, ps.stem(word), ls.stem(word)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead3071e",
   "metadata": {},
   "source": [
    "> Porter is more moderate, while Lancaster often cuts too deep.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ecb313",
   "metadata": {},
   "source": [
    "# Using spaCy for precise word lemmatization\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = nlp(u\"I am a runner running in a race because I love to run since I ran yesterday\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, '\\t', token.pos_, '\\t', token.lemma_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcec80a6",
   "metadata": {},
   "source": [
    "> spaCy returns the base lemma while respecting part-of-speech tags.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "05c42d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meeting\n",
      "meet\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(lemmatizer.lemmatize(\"meeting\", \"n\"))  # noun\n",
    "print(lemmatizer.lemmatize(\"meeting\", \"v\"))  # verb\n",
    "\n",
    "# We can pass the Part of Speech (POS) tag to improve lemmatization accuracy.\n",
    "# For example: if the word is a noun ('n'), it stays the same; if it's a verb ('v'), it returns to its root form.\n",
    "\n",
    "# This is a simple example showing how to manually pass the POS for a single word.\n",
    "# For longer texts, we use automatic POS tagging to detect the part of speech for each word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcc1390",
   "metadata": {},
   "source": [
    "> As a noun it stays â€œmeetingâ€; as a verb it becomes â€œmeetâ€.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2cda13",
   "metadata": {},
   "source": [
    "### **Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¹Ù„Ù‰ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©**\n",
    "\n",
    "### **Applying on Arabic Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "177b8123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ø§Ù„Ø¬Ø±ÙŠ --> Ø§Ù„Ø¬Ø±\n",
      "ØªØ¬Ø±ÙŠ --> ØªØ¬Ø±\n",
      "ÙŠØ¬Ø±ÙˆÙ† --> ÙŠØ¬Ø±Ùˆ\n",
      "Ø¬Ø±ÙŠ --> Ø¬Ø±\n",
      "ÙŠØ¬Ø±ÙŠ --> ÙŠØ¬Ø±\n"
     ]
    }
   ],
   "source": [
    "# Applying stemming tools on Arabic words\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "s_stemmer = SnowballStemmer(language='arabic')\n",
    "words = ['Ø§Ù„Ø¬Ø±ÙŠ','ØªØ¬Ø±ÙŠ','ÙŠØ¬Ø±ÙˆÙ†','Ø¬Ø±ÙŠ','ÙŠØ¬Ø±ÙŠ']\n",
    "\n",
    "for word in words:\n",
    "    print(word + ' --> ' + s_stemmer.stem(word))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb79d4ed",
   "metadata": {},
   "source": [
    "> The Arabic stemmer approximates the root but lacks full precision.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d101a43",
   "metadata": {},
   "source": [
    "| ğŸ§° **Ø§Ù„Ø£Ø¯Ø§Ø© (Tool)**  | ğŸ‡¸ğŸ‡¦ **Ø§Ù„Ø´Ø±Ø­ Ø§Ù„Ø¹Ø±Ø¨ÙŠ**                                                                               | ğŸ‡¬ğŸ‡§ **English Explanation**                                                                | âš–ï¸ **Ù…ØªÙ‰ ØªØ³ØªØ®Ø¯Ù…Ù‡Ø§ (When to Use)**                                                                  |\n",
    "| --------------------- | --------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------- |\n",
    "| **Porter Stemmer**    | Ø§Ù„Ø£Ù‚Ø¯Ù… ÙˆØ§Ù„Ø£ÙƒØ«Ø± Ø´Ù‡Ø±Ø©ØŒ ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ù‚ÙˆØ§Ø¹Ø¯ Ø¨Ø³ÙŠØ·Ø© Ù„Ù‚Øµ Ø§Ù„Ù†Ù‡Ø§ÙŠØ§ØªØŒ Ù„ÙƒÙ†Ù‡ Ø£Ø­ÙŠØ§Ù†Ù‹Ø§ ÙŠÙÙ†ØªØ¬ ÙƒÙ„Ù…Ø§Øª ØºÙŠØ± ØµØ­ÙŠØ­Ø© Ù„ØºÙˆÙŠÙ‹Ø§. | Oldest and most popular; uses simple rules to cut suffixes, sometimes gives non-real roots. | Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø© Ù„Ù„Ø³Ø±Ø¹Ø© Ø¯ÙˆÙ† Ø£Ù‡Ù…ÙŠØ© ÙƒØ¨ÙŠØ±Ø© Ù„Ù„Ø¯Ù‚Ø©.<br>*When you need speed over precision.*                  |\n",
    "| **Lancaster Stemmer** | Ø£ÙƒØ«Ø± â€œØ¹Ø¯ÙˆØ§Ù†ÙŠØ©â€ Ù…Ù† Porter â€” ÙŠØ­Ø°Ù Ø§Ù„ÙƒØ«ÙŠØ± Ù…Ù† Ø§Ù„Ø­Ø±ÙˆÙ ÙˆÙ‚Ø¯ ÙŠÙÙ‚Ø¯ Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ø¹Ø§Ù†ÙŠ.                              | More aggressive than Porter â€” removes too many letters, may lose meaning.                   | Ø¹Ù†Ø¯ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø¶Ø®Ù…Ø© ÙˆØªØ­ØªØ§Ø¬ ØªØ¨Ø³ÙŠØ· ÙƒØ¨ÙŠØ±.<br>*When simplifying large datasets aggressively.*   |\n",
    "| **Snowball Stemmer**  | Ø§Ù„Ø¬ÙŠÙ„ Ø§Ù„Ø£Ø­Ø¯Ø« Ù…Ù† PorterØŒ Ø£ÙƒØ«Ø± ØªÙˆØ§Ø²Ù†Ù‹Ø§ Ø¨ÙŠÙ† Ø§Ù„Ø¯Ù‚Ø© ÙˆØ§Ù„Ø³Ø±Ø¹Ø©ØŒ ÙˆÙŠØ¯Ø¹Ù… Ù„ØºØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ù…Ù†Ù‡Ø§ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.             | Newer and more balanced version of Porter; supports multiple languages including Arabic.    | Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø£ÙØ¶Ù„ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ù„ØºØ§Øª.<br>*Best choice for multilingual or general NLP tasks.* |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926b1d2e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ§­ Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ø®Ø§Ù…Ø³: Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø³Ù…ÙŠØ© | Named Entity Recognition (NER)\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§© Ù…Ù‚Ø¯Ù…Ø© | Introduction\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ **Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©:**\n",
    "> Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø³Ù…ÙŠØ© (**Named Entity Recognition â€“ NER**) Ù‡Ùˆ Ø£Ø­Ø¯ Ø£Ù‡Ù… ØªØ·Ø¨ÙŠÙ‚Ø§Øª\n",
    "> Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ©ØŒ ÙˆÙŠÙ‡Ø¯Ù Ø¥Ù„Ù‰ **ØªØ­Ø¯ÙŠØ¯ ÙˆØªØµÙ†ÙŠÙ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø©** ÙÙŠ Ø§Ù„Ù†Øµ â€”\n",
    "> Ù…Ø«Ù„ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø´Ø®Ø§ØµØŒ Ø§Ù„Ù…Ø¤Ø³Ø³Ø§ØªØŒ Ø§Ù„Ø£Ù…Ø§ÙƒÙ†ØŒ Ø§Ù„Ø¹Ù…Ù„Ø§ØªØŒ Ø§Ù„ØªÙˆØ§Ø±ÙŠØ®ØŒ Ø§Ù„Ù†Ø³Ø¨ØŒ ÙˆØºÙŠØ±Ù‡Ø§.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ **In English:**\n",
    "> **Named Entity Recognition (NER)** is a key NLP technique that automatically\n",
    "> **identifies and classifies important words** in text â€” such as names of people,\n",
    "> organizations, locations, currencies, dates, and more.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ Ø§Ù„Ù‡Ø¯Ù Ù…Ù† NER | Why It Matters\n",
    "\n",
    "| ğŸ‡¸ğŸ‡¦ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…                                           | ğŸ‡¬ğŸ‡§ Use Case                                                 |\n",
    "| -------------------------------------------------------- | ------------------------------------------------------------- |\n",
    "| ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø®Ø¨Ø§Ø± ÙˆØ§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø´Ø®Ø§Øµ Ø£Ùˆ Ø§Ù„Ø¬Ù‡Ø§Øª | Extracting names of people and organizations from news        |\n",
    "| Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙˆØ§Ù‚Ø¹ ÙˆØ§Ù„Ù…Ø¯Ù† ÙÙŠ Ø§Ù„Ù†ØµÙˆØµ                      | Identifying cities and countries within text                  |\n",
    "| Ø±Ø¨Ø· Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø£Ùˆ Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø¨ØµÙØ­Ø§Øª ÙˆÙŠÙƒÙŠØ¨ÙŠØ¯ÙŠØ§                 | Linking named entities to Wikipedia or knowledge graphs       |\n",
    "| ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ø¹Ø± Ø£Ùˆ ØªØµÙ†ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ Ø¨Ø¯Ù‚Ø© Ø£Ø¹Ù„Ù‰                  | Enhancing sentiment analysis and text classification accuracy |\n",
    "\n",
    "---\n",
    "\n",
    "### âš™ï¸ Ù…Ø¨Ø¯Ø£ Ø§Ù„Ø¹Ù…Ù„ | How NER Works\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ ÙŠØªÙ… ØªØ¯Ø±ÙŠØ¨ Ù†Ù…Ø§Ø°Ø¬ NER Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ø¶Ø®Ù…Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª Ù…Ø¹Ø±ÙˆÙØ© Ø§Ù„ÙØ¦Ø© (Ù…Ø«Ù„Ø§Ù‹: Ø£Ø³Ù…Ø§Ø¡ Ø£Ø´Ø®Ø§ØµØŒ Ù…Ø¯Ù†ØŒ Ø´Ø±ÙƒØ§Øª...).\n",
    "> Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØªØ¹Ù„Ù… Ù…Ù† **Ø§Ù„Ø³ÙŠØ§Ù‚** Ùˆ**Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ù†Ø­ÙˆÙŠØ© (POS)** Ùˆ**Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø¬Ø§ÙˆØ±Ø©** Ù„ÙŠÙƒØªØ´Ù Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª ÙÙŠ Ù†ØµÙˆØµ Ø¬Ø¯ÙŠØ¯Ø©.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ NER models are trained on large labeled datasets where each word has a tag (e.g., PERSON, ORG, GPE).\n",
    "> The model learns from **context**, **POS tags**, and **neighboring words** to predict entities in unseen text.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§± Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„ØªØ±Ù…ÙŠØ² | Entity Encoding Types\n",
    "\n",
    "| Ù†ÙˆØ¹ Ø§Ù„ØªØ±Ù…ÙŠØ²                    | ğŸ‡¸ğŸ‡¦ Ø§Ù„Ø´Ø±Ø­                             | ğŸ‡¬ğŸ‡§ Explanation                                                    |\n",
    "| ------------------------------ | -------------------------------------- | ------------------------------------------------------------------- |\n",
    "| **IO (Insideâ€“Outside)**        | Ø§Ù„ÙƒÙ„Ù…Ø© Ø¥Ù…Ø§ Ø¯Ø§Ø®Ù„ ÙƒÙŠØ§Ù† (I) Ø£Ùˆ Ø®Ø§Ø±Ø¬Ù‡ (O). | Words are either *Inside (I)* an entity or *Outside (O)*.           |\n",
    "| **IOB (Insideâ€“Outsideâ€“Begin)** | ÙŠØ¶ÙŠÙ Ø­Ø±Ù B Ù„Ø¨Ø¯Ø§ÙŠØ© ÙƒÙ„ ÙƒÙŠØ§Ù† Ø¬Ø¯ÙŠØ¯. Ù‡Ø°Ø§ Ù…ÙÙŠØ¯ Ù„Ùˆ Ø¹Ù†Ø¯Ù†Ø§ ÙƒÙŠØ§Ù†Ø§Øª ØªØªÙƒÙˆÙ‘Ù† Ù…Ù† Ø£ÙƒØ«Ø± Ù…Ù† ÙƒÙ„Ù…Ø©ØŒ Ù„Ø£Ù†Ù‡ ÙŠÙˆØ¶Ù‘Ø­ Ø¨Ø¯Ø§ÙŠØªÙ‡Ø§ Ø¨ÙˆØ¶ÙˆØ­.  | Adds B to mark the Beginning of each new entity â€” useful for multi-word entities. |\n",
    "\n",
    "ğŸ§© *Ù…Ø«Ø§Ù„ ØªÙˆØ¶ÙŠØ­ÙŠ:*\n",
    "\n",
    "> \"Fred met Sue Mengqui Huang\"\n",
    ">\n",
    "> * **IO:** Fred (I), met (O), Sue (I), Mengqui (I), Huang (I)\n",
    "> * **IOB:** Fred (B), Sue (B), Mengqui (B), Huang (I)\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§° Ø§Ù„Ø£Ø¯Ø§Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© | Tool Used\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ Ø³Ù†Ø³ØªØ®Ø¯Ù… Ù…ÙƒØªØ¨Ø© **spaCy** Ù„Ù…Ø§ ØªÙˆÙØ±Ù‡ Ù…Ù† Ø¯Ù‚Ø© Ø¹Ø§Ù„ÙŠØ© ÙˆÙ†Ù…Ø§Ø°Ø¬ Ø¬Ø§Ù‡Ø²Ø© Ù„Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø³Ù…ÙŠØ©.\n",
    "> ğŸ‡¬ğŸ‡§ Weâ€™ll use **spaCy**, which offers robust pre-trained models for accurate named entity recognition.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b84e95a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple - ORG - Companies, agencies, institutions, etc.\n",
      "Hong Kong - GPE - Countries, cities, states\n",
      "$6 million - MONEY - Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "# Load spaCy and the small English language model\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Apply NLP analysis on a short text\n",
    "doc = nlp(\"Apple to build a Hong Kong factory for $6 million\")\n",
    "\n",
    "# Display the extracted named entities\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \"-\", ent.label_, \"-\", spacy.explain(ent.label_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "193526c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No named entities found.\n",
      "Washington, DC - GPE - Countries, cities, states\n",
      "-----------------------------\n",
      "next May - DATE - Absolute or relative dates or periods\n",
      "-----------------------------\n",
      "the Washington Monument - ORG - Companies, agencies, institutions, etc.\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "# Function to clearly display entities with explanation\n",
    "def show_ents(doc):\n",
    "    if doc.ents:\n",
    "        for ent in doc.ents:\n",
    "            print(ent.text + \" - \" + ent.label_ + \" - \" + str(spacy.explain(ent.label_)))\n",
    "            print(\"-----------------------------\")\n",
    "    else:\n",
    "        print(\"No named entities found.\")\n",
    "\n",
    "# Test on a sentence without entities\n",
    "show_ents(nlp(\"Hi how are you\"))\n",
    "\n",
    "# Test on a sentence with multiple entities\n",
    "show_ents(nlp(\"May I go to Washington, DC next May to see the Washington Monument?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127da62b",
   "metadata": {},
   "source": [
    "### ğŸ§± Ø¥Ø¶Ø§ÙØ© ÙƒÙŠØ§Ù† Ø¬Ø¯ÙŠØ¯ ÙŠØ¯ÙˆÙŠÙ‹Ø§ | Adding Custom Entity\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ Ø£Ø­ÙŠØ§Ù†Ù‹Ø§ Ù‚Ø¯ Ù„Ø§ ÙŠØªØ¹Ø±Ù‘Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ ÙƒÙŠØ§Ù† Ø¬Ø¯ÙŠØ¯ (Ù…Ø«Ù„ Ø§Ø³Ù… Ø´Ø±ÙƒØ© ØºÙŠØ± Ù…Ø´Ù‡ÙˆØ±Ø©)ØŒ\n",
    "> ÙÙŠÙ…ÙƒÙ†Ù†Ø§ Ø¥Ø¶Ø§ÙØªÙ‡ ÙŠØ¯ÙˆÙŠÙ‹Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙƒØ§Ø¦Ù† `Span`.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ Sometimes the model doesnâ€™t recognize a new entity (like a custom company name),\n",
    "> so we can add it manually using a `Span` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e5ccc370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPRO - ORG - Companies, agencies, institutions, etc.\n",
      "-----------------------------\n",
      "U.K. - GPE - Countries, cities, states\n",
      "-----------------------------\n",
      "$6 million - MONEY - Monetary values, including unit\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import Span\n",
    "\n",
    "doc = nlp(\"CPRO to build a U.K. factory for $6 million\")\n",
    "ORG = doc.vocab.strings[u\"ORG\"]  # ğŸ‡¸ğŸ‡¦ ØªØ­Ø¯ÙŠØ¯ ÙØ¦Ø© Ø§Ù„Ø´Ø±ÙƒØ© | ğŸ‡¬ğŸ‡§ Specify ORG label\n",
    "new_ent = Span(doc, 0, 1, label=ORG)  # ğŸ‡¸ğŸ‡¦ Ø§Ù„ÙƒÙŠØ§Ù† Ø§Ù„Ø¬Ø¯ÙŠØ¯ | ğŸ‡¬ğŸ‡§ Create custom entity\n",
    "doc.ents = list(doc.ents) + [new_ent]  # ğŸ‡¸ğŸ‡¦ Ø¥Ø¶Ø§ÙØªÙ‡ Ù„Ù„Ù‚Ø§Ø¦Ù…Ø© | ğŸ‡¬ğŸ‡§ Add to entity list\n",
    "\n",
    "show_ents(doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9c5bf1",
   "metadata": {},
   "source": [
    "### ğŸ§± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø§Øª Ø§Ù„Ø§Ø³Ù…ÙŠØ© | Extracting Noun Chunks\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø§Øª Ø§Ù„Ø§Ø³Ù…ÙŠØ© (Noun Chunks) Ù‡ÙŠ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª ÙƒÙ„Ù…Ø§Øª ØªÙ…Ø«Ù„ Ù…Ø¹Ù†Ù‰ ÙˆØ§Ø­Ø¯ Ù…Ø«Ù„ â€œAutonomous carsâ€ Ø£Ùˆ â€œinsurance liabilityâ€.\n",
    "> \n",
    "> ğŸ‡¬ğŸ‡§ Noun Chunks are continuous phrases that act as single units of meaning, such as â€œAutonomous carsâ€ or â€œinsurance liabilityâ€."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d80b57ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autonomous cars â€” cars â€” nsubj â€” nominal subject\n",
      "insurance liability â€” liability â€” dobj â€” direct object\n",
      "manufacturers â€” manufacturers â€” pobj â€” object of preposition\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(\"Autonomous cars shift insurance liability toward manufacturers.\")\n",
    "\n",
    "for chunk in doc2.noun_chunks:\n",
    "    print(chunk.text, \"â€”\", chunk.root.text, \"â€”\", chunk.root.dep_, \"â€”\", spacy.explain(chunk.root.dep_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc16701e",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### ğŸŒ Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ù†Øµ Ø¹Ø±Ø¨ÙŠ | Example with Arabic Text\n",
    "\n",
    "> âš ï¸ ğŸ‡¸ğŸ‡¦ Ø¯Ù‚Ø© NER ÙÙŠ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù…Ø§ Ø²Ø§Ù„Øª Ù…Ø­Ø¯ÙˆØ¯Ø© Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©ØŒ\n",
    "> Ù„ÙƒÙ†Ù‡Ø§ ØªØªØ­Ø³Ù† ØªØ¯Ø±ÙŠØ¬ÙŠÙ‹Ø§ Ù…Ø¹ ØªØ·ÙˆØ± Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø­Ø¯ÙŠØ«Ø©.\n",
    ">\n",
    "> âš ï¸ ğŸ‡¬ğŸ‡§ NER accuracy in Arabic is still limited compared to English,\n",
    "> though itâ€™s improving with newer multilingual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "17b4b059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ø§Ù„Ù…Ø§Ù†ÙŠØ§ Ù‚Ø§Ù…Øª Ø¨Ø§Ù„Ø§Ø³ØªØ­ÙˆØ§Ø° Ø¹Ù„Ù‰ - PERSON - People, including fictional\n",
      "5 - CARDINAL - Numerals that do not fall under another type\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Ø´Ø±ÙƒØ© Ù…Ø±Ø³ÙŠØ¯Ø³ ÙÙŠ Ø§Ù„Ù…Ø§Ù†ÙŠØ§ Ù‚Ø§Ù…Øª Ø¨Ø§Ù„Ø§Ø³ØªØ­ÙˆØ§Ø° Ø¹Ù„Ù‰ Ø´Ø±ÙƒØ© ÙƒØ±Ø§ÙŠØ³Ù„Ø± Ù…Ù‚Ø§Ø¨Ù„ 5 Ù…Ù„ÙŠÙˆÙ† Ø¯ÙˆÙ„Ø§Ø±\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \"-\", ent.label_, \"-\", spacy.explain(ent.label_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451caf67",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§© Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ© ÙÙŠ spaCy | Additional Attributes\n",
    "\n",
    "| Ø§Ù„Ø®Ø§ØµÙŠØ©          | ğŸ‡¸ğŸ‡¦ Ø§Ù„ÙˆØµÙ                 | ğŸ‡¬ğŸ‡§ Description                 |\n",
    "| ---------------- | -------------------------- | -------------------------------- |\n",
    "| `ent.text`       | Ù†Øµ Ø§Ù„ÙƒÙŠØ§Ù†                  | The actual entity text           |\n",
    "| `ent.label_`     | Ù†ÙˆØ¹ Ø§Ù„ÙƒÙŠØ§Ù† (Ø´Ø®ØµØŒ Ù…Ù†Ø¸Ù…Ø©...) | Entity label (person, org, etc.) |\n",
    "| `ent.start_char` | Ù…ÙˆÙ‚Ø¹ Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„ÙƒÙŠØ§Ù† ÙÙŠ Ø§Ù„Ù†Øµ  | Start character index            |\n",
    "| `ent.end_char`   | Ù…ÙˆÙ‚Ø¹ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„ÙƒÙŠØ§Ù† ÙÙŠ Ø§Ù„Ù†Øµ  | End character index              |\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§  Ù…Ù„Ø®Øµ Ø§Ù„Ù‚Ø³Ù… | Section Summary\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ ØªØ¹Ù„Ù…Ù†Ø§ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù‚Ø³Ù… ÙƒÙŠÙ ÙŠÙ…ÙŠØ² Ø§Ù„Ø­Ø§Ø³ÙˆØ¨ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø© Ø¯Ø§Ø®Ù„ Ø§Ù„Ù†ØµÙˆØµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… NERØŒ\n",
    "> ÙˆÙƒÙŠÙ Ù†Ø¶ÙŠÙ ÙƒÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© ÙŠØ¯ÙˆÙŠÙ‹Ø§ ÙˆÙ†Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø§Øª Ø§Ù„Ø§Ø³Ù…ÙŠØ©.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ In this section, we learned how computers identify important entities using NER,\n",
    "> how to add custom entities manually, and how to extract meaningful noun chunks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9806be10",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ§® Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ø³Ø§Ø¯Ø³: ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªÙˆÙ‚Ù | Stopwords\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§© Ù…Ù‚Ø¯Ù…Ø© | Introduction\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ **Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©:**\n",
    "> ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© (NLP)ØŒ Ù‡Ù†Ø§Ùƒ ÙƒÙ„Ù…Ø§Øª Ø´Ø§Ø¦Ø¹Ø© Ø¬Ø¯Ù‹Ø§ ØªÙØ³ØªØ®Ø¯Ù… ÙƒØ«ÙŠØ±Ù‹Ø§ ÙÙŠ Ø§Ù„Ù†ØµÙˆØµ Ù…Ø«Ù„ â€œtheâ€, â€œisâ€, â€œandâ€ Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©\n",
    "> Ø£Ùˆ â€œÙ…Ù†â€, â€œÙÙŠâ€, â€œØ¹Ù„Ù‰â€ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©. Ù‡Ø°Ù‡ Ø§Ù„ÙƒÙ„Ù…Ø§Øª **ØªÙØ³Ù…Ù‘Ù‰ â€œÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªÙˆÙ‚Ù (Stopwords)â€** Ù„Ø£Ù†Ù‡Ø§ Ù„Ø§ ØªØ¶ÙŠÙ\n",
    "> Ù…Ø¹Ù†Ù‰ Ù‚ÙˆÙŠÙ‹Ø§ Ù„Ù„Ø¬Ù…Ù„Ø© ÙˆÙŠÙ…ÙƒÙ† ØºØ§Ù„Ø¨Ù‹Ø§ ØªØ¬Ø§Ù‡Ù„Ù‡Ø§ Ù„ØªØ¨Ø³ÙŠØ· Ø§Ù„ØªØ­Ù„ÙŠÙ„.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ **In English:**\n",
    "> In NLP, **Stopwords** are very common words (like *the, is, and*) that appear frequently\n",
    "> but carry little meaning. They can often be **removed** to simplify analysis and improve efficiency.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ Ù„Ù…Ø§Ø°Ø§ Ù†Ø²ÙŠÙ„ ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªÙˆÙ‚ÙØŸ | Why Remove Stopwords\n",
    "\n",
    "| ğŸ‡¸ğŸ‡¦ Ø§Ù„Ø³Ø¨Ø¨                              | ğŸ‡¬ğŸ‡§ Reason                                             |\n",
    "| --------------------------------------- | ------------------------------------------------------- |\n",
    "| Ù„Ø£Ù†Ù‡Ø§ ØªØªÙƒØ±Ø± ÙƒØ«ÙŠØ±Ù‹Ø§ ÙˆØªÙ‚Ù„Ù„ Ù…Ù† Ø¯Ù‚Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ | They appear frequently and reduce signal-to-noise ratio |\n",
    "| Ù„Ø§ ØªØ¤Ø«Ø± Ø¹Ø§Ø¯Ø© ÙÙŠ Ù…Ø¹Ù†Ù‰ Ø§Ù„Ù†Øµ Ø§Ù„ÙƒÙ„ÙŠ         | Usually do not affect the core meaning                  |\n",
    "| ØªØ³Ø§Ø¹Ø¯ ÙÙŠ ØªÙ‚Ù„ÙŠÙ„ Ø­Ø¬Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª             | Help reduce text size and processing time               |\n",
    "| ØªØ­Ø³Ù‘Ù† Ø£Ø¯Ø§Ø¡ Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ§Øª Ø§Ù„ØªØµÙ†ÙŠÙ ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„   | Improve machine learning model accuracy                 |\n",
    "\n",
    "> âš ï¸ Ù…Ù„Ø§Ø­Ø¸Ø©: Ù„ÙŠØ³Øª ÙƒÙ„ ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªÙˆÙ‚Ù â€œØºÙŠØ± Ù…Ù‡Ù…Ø©â€ Ø¯Ø§Ø¦Ù…Ù‹Ø§.\n",
    "> ÙƒÙ„Ù…Ø© Ù…Ø«Ù„ **â€œnotâ€** Ø£Ùˆ **â€œbutâ€** Ù‚Ø¯ ØªØºÙŠÙ‘Ø± Ø§Ù„Ù…Ø¹Ù†Ù‰ ØªÙ…Ø§Ù…Ù‹Ø§ØŒ Ù„Ø°Ø§ ÙŠØ¬Ø¨ Ø§Ù„Ø­Ø°Ø± Ø¹Ù†Ø¯ Ø­Ø°ÙÙ‡Ø§.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "365f3b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'being', 'however', 'whereafter', 'well', 'unless', 'themselves', 'nevertheless', 'several', 'anyhow', 'whatever', 'every', 'though', 'were', 'before', 'on', 'formerly', 'once', 'their', 'ourselves', 'via', 'we', 'regarding', 'back', 'there', 'from', 'hundred', 'himself', 'whoever', 'us', 'thence', 'yourselves', 'same', 'never', 'four', 'those', 'yet', 'some', 'among', 'latter', 'wherever', 'to', 'above', 'beyond', 'all', 'towards', 'even', 'during', 'somewhere', 'else', 'cannot', 'until', 'five', 'eleven', 'nor', 'otherwise', 'hereafter', 'whole', 'mostly', 'less', 'therein', 'call', 'neither', 'hereby', 'within', 'as', 'its', 'whereas', 'â€˜s', 'own', 'her', 'now', 'beside', 'me', 'becoming', 'into', 'go', 'his', 'under', 'sixty', 'often', 'nowhere', 'after', 'either', 'whether', 'whereupon', 'below', 'eight', 'upon', \"'s\", 'others', 'empty', 'sometimes', 'that', 'herein', 'seemed', 'twelve', 'my', 'with', 'â€˜d', 'make', 'hereupon', 'indeed', 'nobody', 'thereafter', 'herself', 'whence', 'anyway', 'move', 'such', 'â€™re', \"'d\", 'thru', 'becomes', 'around', 'first', 'serious', 'whom', 'you', 'for', 'she', 'really', 'further', 'out', 'than', 'who', 'up', 'am', 'have', 'per', 'side', 'what', 'did', 'i', 'everywhere', 'too', 'toward', 'top', 'many', 'please', 'â€™ll', 'keep', 'your', 'somehow', 'might', 'over', 'something', 'namely', 'wherein', 'see', 'seem', 'in', 'they', 'just', 'meanwhile', 'whenever', 'almost', 'rather', 'would', 'behind', 'off', 'noone', 'used', 'beforehand', 'against', 'anywhere', 'both', \"'re\", 'could', 'six', 'therefore', 'still', 'amount', 'using', 'here', 'itself', 'â€˜re', 'always', 'made', 'thereby', 'it', 'where', 'enough', 'ours', 'sometime', 'so', 'became', 'ca', 'elsewhere', 'when', 'throughout', 'them', 'which', 'â€™ve', 'amongst', 'moreover', 'any', 'yourself', 'together', 'fifteen', 'much', 'then', 'also', 'part', 'bottom', 'say', 'front', 'only', 'quite', 'next', 'across', 'nothing', 'without', 'two', 'give', 'hers', 'ever', 'no', 'nâ€™t', 'everyone', 'whose', 'he', 'besides', 'nine', 'full', 'through', 'why', 'a', 'at', 'although', \"'ll\", \"'ve\", 'of', 'put', 'afterwards', 'another', 'be', 'most', 'various', 'along', \"n't\", 'â€˜ve', 'about', 'our', 'few', 'â€™m', 'thus', 'perhaps', 'fifty', 'because', 'latterly', 'alone', 'none', 'him', 'is', 'third', 'mine', 'do', 'except', \"'m\", 'the', 'had', 'anything', 'or', 'â€™s', 'â€˜m', 'become', 'been', 'between', 'hence', 'more', 'these', 'each', 'are', 'how', 'last', 'if', 'former', 'and', 'anyone', 'thereupon', 'take', 'may', 'doing', 'get', 'this', 'whereby', 'not', 'seeming', 'yours', 'twenty', 'myself', 'but', 'â€˜ll', 'one', 'done', 'least', 'already', 'down', 'very', 'has', 'must', 'three', 'again', 'onto', 'someone', 'name', 'nâ€˜t', 'forty', 'was', 'since', 'does', 'other', 'everything', 'ten', 'show', 'â€™d', 'an', 'seems', 'should', 'whither', 'while', 'by', 'due', 're', 'can', 'will'}\n"
     ]
    }
   ],
   "source": [
    "# Load spaCy and English language model\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Display default stopwords in spaCy\n",
    "print(nlp.Defaults.stop_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bcd08717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if a word is a stopword\n",
    "nlp.vocab['myself'].is_stop   # âœ… True\n",
    "nlp.vocab['mystery'].is_stop  # âŒ False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "970529c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ø¥Ø¶Ø§ÙØ© ÙƒÙ„Ù…Ø© Ø¬Ø¯ÙŠØ¯Ø© | Add a Custom Stopword\n",
    "\n",
    "# Check the word before adding\n",
    "nlp.vocab['btw'].is_stop  # False\n",
    "\n",
    "# Add a new stopword manually\n",
    "nlp.Defaults.stop_words.add('btw')\n",
    "nlp.vocab['btw'].is_stop = True\n",
    "\n",
    "# Check again\n",
    "nlp.vocab['btw'].is_stop  # âœ… True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "861dfc2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ø­Ø°Ù ÙƒÙ„Ù…Ø© Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© | Remove a Stopword\n",
    "\n",
    "# Check before removing\n",
    "nlp.vocab['beyond'].is_stop  # True\n",
    "\n",
    "# Remove the word from stopwords\n",
    "nlp.Defaults.stop_words.remove('beyond')\n",
    "nlp.vocab['beyond'].is_stop = False\n",
    "\n",
    "# Verify removal\n",
    "nlp.vocab['beyond'].is_stop  # False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f23887",
   "metadata": {},
   "source": [
    "ğŸ§  **Ù…Ù„Ø§Ø­Ø¸Ø© Ù…Ù‡Ù…Ø© | Important:**\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ Ø£ÙŠ ØªØ¹Ø¯ÙŠÙ„ (Ø¥Ø¶Ø§ÙØ© Ø£Ùˆ Ø­Ø°Ù) ÙŠØ¨Ù‚Ù‰ ÙÙ‚Ø· Ø£Ø«Ù†Ø§Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø­Ø§Ù„ÙŠØŒ\n",
    "> ÙˆØ¥Ø°Ø§ Ø£Ø¹Ø¯Øª ØªØ´ØºÙŠÙ„ Ø§Ù„Ù€ Kernel Ø³ØªØ¹ÙˆØ¯ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ù„Ø­Ø§Ù„ØªÙ‡Ø§ Ø§Ù„Ø£ØµÙ„ÙŠØ©.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ Any change (add/remove) lasts only in the current runtime.\n",
    "> Restarting the kernel resets the default stopwords list.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "40726cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shosh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " \"he's\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " \"i've\",\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " \"we've\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ø§Ø³ØªØ®Ø¯Ø§Ù… ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªÙˆÙ‚Ù ÙÙŠ NLTK | Stopwords in NLTK\n",
    "\n",
    "# Import required libraries\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# ğŸ‡¸ğŸ‡¦ ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¦Ù…Ø© ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªÙˆÙ‚Ù Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©\n",
    "# ğŸ‡¬ğŸ‡§ Load English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(len(stop_words))  # Ø¹Ø¯Ø¯Ù‡Ø§\n",
    "stop_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eca8fbf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§± Original: ['This', 'is', 'a', 'sample', 'sentence', ',', 'and', 'this', 'is', 'showing', 'off', 'the', 'stop', 'words', 'filtration', '.']\n",
      "---------------------------------\n",
      "âœ… Filtered: ['sample', 'sentence', ',', 'showing', 'stop', 'words', 'filtration', '.']\n"
     ]
    }
   ],
   "source": [
    "example_sent = \"This is a sample sentence, and this is showing off the stop words filtration.\"\n",
    "\n",
    "# Tokenize the sentence\n",
    "word_tokens = word_tokenize(example_sent)\n",
    "\n",
    "# Remove stopwords\n",
    "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "\n",
    "print(\"ğŸ§± Original:\", word_tokens)\n",
    "print(\"---------------------------------\")\n",
    "print(\"âœ… Filtered:\", filtered_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "828694db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ø«Ù…Ù†Ù…Ø¦Ø© | Ø£Ù‚Ø¨Ù„ | Ø³ØªÙ…Ø¦Ø© | Ø³Ø±Ø¹Ø§Ù† | ÙˆØ§Ø­Ø¯ | Ø´ÙŠÙ† | Ø°Ù„ÙƒÙ† | Ø£ÙŠØ§ | ÙƒÙ„ | Ù†ÙØ³ | Ù„Ø³ØªÙ… | Ø£Ù†Ø¨Ø£ | Ù‡Ø§Ùƒ | ØªØ³Ø¹ÙŠÙ† | Ø­Ø¨Ø°Ø§ | Ø¨ | Ø¨Ø¦Ø³ | Ù‚Ù„Ù…Ø§ | ØºØ§Ù„Ø¨Ø§ | Ù†ÙŠÙ | Ù…Ø¹Ø§Ø° | Ø«Ù„Ø§Ø«Ù…Ø¦Ø© | Ø¥Ù‰ | Ø²Ø¹Ù… | Ø¸ | Ù‡Ø°Ø§ | ÙŠÙˆØ§Ù† | Ø¹Ù„Ù‚ | Ø«Ø§Ù…Ù† | Ù„Ø³Ù† | Ø§Ù„Ù„Ø°ÙŠÙ† | ÙƒÙ„ØªØ§ | Ø¹Ø¯ÙÙ‘ | Ø³Ø¨Ø¹Ø© | ÙˆÙ…Ø§ | Ù†Ø¹Ù… | ØªØ­Øª | Ø¨Ù‡Ù…Ø§ | Ù…Ø§ Ø¨Ø±Ø­ | Ø«Ø§Ù„Ø« | Ø¹Ø§Ø´Ø± | Ù„ÙƒÙŠÙ„Ø§ | Ø´ØªØ§Ù† | Ù…ÙƒØ§Ù†ÙƒÙ… | ÙƒÙŠÙ | Ø¨Ø® | Ø·ÙÙ‚ | Ù…Ø§Ø°Ø§ | Ø¥ÙŠØ§Ù‡Ø§ | Ø£Ùˆ | Ù„ÙŠ | Ø¥Ù„ÙŠÙƒÙ†Ù‘ | Ù‰ | Ø¢Ù‡Ø§ | ØªÙŠÙ† | Ù‡Ø§ØªÙ‡ | ØµØ¯Ù‚Ø§ | Ù‡ÙŠ | Ø°Ù„Ùƒ | Ø£Ù„Ø§ | ÙƒÙŠÙÙ…Ø§ | Ø¥ÙŠØ§ÙŠ | Ø®Ø§Ù„ | Ø¥Ø­Ø¯Ù‰ | Ø­ÙŠÙ† | Ø®Ù…Ø³Ø© | ØªØ¨Ø¯Ù‘Ù„ | Ø£ÙƒØªÙˆØ¨Ø± | Ù„Ø¨ÙŠÙƒ | Ø°ÙˆØ§ | Ø³Ø§Ø¡ | ÙƒÙ„ÙŠÙ‡Ù…Ø§ | Ù…Ù†Ù‡Ø§ | Ù‚Ø¨Ù„ | Ø¢Ù†ÙØ§ | ØµØ§Ø± | Ø¨ÙŠØ¯ | Ø¨ÙŠ | Ø¬Ù…Ø¹Ø© | ÙˆÙ„Ùˆ | Ø£Ù„Ù | Ø£ÙŠÙ† | Ø¨Ø§Ø¡ | Ø£Ù‡Ù„Ø§ | Ø§Ø«Ù†Ø§Ù† | ØªÙÙ‡ | ØªØ³Ø¹Ù…Ø§Ø¦Ø© | Ø®Ù„Ù | Ù„Ø§Ù… | ÙŠÙØ¹Ù„ÙˆÙ† | Ø­ÙŠÙÙ‘ | Ø£Ù…Ø¯ | Ø£ÙŠÙ†Ù…Ø§ | Ø£Ø¬Ù„ | Ø¹ÙØ¯ÙØ³Ù’ | Ø­Ø§Ø¡ | Ø®Ù…Ø³ÙŠÙ† | Ø¢Ø¨ | Ø°Ù‡Ø¨ | Ù…Ø¦Ø© | ÙˆÙ„Ø§ | Ø°ÙÙ‡ | ØªØ®Ø° | Ø­Ø¨ÙŠØ¨ | Ù‡ÙØ°ÙÙŠÙ’Ù†Ù | Ø·Ø§Ø¡ | Ù„Ø¯Ù‰ | Ù‡Ø§ÙƒÙ | Ø­Ø±Ù‰ | Ù…Ø§Ø¦Ø© | Ù„ÙŠØ³ | Ù„Ø§ Ø³ÙŠÙ…Ø§ | ÙØ§Ø¡ | ÙƒÙ„ÙÙ‘Ø§ | Ø£ÙŠ | Ù‡ÙØ°ÙÙŠ | Ø£ÙˆØª | Ø±ÙŠØ« | Ù…Ù‡ | Ø¹Ø´Ø± | ÙŠØ§ | Ø«Ù„Ø§Ø«ÙŠÙ† | Ù‡Ù„ | Ø¹Ù„Ù‰ | Ø®Ù…Ø³ÙˆÙ† | Ø³Ø¨ØªÙ…Ø¨Ø± | Ø¹Ø´Ø±ÙŠÙ† | Ù…Ù†Ø° | Ø¥Ø²Ø§Ø¡ | ÙƒÙ‰ | Ù‘Ø£ÙŠÙ‘Ø§Ù† | Ø¥ÙŠØ§Ù‡Ù† | ØºØ¯Ø§Ø© | ÙˆÙ…Ù† | Ù„Ø¹Ù…Ø± | Ø³Ø¨Øª | Ù…Ù† | Ø§Ù„Ù„ÙˆØ§ØªÙŠ | Ù„Ù‡Ù† | Ø¬ÙŠØ± | Ø±Ø§Ø­ | ÙˆØ±Ø§Ø¡ÙÙƒ | Ø¥ÙŠÙ‡ | Ø´ÙŠÙƒÙ„ | Ù„ | ØªÙŠ | Ù | Ø­Ø¬Ø§ | ÙƒØ£ÙŠÙ‘ | Ù„ÙƒÙ… | Ø§Ù„Ø£Ù„Ù‰ | Øº | Ø¹Ø¯Ø§ | Ø²Ø§ÙŠ | Ù‡Ø°ÙŠÙ† | Ù‡Ù†Ø§Ù„Ùƒ | Ø£ÙˆÙ„ | Ø¥Ù„ÙŠÙƒÙ… | Ø¹Ù† | Ø¨Ù„ | Ù„ÙŠØ±Ø© | Ù‡Ø¨Ù‘ | ÙƒØ£Ù†Ù…Ø§ | Ø£Ù…Ø§Ù…ÙƒÙ | Ø¹Ù„ÙŠÙ‡ | ÙƒØ§Ù†ÙˆÙ† | ÙØ¥Ù† | ØªØ§Ù†Ù | Ø§ØªØ®Ø° | Ø³Ø§Ø¨Ø¹ | Ø°ÙÙŠÙ’Ù†Ù | Ù‡ÙŠØ§ | Ø£Ø®Ø¨Ø± | Ø¥Ù„ÙŠÙƒ | Ø¨Ù‡Ù… | Ø£ØµÙ„Ø§ | Ø­Ø§Ø´Ø§ | Ù„ÙƒÙ†Ù…Ø§ | Ø¸Ù„Ù‘ | ÙˆÙÙŠÙ’ | Ø«Ø§Ø¡ | Ø­Ø¯ÙØ« | Ø®Ù„Ø§ | Ø´Ø¨Ø§Ø· | ØªØ±Ùƒ | Ø³Ù…Ø¹Ø§ | Ø°Ø§ | Ø£ÙƒØ«Ø± | Ø¹ÙŠÙ† | Ù„Ø§Ø³ÙŠÙ…Ø§ | Ø­Ø§Ø¯ÙŠ | Ø¥Ù†Ù…Ø§ | ÙƒÙ„Ù…Ø§ | ØªÙØ¹Ù„ÙˆÙ† | Ø¹Ø³Ù‰ | Ø³Ø±Ø§ | Ø¥ÙŠØ§Ùƒ | Ø¨Ø¤Ø³Ø§ | ÙŠÙ†Ø§ÙŠØ± | Ø­Ø§ÙŠ | Ù…Ø§ÙŠÙˆ | Ù‡Ù„Ù„Ø© | Ø£ÙŠÙ‘ | Ù…ÙƒØ§Ù†ÙÙƒ | Ø¨ÙƒÙ…Ø§ | Ù‚Ø§Ø·Ø¨Ø© | Ù„Ù‡ | Ø±Ø¬Ø¹ | Ø­Ø§Ø± | Ø£Ù†Ù‘Ù‰ | Ø¯ÙˆÙ† | Ù‡Ø§Ø¡ | Ø³ | Ø£ÙŠØ¶Ø§ | Ø£Ù…Ø§Ù… | Ø¨Ù‡Ø§ | Ø¢Ù†Ø§Ø¡ | Ø³Ø¨Ø¹ÙˆÙ† | ØµØ±Ø§Ø­Ø© | ÙƒÙ„ÙŠÙƒÙ…Ø§ | Ø¯ÙˆØ§Ù„ÙŠÙƒ | ØªØ­ÙˆÙ‘Ù„ | Ø£Ù†Øª | Ø®Ø§Ø¡ | Ø£Ù† | Ù„Ùˆ | Ù‡ÙØ§ØªØ§Ù†Ù | Ù†ÙˆÙ† | Ø¹ÙŠØ§Ù†Ø§ | Ø£Ø¨Ø¯Ø§ | Ø® | ÙˆØ±Ø¯ | ÙˆØ¬Ø¯ | ÙˆÙ‡Ùˆ | Ø£Ø±Ø¨Ø¹Ø© | Ø¢Ø°Ø§Ø± | Ø·Ø§Ù„Ù…Ø§ | Ø¨ÙƒÙ… | ØªÙ‡ | Ø¥Ù† | Ù†Ø­Ù† | ÙƒØ§Ù† | Ù…Ø° | Ø£Ù„ | Ø· | Ø§Ù„Ù„Ø§ØªÙŠ | Ø¥Ù„ÙŠÙƒÙ…Ø§ | Ù‡ÙØ°Ø§ | Ø¥Ù…Ù‘Ø§ | Ø³ÙˆÙ | ØªØ³Ø¹ | Ø£Ù†Ù‹Ù‘ | Ø§Ø«Ù†Ø§ | Ø¢Ø¶ | Ù„Ø¹Ù„ | Ø±ÙˆÙŠØ¯Ùƒ | Ø£Ù†ØªÙ | Ø« | ØªØ³Ø¹Ø© | Ù‡ÙØ°ÙÙ‡ | ÙØ±Ø§Ø¯Ù‰ | Ù…Ø§Ø¯Ø§Ù… | ÙˆØ¥Ø° | Ø«Ø§Ù†ÙŠ | Ø°Ù‡ | Ø®Ù…Ø³Ù…Ø¦Ø© | Ù‡Ø§ | ØªÙØ¹Ù„Ø§Ù† | Ù‡Ùˆ | Ù„Ø¹Ù„ÙÙ‘ | ØºÙŠÙ† | Ø­ | Ø¹Ø§Ù…Ø© | Ù‡ÙŠØª | ÙƒØ«ÙŠØ±Ø§ | ØºØ§Ø¯Ø± | Ø§Ù„Ù„ØªÙŠÙ† | Ù‡Ø§Ù‡Ù†Ø§ | Ø£Ø¬Ù…Ø¹ | ÙˆØ§ | Ø°Ø§Ù† | Ø£Ù…Ø³Ù‰ | Ø®Ù…ÙŠØ³ | Ù„Ø³Ù†Ø§ | Ø¹Ù„ÙŠÙƒ | Ø¥Ù†ÙÙ‘ | ÙŠÙ† | Ø£Ø®Ø° | Ø®Ù…Ø³ | Ø¦ | Ø¨Ø®Ù | Ù„Ù†Ø§ | Ù‚Ø·Ù‘ | ÙÙŠÙ…Ø§ | Ù„Ø³ØªÙ† | ÙØ¶Ù„Ø§ | Ø³ØªØ© | Ø£Ø®Ùˆ | Ø®Ø¨ÙÙ‘Ø± | Ø¥ÙŠØ§ÙƒÙ…Ø§ | Ø°ÙŠÙ†Ùƒ | Ù†ÙˆÙÙ…Ø¨Ø± | Ø¹Ø´Ø±ÙˆÙ† | Ø®Ø§Ù…Ø³ | Ù‡Ù„Ø§ | Ø¹Ù†Ø¯ | Ù‡ÙØ¬Ù’ | Ø­ÙŠØ« | Ù…Ø§ÙŠ | Ø·Ø§Ù‚ | Ù…Ù‡Ù…Ø§ | Ø¹Ø¬Ø¨Ø§ | Ø¯Ø§Ù„ | ØªØ§Ø±Ø© | Ø±Ø§Ø¡ | Ù„ÙˆÙ„Ø§ | Ø¬Ù…ÙŠØ¹ | ÙØ¨Ø±Ø§ÙŠØ± | Ø£Ø¹Ù„Ù… | Øª | Ø© | Ø®Ù…Ø³Ù…Ø§Ø¦Ø© | ÙÙ…Ù† | Ø¶Ø§Ø¯ | Ù†Ø§ | ÙŠ | Ù‚Ø§Ù… | Ø£ÙˆÙ„Ø§Ø¡ | ÙˆØ§Ùˆ | Ø¨Ø¹Ø¶ | Ø³Øª | Ø¶ | Ø¨Ø¹Ø¯ | Ø°ÙŠÙ† | Øµ | Ù‡Ù†Ø§Ùƒ | Ø±Ø£Ù‰ | Ù„ÙŠØ³ØªØ§ | Ù†ÙØ®Ù’ | Ù„Ù…Ø§ | Ø¨Ø¶Ø¹ | ÙƒØ°Ø§ | ÙƒÙ„Ø§ | Ø£ | Ø±Ø§Ø¨Ø¹ | ØªÙ„ÙƒÙ…Ø§ | ØªÙÙŠ | Ø£Ù…Ù‘Ø§ | Ø§Ù†Ù‚Ù„Ø¨ | ÙƒÙŠ | ØªØ³Ø¹Ù…Ø¦Ø© | ÙˆÙ‡Ø¨ | Ù‚Ø±Ø´ | Ø§ | Ø³Ø¨Ø¹Ù…Ø§Ø¦Ø© | Ø·Ø±Ø§ | Ø¥ÙŠØ§Ù†Ø§ | Ø£Ø¹Ø·Ù‰ | Ø®Ù„Ø§ÙØ§ | Ø¥Ø°Ø§ | Ø­ÙØ°Ø§Ø±Ù | ØªØ¹Ù„ÙÙ‘Ù… | Ù‡Ù†Ø§ | Ø¬ | Ù‡ÙØ§ØªÙÙŠ | Ø­Ù‚Ø§ | Ù‡Ø°Ø§Ù† | Ø± | Ø¥ÙŠØ§Ù‡ | Ø«Ù…Ø§Ù†Ù…Ø¦Ø© | Ø£ÙˆØ´Ùƒ | Ø«Ù„Ø§Ø« | Ø°Ø§Ù†Ù | Ø£Ù…Ø§ | Ù‡ÙØ°Ø§Ù†Ù | Ø§Ø±Ø¨Ø¹ÙŠÙ† | Ø§Ù„Ù„Ø§Ø¦ÙŠ | Ø¯Ø±Ù‡Ù… | Ø­Ù…ÙŒ | Ù‡ÙÙŠÙ’Ù‡Ø§Øª | Ù…ÙƒØ§Ù†ÙƒÙ…Ø§ | Ø¨Ù‡ | Ø°ÙŠØª | Ø¨Ù…Ø§ | ØºÙŠØ± | Ù„Ø¦Ù† | Ø°ÙˆØ§ØªØ§ | ÙƒÙ… | Ù„Ø³Øª | ØªØ§Ù†ÙÙƒ | Ø«Ù… | Ø¢ÙŠ | Ø«Ù…Ø§Ù†ÙˆÙ† | Ø¸Ù†ÙÙ‘ | ØµÙ‡Ù | Ø¹Ù…Ø§ | Ù† | Ø¯ÙˆÙ†Ùƒ | Ø³Ø§Ø¯Ø³ | Ø£Ø³ÙƒÙ† | Ø¬Ù†ÙŠÙ‡ | Ù…Ø§ Ø£ÙØ¹Ù„Ù‡ | Ù‡Ø°Ù‡ | Ù†Ø­Ùˆ | Ø¥ÙŠØ§Ù‡Ù…Ø§ | Ø£ÙˆÙ„Ø¦Ùƒ | Ø§Ù„ØªÙŠ | Ø¥Ø°Ù…Ø§ | Ø«Ù…Ø© | Ø­Ù…Ø¯Ø§ | Ø§Ù„Ù„ØªØ§Ù† | ØªÙÙŠÙ’Ù†Ù | ØªØ¹Ø³Ø§ | Ø£ØµØ¨Ø­ | Ù…ÙƒØ§Ù†ÙƒÙ†Ù‘ | ÙÙˆ | Ø°Ø§Ùƒ | Ù‡ÙŠÙ‡Ø§Øª | ØµØ¨Ø± | Ù‡Ù† | ÙƒÙ…Ø§ | Ù„ÙƒÙ…Ø§ | Ø° | ØªÙŠÙ†Ùƒ | ÙƒØ³Ø§ | ÙŠÙØ¹Ù„Ø§Ù† | Ù…Ù„ÙŠÙ… | Ø¥Ø°Ø§Ù‹ | Ø¥Ù†Ù‡ | Ø£Ù†ØªÙ… | Ø£ÙŠÙ‘Ø§Ù† | Ø§Ù„Ø£Ù„Ø§Ø¡ | Ù‡ÙƒØ°Ø§ | Ø¯ÙŠÙ†Ø§Ø± | Ø¹Ù„Ù… | Ù…Ø¦ØªØ§Ù† | Ø£ÙŠØ§Ø± | Ù„Ù† | Ø¨Ø¹Ø¯Ø§ | ÙˆÙ„ÙƒÙ† | Ø¥Ø° | Ø³Ù‚Ù‰ | Ø¨Ù…Ù† | Ø¥Ù„ÙŠÙƒÙ | Ù„Ø§ | Ø³ØªÙŠÙ† | Ø­ØªÙ‰ | Ù‚Ø¯ | Ø¥Ù„Ø§ | Ø¯Ø±Ù‰ | Ø³Ø¨Ø¹Ù…Ø¦Ø© | Ø«Ù…ÙÙ‘ | Ø£Ø¨ÙŒ | Ø£ØºØ³Ø·Ø³ | Ø±ÙØ¨ÙÙ‘ | Ø§Ù„Ù„Ø°Ø§Ù† | Ø£Ø¶Ø­Ù‰ | Ù‡Ø§ØªÙŠ | Ø³Ø­Ù‚Ø§ | Ù‡ÙØ¤Ù„Ø§Ø¡ | Ø¡Ù | Ù„Ùƒ | Ù‡ÙØ§ØªÙÙŠÙ’Ù†Ù | ÙŠÙˆÙ„ÙŠÙˆ | Ù„Ù…Ù‘Ø§ | Ø°Ù„ÙƒÙ…Ø§ | Ø£Ù‚Ù„ | Ø¹Ø´Ø±Ø© | ÙƒØ£ÙŠÙ‘Ù† | ÙƒØ§Ø¯ | Ù…ÙŠÙ… | Ø£Ù†ØªÙ…Ø§ | ÙŠØ§Ø¡ | Ø¥Ù„Ù‰ | Ø£ÙŠÙ‡Ø§ | Ø¢ | ÙƒØ±Ø¨ | ÙƒÙ„Ù‘Ù…Ø§ | Ùƒ | ÙˆØ¥Ù† | Ø§Ø«Ù†ÙŠÙ† | Ø­Ø²ÙŠØ±Ø§Ù† | Ø£Ø¨Ùˆ | Ø¸Ø§Ø¡ | ÙÙŠ | Ø«Ù„Ø§Ø«Ø§Ø¡ | Ø¥Ø°Ù† | Ø¥ÙŠØ§ÙƒÙ… | Ø¨ÙÙ„Ù’Ù‡Ù | Ø«Ø§Ù† | Ø£Ø±Ø¨Ø¹Ù…Ø§Ø¦Ø© | Ø¬ÙŠÙ… | Ø³Ø¨Ø­Ø§Ù† | ØªÙØ¹Ù„ÙŠÙ† | ØªÙ„ÙƒÙ… | Ù†Ø¨ÙÙ‘Ø§ | ÙØ¥Ø°Ø§ | Ù„ÙƒÙŠ | Ù…Ù…Ù† | Ø¹ | Ø«Ù…Ù‘Ø© | Ø¢Ù‡Ø§Ù‹ | Ø¨Ø³Ù‘ | Ø£Ù | Ø£ÙˆÙ„Ø§Ù„Ùƒ | Ù…Ø§Ø±Ø³ | ÙÙ„Ø§ | Ø£ÙˆÙ‘Ù‡Ù’ | Ù„ÙŠØ³Ø§ | Ø£Ø±Ø¨Ø¹Ø§Ø¡ | ØµØ§Ø¯ | Ø¤ | Ø°ÙÙŠ | Ø¨Ù…Ø§Ø°Ø§ | Ù‡Ù… | ØµØ¨Ø±Ø§ | Ø£ÙŠÙ„ÙˆÙ„ | Ø«Ù…Ø§Ù† | Ø£Ù„ÙÙ‰ | Ù…Ø³Ø§Ø¡ | Ø¡ | Ø¥Ù„ÙŠÙƒÙ† | Ø¬Ù„Ù„ | ØªØ§Ø¡ | Ø§Ù„Ù„ØªÙŠØ§ | Ø£Ù‰ | ØªÙ…ÙˆØ² | Ø¨Ø³ | ØªÙ„Ù‚Ø§Ø¡ | Ø¹Ø§Ø¯ | Ø³ØªÙ…Ø§Ø¦Ø© | Ù„Ù‡Ù…Ø§ | ØªØ¬Ø§Ù‡ | Ù„Ù… | Ø£Ù†ØªÙ† | Ø£ÙØ±ÙŠÙ„ | Ø¢Ù…ÙŠÙ†Ù | Ù„ÙŠØ³ÙˆØ§ | Ù‡Ø¤Ù„Ø§Ø¡ | ÙˆÙØ´Ù’ÙƒÙØ§Ù†Ù | Ù†ÙÙ‘ | Ø³ÙˆÙ‰ | Ø£ÙÙÙ‘ | Ù„Ù‡Ø§ | Ø£Ù… | Ø°Ø§Øª | Ø³Ø¨Ø¹ | Ø¯ÙˆÙ„Ø§Ø± | Ù‡Ù…Ø§ | Ù‡Ù…Ø²Ø© | Ø¥Ù†Ø§ | Ø¨ÙØ³Ù’ | Ø¬Ø§Ù†ÙÙŠ | Ø´ÙØªÙÙ‘Ø§Ù†Ù | Ø¨ØºØªØ© | Ø£ÙˆÙ‡ | ÙƒØ°Ù„Ùƒ | Ø±Ø²Ù‚ | Ø¬Ø¹Ù„ | Ø£ÙØ¹Ù„ Ø¨Ù‡ | ÙƒØ£ÙŠÙ† | Ø°ÙˆØ§ØªÙŠ | Ù„ÙˆÙ…Ø§ | Ø«Ù…Ù‘ | Ù…Ø§ÙØªØ¦ | Ø¢Ù‡ | Ù‡ | Ù‡ÙØ§ØªÙÙ‡ | Ø¥ÙŠØ§ÙƒÙ† | ÙÙ„Ø§Ù† | Ù‚ | Ø¨Ø§Øª | Ø°Ø§Ù†Ùƒ | Ø² | ÙƒØ§Ù | Ø£Ù†Ù‰ | Ø´Ø¨Ù‡ | Ø£Ù†Ø´Ø£ | Ø¹ÙˆØ¶ | Ø§Ù„Ø°ÙŠÙ† | Ø¨ÙƒÙ† | Ø°Ù„ÙƒÙ… | Ø°Ùˆ | ÙƒÙŠØª | ÙŠÙˆØ±Ùˆ | Ù„Ø¯Ù† | Ù„ÙƒÙ† | ÙÙŠÙØ±ÙŠ | ØµÙ‡Ù’ | Ù…Ø±Ù‘Ø© | Ø£Ø®ÙŒ | Ø¥Ù„ÙÙŠÙ’ÙƒÙ | Ø§Ø®Ù„ÙˆÙ„Ù‚ | Ø«Ù…Ø§Ù†ÙŠÙ† | Ø£Ø±Ù‰ | Ø¯ | Ø¹Ù„ | Ø§Ø«Ù†ÙŠ | Ù‡Ø§ØªØ§Ù† | Ø£Ù…Ø§Ù…Ùƒ | Ù…Ù†Ù‡ | ÙƒØ£Ù† | ÙŠÙ…ÙŠÙ† | Ø«Ù…Ø§Ù†ÙŠØ© | Ø«Ù„Ø§Ø«Ù…Ø§Ø¦Ø© | Ùˆ | Ø°ÙŠ | Ù„ÙŠØª | Ù„Ù‡Ù… | Ø§Ø³ØªØ­Ø§Ù„ | Ø°Ø§Ù„ | Ø¥ÙŠØ§Ù‡Ù… | ÙƒÙØ® | Ø«Ù„Ø§Ø«Ø© | Ø¢Ù‡Ù | Ø¥Ù„Ù‘Ø§ | ÙŠÙˆÙ†ÙŠÙˆ | Ø£Ø¨Ø±ÙŠÙ„ | Ù…Ø§ Ø§Ù†ÙÙƒ | Ø®Ø§ØµØ© | ØªØ³Ø¹ÙˆÙ† | Ø²ÙˆØ¯ | Ù…Ø«Ù„ | Ø³Ø¨Ø¹ÙŠÙ† | ÙƒÙ† | ÙƒØ£ÙŠ | Ø¨Ø·Ø¢Ù† | Ù‡Ù„Ù… | ÙƒØ£Ù†Ù‘ | Ø£Ø±Ø¨Ø¹Ù…Ø¦Ø© | Ø§Ù„Ø°ÙŠ | Ø£Ù…Ø³ | Ù…Ù…Ø§ | Ù‡Ø°ÙŠ | Ø¬ÙˆØ§Ù† | Ø¥ÙŠ | Ø§Ù†Ø¨Ø±Ù‰ | Ø¨Ù†Ø§ | ÙˆØ§Ù‡Ø§Ù‹ | Ø­Ø³Ø¨ | ÙˆØ¥Ø°Ø§ | ÙÙ„Ø³ | Ø¥ÙŠÙ‡Ù | Ø§Ø¨ØªØ¯Ø£ | Ø¯ÙŠØ³Ù…Ø¨Ø± | Ù‚Ø§Ù | Ø³Ù†ØªÙŠÙ… | Ø¶Ø­ÙˆØ© | Ù„ÙŠØ³Øª | Ù…Ø§ | Ø¨Ùƒ | Ø·ÙÙ‚ | Ø£ÙÙÙÙ‘ | Ù‡Ø§ØªÙŠÙ† | Ù„Ø§Øª | Ø¨Ù‡Ù† | Ø¨Ù„Ù‰ | ÙˆØ§Ù„Ø°ÙŠ | Ø±ÙŠØ§Ù„ | Ø­ÙŠØ«Ù…Ø§ | Ø³ØªÙˆÙ† | Ø¹Ù„Ù‹Ù‘ | ØªÙ„Ùƒ | Ø§Ø±Ø¨Ø¹ÙˆÙ† | Ø³ÙŠÙ† | Ø´Ù…Ø§Ù„ | Ø§Ù„Ø¢Ù† | Ø¬ÙˆÙŠÙ„ÙŠØ© | Ù‡ÙŠÙ‘Ø§ | Ø¥Ù…Ø§ | Ù‡Ù„Ù‘Ø§ | Ù…ØªÙ‰ | Ù… | Ø­Ù…Ùˆ | Ù„ÙƒÙ†ÙÙ‘ | ØªØ´Ø±ÙŠÙ† | Ø«Ù„Ø§Ø«ÙˆÙ† | Ø§Ø±ØªØ¯Ù‘ | Ø´Ø±Ø¹ | ÙˆØ§Ù„Ø°ÙŠÙ† | Ù…Ø¹ | Ø£Ø­Ø¯ | Ø´ | Ø£Ù†Ø§ | Ø£Ø±Ø¨Ø¹ | Ø«Ù…Ø§Ù†ÙŠ | Ù„Ø³ØªÙ…Ø§ | ÙÙŠÙ‡ | ÙƒÙ„Ø§Ù‡Ù…Ø§ | Ù…Ø§Ø²Ø§Ù„ | ÙÙŠÙ‡Ø§ | ØªØ§Ø³Ø¹ | Ø¢Ù‡Ù | Ù†ÙŠØ³Ø§Ù† | ÙÙŠÙ… | ØµØ¨Ø§Ø­ | ÙÙˆÙ‚ | ØºØ¯Ø§ | Ø´ØªØ§Ù†Ù | Ø¨ÙŠÙ† | Ø£Ø·Ø¹Ù…'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªÙˆÙ‚Ù Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© | Arabic Stopwords in NLTK\n",
    "\n",
    "# Load Arabic stopwords from NLTK\n",
    "Ar_SW1 = set(nltk.corpus.stopwords.words(\"arabic\"))\n",
    "print(len(Ar_SW1))\n",
    "' | '.join(Ar_SW1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9b6ddf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ø¥Ø° | Ø¥Ø°Ø§ | Ø¥Ø°Ù…Ø§ | Ø¥Ø°Ù† | Ø£Ù | Ø£Ù‚Ù„ | Ø£ÙƒØ«Ø± | Ø£Ù„Ø§ | Ø¥Ù„Ø§ | Ø§Ù„ØªÙŠ | Ø§Ù„Ø°ÙŠ | Ø§Ù„Ø°ÙŠÙ† | Ø§Ù„Ù„Ø§ØªÙŠ | Ø§Ù„Ù„Ø§Ø¦ÙŠ | Ø§Ù„Ù„ØªØ§Ù† | Ø§Ù„Ù„ØªÙŠØ§ | Ø§Ù„Ù„ØªÙŠÙ† | Ø§Ù„Ù„Ø°Ø§Ù† | Ø§Ù„Ù„Ø°ÙŠÙ† | Ø§Ù„Ù„ÙˆØ§ØªÙŠ | Ø¥Ù„Ù‰ | Ø¥Ù„ÙŠÙƒ | Ø¥Ù„ÙŠÙƒÙ… | Ø¥Ù„ÙŠÙƒÙ…Ø§ | Ø¥Ù„ÙŠÙƒÙ† | Ø£Ù… | Ø£Ù…Ø§ | Ø£Ù…Ø§ | Ø¥Ù…Ø§ | Ø£Ù† | Ø¥Ù† | Ø¥Ù†Ø§ | Ø£Ù†Ø§ | Ø£Ù†Øª | Ø£Ù†ØªÙ… | Ø£Ù†ØªÙ…Ø§ | Ø£Ù†ØªÙ† | Ø¥Ù†Ù…Ø§ | Ø¥Ù†Ù‡ | Ø£Ù†Ù‰ | Ø£Ù†Ù‰ | Ø¢Ù‡ | Ø¢Ù‡Ø§ | Ø£Ùˆ | Ø£ÙˆÙ„Ø§Ø¡ | Ø£ÙˆÙ„Ø¦Ùƒ | Ø£ÙˆÙ‡ | Ø¢ÙŠ | Ø£ÙŠ | Ø£ÙŠÙ‡Ø§ | Ø¥ÙŠ | Ø£ÙŠÙ† | Ø£ÙŠÙ† | Ø£ÙŠÙ†Ù…Ø§ | Ø¥ÙŠÙ‡ | Ø¨Ø® | Ø¨Ø³ | Ø¨Ø¹Ø¯ | Ø¨Ø¹Ø¶ | Ø¨Ùƒ | Ø¨ÙƒÙ… | Ø¨ÙƒÙ… | Ø¨ÙƒÙ…Ø§ | Ø¨ÙƒÙ† | Ø¨Ù„ | Ø¨Ù„Ù‰ | Ø¨Ù…Ø§ | Ø¨Ù…Ø§Ø°Ø§ | Ø¨Ù…Ù† | Ø¨Ù†Ø§ | Ø¨Ù‡ | Ø¨Ù‡Ø§ | Ø¨Ù‡Ù… | Ø¨Ù‡Ù…Ø§ | Ø¨Ù‡Ù† | Ø¨ÙŠ | Ø¨ÙŠÙ† | Ø¨ÙŠØ¯ | ØªÙ„Ùƒ | ØªÙ„ÙƒÙ… | ØªÙ„ÙƒÙ…Ø§ | ØªÙ‡ | ØªÙŠ | ØªÙŠÙ† | ØªÙŠÙ†Ùƒ | Ø«Ù… | Ø«Ù…Ø© | Ø­Ø§Ø´Ø§ | Ø­Ø¨Ø°Ø§ | Ø­ØªÙ‰ | Ø­ÙŠØ« | Ø­ÙŠØ«Ù…Ø§ | Ø­ÙŠÙ† | Ø®Ù„Ø§ | Ø¯ÙˆÙ† | Ø°Ø§ | Ø°Ø§Øª | Ø°Ø§Ùƒ | Ø°Ø§Ù† | Ø°Ø§Ù†Ùƒ | Ø°Ù„Ùƒ | Ø°Ù„ÙƒÙ… | Ø°Ù„ÙƒÙ…Ø§ | Ø°Ù„ÙƒÙ† | Ø°Ù‡ | Ø°Ùˆ | Ø°ÙˆØ§ | Ø°ÙˆØ§ØªØ§ | Ø°ÙˆØ§ØªÙŠ | Ø°ÙŠ | Ø°ÙŠÙ† | Ø°ÙŠÙ†Ùƒ | Ø±ÙŠØ« | Ø³ÙˆÙ | Ø³ÙˆÙ‰ | Ø´ØªØ§Ù† | Ø¹Ø¯Ø§ | Ø¹Ø³Ù‰ | Ø¹Ù„ | Ø¹Ù„Ù‰ | Ø¹Ù„ÙŠÙƒ | Ø¹Ù„ÙŠÙ‡ | Ø¹Ù…Ø§ | Ø¹Ù† | Ø¹Ù†Ø¯ | ØºÙŠØ± | ÙØ¥Ø°Ø§ | ÙØ¥Ù† | ÙÙ„Ø§ | ÙÙ…Ù† | ÙÙŠ | ÙÙŠÙ… | ÙÙŠÙ…Ø§ | ÙÙŠÙ‡ | ÙÙŠÙ‡Ø§ | Ù‚Ø¯ | ÙƒØ£Ù† | ÙƒØ£Ù†Ù…Ø§ | ÙƒØ£ÙŠ | ÙƒØ£ÙŠÙ† | ÙƒØ°Ø§ | ÙƒØ°Ù„Ùƒ | ÙƒÙ„ | ÙƒÙ„Ø§ | ÙƒÙ„Ø§Ù‡Ù…Ø§ | ÙƒÙ„ØªØ§ | ÙƒÙ„Ù…Ø§ | ÙƒÙ„ÙŠÙƒÙ…Ø§ | ÙƒÙ„ÙŠÙ‡Ù…Ø§ | ÙƒÙ… | ÙƒÙ… | ÙƒÙ…Ø§ | ÙƒÙŠ | ÙƒÙŠØª | ÙƒÙŠÙ | ÙƒÙŠÙÙ…Ø§ | Ù„Ø§ | Ù„Ø§Ø³ÙŠÙ…Ø§ | Ù„Ø¯Ù‰ | Ù„Ø³Øª | Ù„Ø³ØªÙ… | Ù„Ø³ØªÙ…Ø§ | Ù„Ø³ØªÙ† | Ù„Ø³Ù† | Ù„Ø³Ù†Ø§ | Ù„Ø¹Ù„ | Ù„Ùƒ | Ù„ÙƒÙ… | Ù„ÙƒÙ…Ø§ | Ù„ÙƒÙ† | Ù„ÙƒÙ†Ù…Ø§ | Ù„ÙƒÙŠ | Ù„ÙƒÙŠÙ„Ø§ | Ù„Ù… | Ù„Ù…Ø§ | Ù„Ù† | Ù„Ù†Ø§ | Ù„Ù‡ | Ù„Ù‡Ø§ | Ù„Ù‡Ù… | Ù„Ù‡Ù…Ø§ | Ù„Ù‡Ù† | Ù„Ùˆ | Ù„ÙˆÙ„Ø§ | Ù„ÙˆÙ…Ø§ | Ù„ÙŠ | Ù„Ø¦Ù† | Ù„ÙŠØª | Ù„ÙŠØ³ | Ù„ÙŠØ³Ø§ | Ù„ÙŠØ³Øª | Ù„ÙŠØ³ØªØ§ | Ù„ÙŠØ³ÙˆØ§ | Ù…Ø§ | Ù…Ø§Ø°Ø§ | Ù…ØªÙ‰ | Ù…Ø° | Ù…Ø¹ | Ù…Ù…Ø§ | Ù…Ù…Ù† | Ù…Ù† | Ù…Ù†Ù‡ | Ù…Ù†Ù‡Ø§ | Ù…Ù†Ø° | Ù…Ù‡ | Ù…Ù‡Ù…Ø§ | Ù†Ø­Ù† | Ù†Ø­Ùˆ | Ù†Ø¹Ù… | Ù‡Ø§ | Ù‡Ø§ØªØ§Ù† | Ù‡Ø§ØªÙ‡ | Ù‡Ø§ØªÙŠ | Ù‡Ø§ØªÙŠÙ† | Ù‡Ø§Ùƒ | Ù‡Ø§Ù‡Ù†Ø§ | Ù‡Ø°Ø§ | Ù‡Ø°Ø§Ù† | Ù‡Ø°Ù‡ | Ù‡Ø°ÙŠ | Ù‡Ø°ÙŠÙ† | Ù‡ÙƒØ°Ø§ | Ù‡Ù„ | Ù‡Ù„Ø§ | Ù‡Ù… | Ù‡Ù…Ø§ | Ù‡Ù† | Ù‡Ù†Ø§ | Ù‡Ù†Ø§Ùƒ | Ù‡Ù†Ø§Ù„Ùƒ | Ù‡Ùˆ | Ù‡Ø¤Ù„Ø§Ø¡ | Ù‡ÙŠ | Ù‡ÙŠØ§ | Ù‡ÙŠØª | Ù‡ÙŠÙ‡Ø§Øª | ÙˆØ§Ù„Ø°ÙŠ | ÙˆØ§Ù„Ø°ÙŠÙ† | ÙˆØ¥Ø° | ÙˆØ¥Ø°Ø§ | ÙˆØ¥Ù† | ÙˆÙ„Ø§ | ÙˆÙ„ÙƒÙ† | ÙˆÙ„Ùˆ | ÙˆÙ…Ø§ | ÙˆÙ…Ù† | ÙˆÙ‡Ùˆ | ÙŠØ§ | Ø£Ø¨ÙŒ | Ø£Ø®ÙŒ | Ø­Ù…ÙŒ | ÙÙˆ | Ø£Ù†ØªÙ | ÙŠÙ†Ø§ÙŠØ± | ÙØ¨Ø±Ø§ÙŠØ± | Ù…Ø§Ø±Ø³ | Ø£Ø¨Ø±ÙŠÙ„ | Ù…Ø§ÙŠÙˆ | ÙŠÙˆÙ†ÙŠÙˆ | ÙŠÙˆÙ„ÙŠÙˆ | Ø£ØºØ³Ø·Ø³ | Ø³Ø¨ØªÙ…Ø¨Ø± | Ø£ÙƒØªÙˆØ¨Ø± | Ù†ÙˆÙÙ…Ø¨Ø± | Ø¯ÙŠØ³Ù…Ø¨Ø± | Ø¬Ø§Ù†ÙÙŠ | ÙÙŠÙØ±ÙŠ | Ù…Ø§Ø±Ø³ | Ø£ÙØ±ÙŠÙ„ | Ù…Ø§ÙŠ | Ø¬ÙˆØ§Ù† | Ø¬ÙˆÙŠÙ„ÙŠØ© | Ø£ÙˆØª | ÙƒØ§Ù†ÙˆÙ† | Ø´Ø¨Ø§Ø· | Ø¢Ø°Ø§Ø± | Ù†ÙŠØ³Ø§Ù† | Ø£ÙŠØ§Ø± | Ø­Ø²ÙŠØ±Ø§Ù† | ØªÙ…ÙˆØ² | Ø¢Ø¨ | Ø£ÙŠÙ„ÙˆÙ„ | ØªØ´Ø±ÙŠÙ† | Ø¯ÙˆÙ„Ø§Ø± | Ø¯ÙŠÙ†Ø§Ø± | Ø±ÙŠØ§Ù„ | Ø¯Ø±Ù‡Ù… | Ù„ÙŠØ±Ø© | Ø¬Ù†ÙŠÙ‡ | Ù‚Ø±Ø´ | Ù…Ù„ÙŠÙ… | ÙÙ„Ø³ | Ù‡Ù„Ù„Ø© | Ø³Ù†ØªÙŠÙ… | ÙŠÙˆØ±Ùˆ | ÙŠÙ† | ÙŠÙˆØ§Ù† | Ø´ÙŠÙƒÙ„ | ÙˆØ§Ø­Ø¯ | Ø§Ø«Ù†Ø§Ù† | Ø«Ù„Ø§Ø«Ø© | Ø£Ø±Ø¨Ø¹Ø© | Ø®Ù…Ø³Ø© | Ø³ØªØ© | Ø³Ø¨Ø¹Ø© | Ø«Ù…Ø§Ù†ÙŠØ© | ØªØ³Ø¹Ø© | Ø¹Ø´Ø±Ø© | Ø£Ø­Ø¯ | Ø§Ø«Ù†Ø§ | Ø§Ø«Ù†ÙŠ | Ø¥Ø­Ø¯Ù‰ | Ø«Ù„Ø§Ø« | Ø£Ø±Ø¨Ø¹ | Ø®Ù…Ø³ | Ø³Øª | Ø³Ø¨Ø¹ | Ø«Ù…Ø§Ù†ÙŠ | ØªØ³Ø¹ | Ø¹Ø´Ø± | Ø«Ù…Ø§Ù† | Ø³Ø¨Øª | Ø£Ø­Ø¯ | Ø§Ø«Ù†ÙŠÙ† | Ø«Ù„Ø§Ø«Ø§Ø¡ | Ø£Ø±Ø¨Ø¹Ø§Ø¡ | Ø®Ù…ÙŠØ³ | Ø¬Ù…Ø¹Ø© | Ø£ÙˆÙ„ | Ø«Ø§Ù† | Ø«Ø§Ù†ÙŠ | Ø«Ø§Ù„Ø« | Ø±Ø§Ø¨Ø¹ | Ø®Ø§Ù…Ø³ | Ø³Ø§Ø¯Ø³ | Ø³Ø§Ø¨Ø¹ | Ø«Ø§Ù…Ù† | ØªØ§Ø³Ø¹ | Ø¹Ø§Ø´Ø± | Ø­Ø§Ø¯ÙŠ | Ø£ | Ø¨ | Øª | Ø« | Ø¬ | Ø­ | Ø® | Ø¯ | Ø° | Ø± | Ø² | Ø³ | Ø´ | Øµ | Ø¶ | Ø· | Ø¸ | Ø¹ | Øº | Ù | Ù‚ | Ùƒ | Ù„ | Ù… | Ù† | Ù‡ | Ùˆ | ÙŠ | Ø¡ | Ù‰ | Ø¢ | Ø¤ | Ø¦ | Ø£ | Ø© | Ø£Ù„Ù | Ø¨Ø§Ø¡ | ØªØ§Ø¡ | Ø«Ø§Ø¡ | Ø¬ÙŠÙ… | Ø­Ø§Ø¡ | Ø®Ø§Ø¡ | Ø¯Ø§Ù„ | Ø°Ø§Ù„ | Ø±Ø§Ø¡ | Ø²Ø§ÙŠ | Ø³ÙŠÙ† | Ø´ÙŠÙ† | ØµØ§Ø¯ | Ø¶Ø§Ø¯ | Ø·Ø§Ø¡ | Ø¸Ø§Ø¡ | Ø¹ÙŠÙ† | ØºÙŠÙ† | ÙØ§Ø¡ | Ù‚Ø§Ù | ÙƒØ§Ù | Ù„Ø§Ù… | Ù…ÙŠÙ… | Ù†ÙˆÙ† | Ù‡Ø§Ø¡ | ÙˆØ§Ùˆ | ÙŠØ§Ø¡ | Ù‡Ù…Ø²Ø© | ÙŠ | Ù†Ø§ | Ùƒ | ÙƒÙ† | Ù‡ | Ø¥ÙŠØ§Ù‡ | Ø¥ÙŠØ§Ù‡Ø§ | Ø¥ÙŠØ§Ù‡Ù…Ø§ | Ø¥ÙŠØ§Ù‡Ù… | Ø¥ÙŠØ§Ù‡Ù† | Ø¥ÙŠØ§Ùƒ | Ø¥ÙŠØ§ÙƒÙ…Ø§ | Ø¥ÙŠØ§ÙƒÙ… | Ø¥ÙŠØ§Ùƒ | Ø¥ÙŠØ§ÙƒÙ† | Ø¥ÙŠØ§ÙŠ | Ø¥ÙŠØ§Ù†Ø§ | Ø£ÙˆÙ„Ø§Ù„Ùƒ | ØªØ§Ù†Ù | ØªØ§Ù†ÙÙƒ | ØªÙÙ‡ | ØªÙÙŠ | ØªÙÙŠÙ’Ù†Ù | Ø«Ù…Ù‘ | Ø«Ù…Ù‘Ø© | Ø°Ø§Ù†Ù | Ø°ÙÙ‡ | Ø°ÙÙŠ | Ø°ÙÙŠÙ’Ù†Ù | Ù‡ÙØ¤Ù„Ø§Ø¡ | Ù‡ÙØ§ØªØ§Ù†Ù | Ù‡ÙØ§ØªÙÙ‡ | Ù‡ÙØ§ØªÙÙŠ | Ù‡ÙØ§ØªÙÙŠÙ’Ù†Ù | Ù‡ÙØ°Ø§ | Ù‡ÙØ°Ø§Ù†Ù | Ù‡ÙØ°ÙÙ‡ | Ù‡ÙØ°ÙÙŠ | Ù‡ÙØ°ÙÙŠÙ’Ù†Ù | Ø§Ù„Ø£Ù„Ù‰ | Ø§Ù„Ø£Ù„Ø§Ø¡ | Ø£Ù„ | Ø£Ù†Ù‘Ù‰ | Ø£ÙŠÙ‘ | Ù‘Ø£ÙŠÙ‘Ø§Ù† | Ø£Ù†Ù‘Ù‰ | Ø£ÙŠÙ‘ | Ù‘Ø£ÙŠÙ‘Ø§Ù† | Ø°ÙŠØª | ÙƒØ£ÙŠÙ‘ | ÙƒØ£ÙŠÙ‘Ù† | Ø¨Ø¶Ø¹ | ÙÙ„Ø§Ù† | ÙˆØ§ | Ø¢Ù…ÙŠÙ†Ù | Ø¢Ù‡Ù | Ø¢Ù‡Ù | Ø¢Ù‡Ø§Ù‹ | Ø£ÙÙÙÙ‘ | Ø£ÙÙÙÙ‘ | Ø£ÙÙÙ‘ | Ø£Ù…Ø§Ù…Ùƒ | Ø£Ù…Ø§Ù…ÙƒÙ | Ø£ÙˆÙ‘Ù‡Ù’ | Ø¥Ù„ÙÙŠÙ’ÙƒÙ | Ø¥Ù„ÙÙŠÙ’ÙƒÙ | Ø¥Ù„ÙŠÙƒÙ | Ø¥Ù„ÙŠÙƒÙ†Ù‘ | Ø¥ÙŠÙ‡Ù | Ø¨Ø®Ù | Ø¨Ø³Ù‘ | Ø¨ÙØ³Ù’ | Ø¨Ø·Ø¢Ù† | Ø¨ÙÙ„Ù’Ù‡Ù | Ø­Ø§ÙŠ | Ø­ÙØ°Ø§Ø±Ù | Ø­ÙŠÙÙ‘ | Ø­ÙŠÙÙ‘ | Ø¯ÙˆÙ†Ùƒ | Ø±ÙˆÙŠØ¯Ùƒ | Ø³Ø±Ø¹Ø§Ù† | Ø´ØªØ§Ù†Ù | Ø´ÙØªÙÙ‘Ø§Ù†Ù | ØµÙ‡Ù’ | ØµÙ‡Ù | Ø·Ø§Ù‚ | Ø·ÙÙ‚ | Ø¹ÙØ¯ÙØ³Ù’ | ÙƒÙØ® | Ù…ÙƒØ§Ù†ÙÙƒ | Ù…ÙƒØ§Ù†ÙÙƒ | Ù…ÙƒØ§Ù†ÙÙƒ | Ù…ÙƒØ§Ù†ÙƒÙ… | Ù…ÙƒØ§Ù†ÙƒÙ…Ø§ | Ù…ÙƒØ§Ù†ÙƒÙ†Ù‘ | Ù†ÙØ®Ù’ | Ù‡Ø§ÙƒÙ | Ù‡ÙØ¬Ù’ | Ù‡Ù„Ù… | Ù‡ÙŠÙ‘Ø§ | Ù‡ÙÙŠÙ’Ù‡Ø§Øª | ÙˆØ§ | ÙˆØ§Ù‡Ø§Ù‹ | ÙˆØ±Ø§Ø¡ÙÙƒ | ÙˆÙØ´Ù’ÙƒÙØ§Ù†Ù | ÙˆÙÙŠÙ’ | ÙŠÙØ¹Ù„Ø§Ù† | ØªÙØ¹Ù„Ø§Ù† | ÙŠÙØ¹Ù„ÙˆÙ† | ØªÙØ¹Ù„ÙˆÙ† | ØªÙØ¹Ù„ÙŠÙ† | Ø§ØªØ®Ø° | Ø£Ù„ÙÙ‰ | ØªØ®Ø° | ØªØ±Ùƒ | ØªØ¹Ù„ÙÙ‘Ù… | Ø¬Ø¹Ù„ | Ø­Ø¬Ø§ | Ø­Ø¨ÙŠØ¨ | Ø®Ø§Ù„ | Ø­Ø³Ø¨ | Ø®Ø§Ù„ | Ø¯Ø±Ù‰ | Ø±Ø£Ù‰ | Ø²Ø¹Ù… | ØµØ¨Ø± | Ø¸Ù†ÙÙ‘ | Ø¹Ø¯ÙÙ‘ | Ø¹Ù„Ù… | ØºØ§Ø¯Ø± | Ø°Ù‡Ø¨ | ÙˆØ¬Ø¯ | ÙˆØ±Ø¯ | ÙˆÙ‡Ø¨ | Ø£Ø³ÙƒÙ† | Ø£Ø·Ø¹Ù… | Ø£Ø¹Ø·Ù‰ | Ø±Ø²Ù‚ | Ø²ÙˆØ¯ | Ø³Ù‚Ù‰ | ÙƒØ³Ø§ | Ø£Ø®Ø¨Ø± | Ø£Ø±Ù‰ | Ø£Ø¹Ù„Ù… | Ø£Ù†Ø¨Ø£ | Ø­Ø¯ÙØ« | Ø®Ø¨ÙÙ‘Ø± | Ù†Ø¨ÙÙ‘Ø§ | Ø£ÙØ¹Ù„ Ø¨Ù‡ | Ù…Ø§ Ø£ÙØ¹Ù„Ù‡ | Ø¨Ø¦Ø³ | Ø³Ø§Ø¡ | Ø·Ø§Ù„Ù…Ø§ | Ù‚Ù„Ù…Ø§ | Ù„Ø§Øª | Ù„ÙƒÙ†ÙÙ‘ | Ø¡Ù | Ø£Ø¬Ù„ | Ø¥Ø°Ø§Ù‹ | Ø£Ù…Ù‘Ø§ | Ø¥Ù…Ù‘Ø§ | Ø¥Ù†ÙÙ‘ | Ø£Ù†Ù‹Ù‘ | Ø£Ù‰ | Ø¥Ù‰ | Ø£ÙŠØ§ | Ø¨ | Ø«Ù…ÙÙ‘ | Ø¬Ù„Ù„ | Ø¬ÙŠØ± | Ø±ÙØ¨ÙÙ‘ | Ø³ | Ø¹Ù„Ù‹Ù‘ | Ù | ÙƒØ£Ù†Ù‘ | ÙƒÙ„ÙÙ‘Ø§ | ÙƒÙ‰ | Ù„ | Ù„Ø§Øª | Ù„Ø¹Ù„ÙÙ‘ | Ù„ÙƒÙ†ÙÙ‘ | Ù„ÙƒÙ†ÙÙ‘ | Ù… | Ù†ÙÙ‘ | Ù‡Ù„Ù‘Ø§ | ÙˆØ§ | Ø£Ù„ | Ø¥Ù„Ù‘Ø§ | Øª | Ùƒ | Ù„Ù…Ù‘Ø§ | Ù† | Ù‡ | Ùˆ | Ø§ | ÙŠ | ØªØ¬Ø§Ù‡ | ØªÙ„Ù‚Ø§Ø¡ | Ø¬Ù…ÙŠØ¹ | Ø­Ø³Ø¨ | Ø³Ø¨Ø­Ø§Ù† | Ø´Ø¨Ù‡ | Ù„Ø¹Ù…Ø± | Ù…Ø«Ù„ | Ù…Ø¹Ø§Ø° | Ø£Ø¨Ùˆ | Ø£Ø®Ùˆ | Ø­Ù…Ùˆ | ÙÙˆ | Ù…Ø¦Ø© | Ù…Ø¦ØªØ§Ù† | Ø«Ù„Ø§Ø«Ù…Ø¦Ø© | Ø£Ø±Ø¨Ø¹Ù…Ø¦Ø© | Ø®Ù…Ø³Ù…Ø¦Ø© | Ø³ØªÙ…Ø¦Ø© | Ø³Ø¨Ø¹Ù…Ø¦Ø© | Ø«Ù…Ù†Ù…Ø¦Ø© | ØªØ³Ø¹Ù…Ø¦Ø© | Ù…Ø§Ø¦Ø© | Ø«Ù„Ø§Ø«Ù…Ø§Ø¦Ø© | Ø£Ø±Ø¨Ø¹Ù…Ø§Ø¦Ø© | Ø®Ù…Ø³Ù…Ø§Ø¦Ø© | Ø³ØªÙ…Ø§Ø¦Ø© | Ø³Ø¨Ø¹Ù…Ø§Ø¦Ø© | Ø«Ù…Ø§Ù†Ù…Ø¦Ø© | ØªØ³Ø¹Ù…Ø§Ø¦Ø© | Ø¹Ø´Ø±ÙˆÙ† | Ø«Ù„Ø§Ø«ÙˆÙ† | Ø§Ø±Ø¨Ø¹ÙˆÙ† | Ø®Ù…Ø³ÙˆÙ† | Ø³ØªÙˆÙ† | Ø³Ø¨Ø¹ÙˆÙ† | Ø«Ù…Ø§Ù†ÙˆÙ† | ØªØ³Ø¹ÙˆÙ† | Ø¹Ø´Ø±ÙŠÙ† | Ø«Ù„Ø§Ø«ÙŠÙ† | Ø§Ø±Ø¨Ø¹ÙŠÙ† | Ø®Ù…Ø³ÙŠÙ† | Ø³ØªÙŠÙ† | Ø³Ø¨Ø¹ÙŠÙ† | Ø«Ù…Ø§Ù†ÙŠÙ† | ØªØ³Ø¹ÙŠÙ† | Ø¨Ø¶Ø¹ | Ù†ÙŠÙ | Ø£Ø¬Ù…Ø¹ | Ø¬Ù…ÙŠØ¹ | Ø¹Ø§Ù…Ø© | Ø¹ÙŠÙ† | Ù†ÙØ³ | Ù„Ø§ Ø³ÙŠÙ…Ø§ | Ø£ØµÙ„Ø§ | Ø£Ù‡Ù„Ø§ | Ø£ÙŠØ¶Ø§ | Ø¨Ø¤Ø³Ø§ | Ø¨Ø¹Ø¯Ø§ | Ø¨ØºØªØ© | ØªØ¹Ø³Ø§ | Ø­Ù‚Ø§ | Ø­Ù…Ø¯Ø§ | Ø®Ù„Ø§ÙØ§ | Ø®Ø§ØµØ© | Ø¯ÙˆØ§Ù„ÙŠÙƒ | Ø³Ø­Ù‚Ø§ | Ø³Ø±Ø§ | Ø³Ù…Ø¹Ø§ | ØµØ¨Ø±Ø§ | ØµØ¯Ù‚Ø§ | ØµØ±Ø§Ø­Ø© | Ø·Ø±Ø§ | Ø¹Ø¬Ø¨Ø§ | Ø¹ÙŠØ§Ù†Ø§ | ØºØ§Ù„Ø¨Ø§ | ÙØ±Ø§Ø¯Ù‰ | ÙØ¶Ù„Ø§ | Ù‚Ø§Ø·Ø¨Ø© | ÙƒØ«ÙŠØ±Ø§ | Ù„Ø¨ÙŠÙƒ | Ù…Ø¹Ø§Ø° | Ø£Ø¨Ø¯Ø§ | Ø¥Ø²Ø§Ø¡ | Ø£ØµÙ„Ø§ | Ø§Ù„Ø¢Ù† | Ø£Ù…Ø¯ | Ø£Ù…Ø³ | Ø¢Ù†ÙØ§ | Ø¢Ù†Ø§Ø¡ | Ø£Ù†Ù‘Ù‰ | Ø£ÙˆÙ„ | Ø£ÙŠÙ‘Ø§Ù† | ØªØ§Ø±Ø© | Ø«Ù…Ù‘ | Ø«Ù…Ù‘Ø© | Ø­Ù‚Ø§ | ØµØ¨Ø§Ø­ | Ù…Ø³Ø§Ø¡ | Ø¶Ø­ÙˆØ© | Ø¹ÙˆØ¶ | ØºØ¯Ø§ | ØºØ¯Ø§Ø© | Ù‚Ø·Ù‘ | ÙƒÙ„Ù‘Ù…Ø§ | Ù„Ø¯Ù† | Ù„Ù…Ù‘Ø§ | Ù…Ø±Ù‘Ø© | Ù‚Ø¨Ù„ | Ø®Ù„Ù | Ø£Ù…Ø§Ù… | ÙÙˆÙ‚ | ØªØ­Øª | ÙŠÙ…ÙŠÙ† | Ø´Ù…Ø§Ù„ | Ø§Ø±ØªØ¯Ù‘ | Ø§Ø³ØªØ­Ø§Ù„ | Ø£ØµØ¨Ø­ | Ø£Ø¶Ø­Ù‰ | Ø¢Ø¶ | Ø£Ù…Ø³Ù‰ | Ø§Ù†Ù‚Ù„Ø¨ | Ø¨Ø§Øª | ØªØ¨Ø¯Ù‘Ù„ | ØªØ­ÙˆÙ‘Ù„ | Ø­Ø§Ø± | Ø±Ø¬Ø¹ | Ø±Ø§Ø­ | ØµØ§Ø± | Ø¸Ù„Ù‘ | Ø¹Ø§Ø¯ | ØºØ¯Ø§ | ÙƒØ§Ù† | Ù…Ø§ Ø§Ù†ÙÙƒ | Ù…Ø§ Ø¨Ø±Ø­ | Ù…Ø§Ø¯Ø§Ù… | Ù…Ø§Ø²Ø§Ù„ | Ù…Ø§ÙØªØ¦ | Ø§Ø¨ØªØ¯Ø£ | Ø£Ø®Ø° | Ø§Ø®Ù„ÙˆÙ„Ù‚ | Ø£Ù‚Ø¨Ù„ | Ø§Ù†Ø¨Ø±Ù‰ | Ø£Ù†Ø´Ø£ | Ø£ÙˆØ´Ùƒ | Ø¬Ø¹Ù„ | Ø­Ø±Ù‰ | Ø´Ø±Ø¹ | Ø·ÙÙ‚ | Ø¹Ù„Ù‚ | Ù‚Ø§Ù… | ÙƒØ±Ø¨ | ÙƒØ§Ø¯ | Ù‡Ø¨Ù‘'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ù†Ø³Ø®Ø© Ø£Ø®Ø±Ù‰ (248 ÙƒÙ„Ù…Ø©) | Another Arabic List (248 words)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "Ar_SW2 = stopwords.words('arabic')\n",
    "print(len(Ar_SW2))\n",
    "' | '.join(Ar_SW2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e4de45",
   "metadata": {},
   "source": [
    "### ğŸ§± Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙƒØªØ¨Ø© arabicstopwords | ArabicStopwords Library\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ Ù…ÙƒØªØ¨Ø© Ù…ØªØ®ØµØµØ© ÙÙŠ ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªÙˆÙ‚Ù Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©ØŒ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£ÙƒØ«Ø± Ù…Ù† **13,000 ÙƒÙ„Ù…Ø© ÙˆØªØµØ±ÙŠÙØ§ØªÙ‡Ø§**.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ A specialized Arabic stopword library containing **13,000+ words and forms**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1f3f785f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement arabicstopwords (from versions: none)\n",
      "ERROR: No matching distribution found for arabicstopwords\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'arabicstopwords'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Install the library (once)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install arabicstopwords\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01marabicstopwords\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marabicstopwords\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mstp\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# View classed Arabic stopwords\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mlen\u001b[39m(stp\u001b[38;5;241m.\u001b[39mclassed_stopwords_list())  \u001b[38;5;66;03m# 507\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'arabicstopwords'"
     ]
    }
   ],
   "source": [
    "# Install the library (once)\n",
    "!pip install arabicstopwords\n",
    "\n",
    "\n",
    "import arabicstopwords.arabicstopwords as stp\n",
    "\n",
    "# View classed Arabic stopwords\n",
    "len(stp.classed_stopwords_list())  # 507\n",
    "stp.classed_stopwords_list()\n",
    "\n",
    "# View full list (13,000+)\n",
    "len(stp.stopwords_list())  # 13629\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daa5461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ÙƒÙ„Ù…Ø§Øª | Checking Arabic Words\n",
    "\n",
    "stp.is_stop(u'Ù…Ù…ÙƒÙ†')   # False âŒ\n",
    "stp.is_stop(u'Ù…Ù†ÙƒÙ…')   # True âœ…\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092d3fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all forms of a word\n",
    "stp.stopword_forms(u\"Ø¹Ù„Ù‰\")\n",
    "len(stp.stopword_forms(u\"Ø¹Ù„Ù‰\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0a65da",
   "metadata": {},
   "source": [
    "ğŸ“Š **Ø§Ù„Ù†ØªÙŠØ¬Ø©:**\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ ØªØ¸Ù‡Ø± Ø¬Ù…ÙŠØ¹ ØªØµØ±ÙŠÙØ§Øª Ø§Ù„ÙƒÙ„Ù…Ø© Ù…Ø«Ù„ (Ø¹Ù„ÙŠÙ‡Ø§ØŒ Ø¹Ù„ÙŠÙ‡ØŒ Ø¹Ù„ÙŠÙ‡Ù…...)\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ Displays all inflected forms (e.g., Ø¹Ù„ÙŠÙ‡Ø§, Ø¹Ù„ÙŠÙ‡, Ø¹Ù„ÙŠÙ‡Ù…...)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe98482b",
   "metadata": {},
   "source": [
    "### ğŸ§  Ù…Ù„Ø®Øµ Ø§Ù„Ù‚Ø³Ù… | Section Summary\n",
    "\n",
    "| ğŸ‡¸ğŸ‡¦ Ø§Ù„Ù…ÙÙ‡ÙˆÙ…        | ğŸ‡¬ğŸ‡§ Concept             | ğŸ’¡ Ø§Ù„ØªÙˆØ¶ÙŠØ­                           |\n",
    "| ------------------- | ------------------------ | ------------------------------------ |\n",
    "| **Stopwords**       | Common Words             | ÙƒÙ„Ù…Ø§Øª Ù…ØªÙƒØ±Ø±Ø© Ù„Ø§ ØªØ­Ù…Ù„ Ù…Ø¹Ù†Ù‰ Ù‚ÙˆÙŠ        |\n",
    "| **spaCy**           | Built-in list            | ØªØ­ØªÙˆÙŠ Ø£ÙƒØ«Ø± Ù…Ù† 300 ÙƒÙ„Ù…Ø© ØªÙˆÙ‚Ù Ø§ÙØªØ±Ø§Ø¶ÙŠØ© |\n",
    "| **NLTK**            | English & Arabic support | ØªØ¯Ø¹Ù… Ù„ØºØ§Øª Ù…ØªØ¹Ø¯Ø¯Ø© Ø¨Ù…Ø§ ÙÙŠÙ‡Ø§ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©    |\n",
    "| **arabicstopwords** | Extensive library        | ØªØ­ØªÙˆÙŠ Ø£ÙƒØ«Ø± Ù…Ù† 13 Ø£Ù„Ù ÙƒÙ„Ù…Ø© ÙˆØªØµØ±ÙŠÙÙ‡Ø§   |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdf99f0",
   "metadata": {},
   "source": [
    "## ğŸ§© Ø§Ù„Ù‚Ø³Ù… Ø§Ù„Ø³Ø§Ø¨Ø¹: Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø£Ù†Ù…Ø§Ø· ÙˆØ§Ù„Ø¹Ø¨Ø§Ø±Ø§Øª | Word & Phrase Matchers\n",
    "---\n",
    "\n",
    "##  ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù€ Matcher (Ø§Ø±ØªØ¨Ø§Ø· Ø§Ù„ÙƒÙ„Ù…Ø§Øª) \n",
    "\n",
    "> ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© (NLP)ØŒ ØªÙØ¹Ø¯ Ø£Ø¯Ø§Ø© **Matcher** Ù…Ù† Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù‚ÙˆÙŠØ© ÙÙŠ Ù…ÙƒØªØ¨Ø© **spaCy**ØŒ\n",
    "> ÙˆÙ‡ÙŠ ØªÙØ³ØªØ®Ø¯Ù… Ù„Ù„Ø¨Ø­Ø« Ø¯Ø§Ø®Ù„ Ø§Ù„Ù†Øµ Ø¹Ù† **Ø£Ù†Ù…Ø§Ø· Ù…Ø­Ø¯Ø¯Ø© (Patterns)** â€”\n",
    "> Ù„ÙŠØ³ ÙÙ‚Ø· ÙƒÙ„Ù…Ø§Øª Ù…ÙØ±Ø¯Ø©ØŒ Ø¨Ù„ **ØªØ³Ù„Ø³Ù„ Ø£Ùˆ Ø´ÙƒÙ„ Ù…Ø¹ÙŠÙ† Ù…Ù† Ø§Ù„ÙƒÙ„Ù…Ø§Øª**.\n",
    ">\n",
    "> ÙŠÙ…ÙƒÙ†Ù†Ø§ Ù…Ù† Ø®Ù„Ø§Ù„Ù‡Ø§ ØªØ­Ø¯ÙŠØ¯ Ù‚ÙˆØ§Ø¹Ø¯ Ù„ØºÙˆÙŠØ© Ù…Ø«Ù„:\n",
    ">\n",
    "> * ÙƒÙ„Ù…Ø© Ù…Ø¹ÙŠÙ‘Ù†Ø© Ù…ØªØ¨ÙˆØ¹Ø© Ø¨ØµÙØ©\n",
    "> * ØªØ±ÙƒÙŠØ¨ Ù…Ø¹ÙŠÙ† (Ù…Ø«Ù„ Ø§Ø³Ù… + ÙØ¹Ù„)\n",
    "> * Ø£Ùˆ Ø­ØªÙ‰ Ù…Ø¬Ù…ÙˆØ¹Ø© ÙƒÙ„Ù…Ø§Øª ØªØ¹Ø¨Ù‘Ø± Ø¹Ù† Ù…ÙÙ‡ÙˆÙ… ÙˆØ§Ø­Ø¯ Ø±ØºÙ… Ø§Ø®ØªÙ„Ø§Ù ÙƒØªØ§Ø¨ØªÙ‡Ø§.\n",
    ">\n",
    "> ğŸ§  ÙˆØ¨Ø´ÙƒÙ„ Ø¹Ù…Ù„ÙŠØŒ ØªØ³Ø§Ø¹Ø¯ Ø§Ù„Ù€ Matcher ÙÙŠ **ØªÙˆØ­ÙŠØ¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ© Ø§Ù„ØªÙŠ ØªØ­Ù…Ù„ Ù†ÙØ³ Ø§Ù„Ù…Ø¹Ù†Ù‰**ØŒ\n",
    "> Ù…Ø«Ù„ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©:\n",
    ">\n",
    "> * â€œØ¹Ø¨Ø¯Ø§Ù„Ù„Ù‡â€ Ùˆ â€œØ¹Ø¨Ø¯ Ø§Ù„Ù„Ù‡â€ Ùˆ â€œØ¹Ø¨Ø¯ Ø§Ù„Ø¥Ù„Ù‡â€\n",
    "> * â€œØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ØµÙ†Ø§Ø¹ÙŠâ€ Ùˆ â€œØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø¥ØµØ·Ù†Ø§Ø¹ÙŠâ€ Ùˆ â€œØ§Ù„Ø°ÙƒØ§Ø¡Ø§Ù„Ø¥ØµØ·Ù†Ø§Ø¹ÙŠâ€\n",
    ">\n",
    "> Ø£ÙŠ Ø£Ù†Ù‡Ø§ Ø£Ø¯Ø§Ø© ØªØ³Ù…Ø­ Ù„Ù„Ù†Ø¸Ø§Ù… **Ø¨ÙÙ‡Ù… Ø£Ù† Ù‡Ø°Ù‡ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ© ØªØ´ÙŠØ± Ø¥Ù„Ù‰ Ù†ÙØ³ Ø§Ù„Ù…ÙÙ‡ÙˆÙ…**ØŒ\n",
    "> Ø­ØªÙ‰ ÙˆØ¥Ù† Ø§Ø®ØªÙ„ÙØª Ø·Ø±ÙŠÙ‚Ø© ÙƒØªØ§Ø¨ØªÙ‡Ø§ Ø£Ùˆ ØªØ±ØªÙŠØ¨Ù‡Ø§ Ø£Ùˆ Ø§Ø­ØªÙˆØª Ø¹Ù„Ù‰ Ø¹Ù„Ø§Ù…Ø§Øª ØªØ±Ù‚ÙŠÙ….\n",
    ">\n",
    "> ğŸ”¹ Ø¨Ø¹Ø¨Ø§Ø±Ø© Ø£Ø®Ø±Ù‰:\n",
    ">\n",
    "> > Ø§Ù„Ù€ **Matcher** Ù‡Ùˆ Ù†Ø¸Ø§Ù… **Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø¨Ù†ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ (Rule-based Pattern Matching)**\n",
    "> > ÙŠÙØ³ØªØ®Ø¯Ù… Ù„Ø§ÙƒØªØ´Ø§Ù Ø§Ù„ØªØ±Ø§ÙƒÙŠØ¨ Ø£Ùˆ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù„ØºÙˆÙŠØ© Ø¯Ø§Ø®Ù„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ø³ØªÙ†Ø§Ø¯Ù‹Ø§ Ø¥Ù„Ù‰ Ø®ØµØ§Ø¦Øµ Ø§Ù„ÙƒÙ„Ù…Ø§Øª (Ù…Ø«Ù„ Ø´ÙƒÙ„Ù‡Ø§ØŒ Ù†ÙˆØ¹Ù‡Ø§ØŒ ØªØ±ØªÙŠØ¨Ù‡Ø§ØŒ Ø£Ùˆ Ø¹Ù„Ø§Ù…Ø§ØªÙ‡Ø§).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "19cb1e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library and create a Matcher object\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "matcher = Matcher(nlp.vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "04d2b97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word ID 8656102463236116519, starts at 1, ends at 3, and word is Solar Power\n",
      "Word ID 8656102463236116519, starts at 10, ends at 11, and word is solarpower\n",
      "Word ID 8656102463236116519, starts at 13, ends at 16, and word is Solar-power\n"
     ]
    }
   ],
   "source": [
    "# Ø¥Ù†Ø´Ø§Ø¡ Ø£Ù†Ù…Ø§Ø· Ù…ØªØ¹Ø¯Ø¯Ø© | Defining Multiple Patterns\n",
    "\n",
    "# Define patterns for \"Solar Power\"\n",
    "pattern1 = [{'LOWER': 'solarpower'}]\n",
    "pattern2 = [{'LOWER': 'solar'}, {'LOWER': 'power'}]\n",
    "pattern3 = [{'LOWER': 'solar'}, {'IS_PUNCT': True}, {'LOWER': 'power'}]\n",
    "\n",
    "matcher.add('SolarPower', [pattern1, pattern2, pattern3])\n",
    "\n",
    "doc = nlp(\"The Solar Power industry continues to grow as demand for solarpower increases. Solar-power cars are gaining popularity.\")\n",
    "\n",
    "found_matches = matcher(doc)\n",
    "for match_id, start, end in found_matches:\n",
    "    print(f'Word ID {match_id}, starts at {start}, ends at {end}, and word is {doc[start:end]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cf442b",
   "metadata": {},
   "source": [
    "### ğŸ§© Ø´Ø±Ø­ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ | Code Explanation\n",
    "\n",
    "| Ø§Ù„Ø±Ù…Ø²      | ğŸ‡¸ğŸ‡¦ Ø§Ù„Ù…Ø¹Ù†Ù‰                             | ğŸ‡¬ğŸ‡§ Explanation                        |\n",
    "| ---------- | --------------------------------------- | --------------------------------------- |\n",
    "| `LOWER`    | ÙŠØ·Ø§Ø¨Ù‚ Ø§Ù„ÙƒÙ„Ù…Ø© Ø¨Ø¯ÙˆÙ† Ø­Ø³Ø§Ø³ÙŠØ© Ù„Ù„Ø­Ø±ÙˆÙ Ø§Ù„ÙƒØ¨ÙŠØ±Ø© | Case-insensitive word match             |\n",
    "| `IS_PUNCT` | ÙŠØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¹Ù„Ø§Ù…Ø© ØªØ±Ù‚ÙŠÙ…               | Checks if token is punctuation          |\n",
    "| `OP`       | ÙŠØ­Ø¯Ø¯ Ø¹Ø¯Ø¯ Ù…Ø±Ø§Øª Ø§Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡Ø§       | Operator for repetition (`*`, `+`, `?`) |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65019054",
   "metadata": {},
   "source": [
    "### ğŸ§® Ø§Ù„Ø¨Ø§Ø±Ø§Ù…ÙŠØªØ± OP | The OP Parameter\n",
    "\n",
    "| Ø§Ù„Ø±Ù…Ø² | ğŸ‡¸ğŸ‡¦ Ø§Ù„Ù…Ø¹Ù†Ù‰               | ğŸ‡¬ğŸ‡§ Meaning             |\n",
    "| ----- | ------------------------- | ------------------------ |\n",
    "| `*`   | Ø¹Ø¯Ø¯ ØºÙŠØ± Ù…Ø­Ø¯ÙˆØ¯ (0 Ø£Ùˆ Ø£ÙƒØ«Ø±) | Zero or more occurrences |\n",
    "| `+`   | Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„       | One or more occurrences  |\n",
    "| `?`   | Ø§Ø®ØªÙŠØ§Ø±ÙŠ (Ù…Ø±Ø© Ø£Ùˆ Ù„Ø§ Ø´ÙŠØ¡)   | Optional â€” one or none   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a7a9dde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "pattern = [{'LOWER': 'solar'}, {'IS_PUNCT': True, 'OP': '*'}, {'LOWER': 'power'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d06a8e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ØªØ­Ø¯ÙŠØ« Ø£Ùˆ Ø­Ø°Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø· | Update or Remove Patterns\n",
    "\n",
    "matcher.remove('SolarPower')\n",
    "matcher.add('SolarPower', [pattern1, pattern2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246f8c1c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ğŸ’¡ Ø§Ø³ØªØ®Ø¯Ø§Ù… PhraseMatcher | Using PhraseMatcher\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ Ø¹Ù†Ø¯Ù…Ø§ Ù†Ø±ÙŠØ¯ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù†ØµÙˆØµ Ø·ÙˆÙŠÙ„Ø© Ø£Ùˆ Ù…Ù„ÙØ§Øª Ø¹Ù† **Ø¹Ø¨Ø§Ø±Ø§Øª Ø¬Ø§Ù‡Ø²Ø©** Ù…Ø«Ù„ â€œfree-market economicsâ€ØŒ\n",
    "> Ù†Ø³ØªØ®Ø¯Ù… **PhraseMatcher**ØŒ ÙˆÙ‡Ùˆ Ø£Ø³Ø±Ø¹ Ù…Ù† Matcher Ù„Ø£Ù†Ù‡ ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¨Ø§Ø´Ø±Ø© Ù„Ù„Ù†ØµÙˆØµ.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ For longer texts or predefined phrases like â€œfree-market economicsâ€,\n",
    "> use **PhraseMatcher** â€” itâ€™s optimized for direct text matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c99e08a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word ID 8661179581600636185, starts at 41, ends at 45, and phrase is commonly associated with supply-side economics, referred to\n",
      "------------------------------------------------------\n",
      "Word ID 8661179581600636185, starts at 49, ends at 53, and phrase is referred to as trickle-down economics or voodoo economics\n",
      "------------------------------------------------------\n",
      "Word ID 8661179581600636185, starts at 54, ends at 56, and phrase is down economics or voodoo economics by political opponents\n",
      "------------------------------------------------------\n",
      "Word ID 8661179581600636185, starts at 61, ends at 65, and phrase is opponents, and free-market economics by political advocates\n",
      "------------------------------------------------------\n",
      "Word ID 8661179581600636185, starts at 673, ends at 677, and phrase is following from the supply-side economics movement, which\n",
      "------------------------------------------------------\n",
      "Word ID 8661179581600636185, starts at 2986, ends at 2990, and phrase is known as \"trickle-down economics\", due\n",
      "------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "\n",
    "with open('reaganomics.txt', encoding='latin-1') as f:\n",
    "    doc3 = nlp(f.read())\n",
    "\n",
    "phrase_list = ['voodoo economics', 'supply-side economics', 'trickle-down economics', 'free-market economics']\n",
    "phrase_patterns = [nlp(text) for text in phrase_list]\n",
    "matcher.add('ECONOMICS', phrase_patterns)\n",
    "\n",
    "matches = matcher(doc3)\n",
    "for match_id, start, end in matches:\n",
    "    print(f'Word ID {match_id}, starts at {start}, ends at {end}, and phrase is {doc3[start-3:end+3]}')\n",
    "    print('------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fc9f5b",
   "metadata": {},
   "source": [
    "### ğŸŒ ØªØ·Ø¨ÙŠÙ‚ Ø¹Ù„Ù‰ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© | Matching Arabic Text\n",
    "\n",
    "> ğŸ‡¸ğŸ‡¦ ÙÙŠ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù€ Matcher Ù„ØªÙˆØ­ÙŠØ¯ Ø§Ù„ØµÙŠØº Ø§Ù„Ù…Ø®ØªÙ„ÙØ© Ù„Ù„ÙƒÙ„Ù…Ø§Øª Ù…Ø«Ù„:\n",
    "> â€œØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ØµÙ†Ø§Ø¹ÙŠâ€ØŒ â€œØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø¥ØµØ·Ù†Ø§Ø¹ÙŠâ€ØŒ â€œØ§Ù„Ø°ÙƒØ§Ø¡Ø§Ù„Ø¥ØµØ·Ù†Ø§Ø¹ÙŠâ€.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ In Arabic texts, the Matcher helps unify variations like:\n",
    "> â€œØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ØµÙ†Ø§Ø¹ÙŠâ€, â€œØ§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø¥ØµØ·Ù†Ø§Ø¹ÙŠâ€, â€œØ§Ù„Ø°ÙƒØ§Ø¡Ø§Ù„Ø¥ØµØ·Ù†Ø§Ø¹ÙŠâ€."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a1312497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word ID 42380760631695353, starts at 2, ends at 3, and word is Ø§Ù„Ø°ÙƒØ§Ø¡Ø§Ù„Ø¥ØµØ·Ù†Ø§Ø¹ÙŠ\n",
      "Word ID 42380760631695353, starts at 18, ends at 20, and word is Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø¥ØµØ·Ù†Ø§Ø¹ÙŠ\n",
      "Word ID 42380760631695353, starts at 26, ends at 28, and word is Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "pattern1 = [{'LOWER': 'Ø§Ù„Ø°ÙƒØ§Ø¡Ø§Ù„Ø¥ØµØ·Ù†Ø§Ø¹ÙŠ'}]\n",
    "pattern2 = [{'LOWER': 'Ø§Ù„Ø°ÙƒØ§Ø¡'}, {'LOWER': 'Ø§Ù„Ø¥ØµØ·Ù†Ø§Ø¹ÙŠ'}]\n",
    "pattern3 = [{'LOWER': 'Ø§Ù„Ø°ÙƒØ§Ø¡'}, {'LOWER': 'Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ'}]\n",
    "\n",
    "matcher.add('Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ', [pattern1, pattern2, pattern3])\n",
    "\n",
    "doc = nlp('''\n",
    "ÙŠØªÙ…ÙŠØ² Ø§Ù„Ø°ÙƒØ§Ø¡Ø§Ù„Ø¥ØµØ·Ù†Ø§Ø¹ÙŠ Ø£Ù†Ù‡ ÙŠØ³ÙŠØ± Ø¨Ø³Ø±Ø¹Ø© ÙƒØ¨ÙŠØ±Ø© Ù†Ø­Ùˆ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ØŒ\n",
    "ÙˆÙ‚Ø¯ Ø¨Ø¯Ø£ Ø§Ù„ÙƒØ«ÙŠØ± Ù…Ù† Ø§Ù„Ø·Ù„Ø§Ø¨ ÙÙŠ Ø¯Ø±Ø§Ø³Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø¥ØµØ·Ù†Ø§Ø¹ÙŠØŒ\n",
    "ÙˆØªØ²Ø¯Ø§Ø¯ ÙØ±Øµ Ø§Ù„Ø¹Ù…Ù„ ÙÙŠ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ØµÙ†Ø§Ø¹ÙŠ ÙÙŠ ÙƒÙ„ Ù…ÙƒØ§Ù†.\n",
    "''')\n",
    "\n",
    "found_matches = matcher(doc)\n",
    "for match_id, start, end in found_matches:\n",
    "    print(f'Word ID {match_id}, starts at {start}, ends at {end}, and word is {doc[start:end]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd98826c",
   "metadata": {},
   "source": [
    "### ğŸ§± PhraseMatcher Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© | Arabic PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "15aead7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word ID 7482666889028465404, starts at 16, ends at 17, and word is Ø¹ÙÙƒØ§Ø¸ Ø­Ø±Ø¨ Ø¨ÙŠÙ† Ù‚Ø±ÙŠØ´ Ù€ ÙˆÙ…Ø¹Ù‡Ù… ÙƒÙ†Ø§Ù†Ø©\n",
      "Word ID 7482666889028465404, starts at 54, ends at 55, and word is ØŒ ÙˆÙƒØ§Ù† Ù‚Ø§Ø¦Ø¯ Ù‚Ø±ÙŠØ´ ÙˆÙƒÙ†Ø§Ù†Ø© ÙƒÙ„Ù‡Ø§ Ø­Ø±Ø¨\n",
      "Word ID 7482666889028465404, starts at 90, ends at 91, and word is Ø«Ù… ØªØ¯Ø§Ø¹Ù‰ Ø¨Ø¹Ø¶ Ù‚Ø±ÙŠØ´ Ø¥Ù„Ù‰ Ø§Ù„ØµÙ„Ø­ Ø¹Ù„Ù‰\n",
      "Word ID 7482666889028465404, starts at 220, ends at 221, and word is Ø¥Ù„ÙŠÙ‡ Ù‚Ø¨Ø§Ø¦Ù„ Ù…Ù† Ù‚Ø±ÙŠØ´ : Ø¨Ù†Ùˆ Ù‡Ø§Ø´Ù…\n",
      "Word ID 7482666889028465404, starts at 222, ends at 224, and word is Ù…Ù† Ù‚Ø±ÙŠØ´ : Ø¨Ù†Ùˆ Ù‡Ø§Ø´Ù…ØŒ ÙˆØ¨Ù†Ùˆ Ø§Ù„Ù…Ø·Ù„Ø¨ØŒÙˆØ£Ø³Ø¯\n",
      "Word ID 7482666889028465404, starts at 584, ends at 585, and word is Ù„Ù‡Ù…ØŒ ÙˆÙƒØ§Ù†Øª Ù‚Ø±ÙŠØ´ Ù‚ÙˆÙ…Ù‹Ø§ ØªØ¬Ø§Ø±Ù‹Ø§ØŒ\n",
      "Word ID 7482666889028465404, starts at 810, ends at 812, and word is ØŒ ÙˆØ­Ø¶Ø± Ø§Ù„Ø¹Ù‚Ø¯ Ø¨Ù†Ùˆ Ù‡Ø§Ø´Ù… ÙˆØ±Ø¤Ø³Ø§Ø¡ Ù…Ø¶Ø±ØŒ\n",
      "Word ID 7482666889028465404, starts at 997, ends at 998, and word is Ø¹Ù„ÙŠÙ‡ ÙˆØ³Ù„Ù… Ù‚Ø§Ù…Øª Ù‚Ø±ÙŠØ´ Ø¨Ø¨Ù†Ø§Ø¡ Ø§Ù„ÙƒØ¹Ø¨Ø©Ø›\n",
      "Word ID 7482666889028465404, starts at 1075, ends at 1076, and word is Ø§Ù„Ø§Ù†Ù‡ÙŠØ§Ø±ØŒ ÙØ§Ø¶Ø·Ø±Øª Ù‚Ø±ÙŠØ´ Ø¥Ù„Ù‰ ØªØ¬Ø¯ÙŠØ¯ Ø¨Ù†Ø§Ø¦Ù‡Ø§\n",
      "Word ID 7482666889028465404, starts at 5107, ends at 5109, and word is Ø§Ø¨Ù† Ø§Ù„Ù…Ø·Ù„Ø¨ Ø¨Ù† Ø¹Ø¨Ø¯ Ù…Ù†Ø§ÙØŒ ÙˆØ³Ø¹ÙŠØ¯ Ø¨Ù†\n",
      "Word ID 7482666889028465404, starts at 5211, ends at 5212, and word is ÙˆØ£ÙØ®Ø§Ø° Ø´ØªÙ‰ Ù…Ù† Ù‚Ø±ÙŠØ´ .\n",
      "ÙˆÙ…Ù†\n",
      "Word ID 7482666889028465404, starts at 5221, ends at 5222, and word is Ø§Ù„Ø¥Ø³Ù„Ø§Ù… Ù…Ù† ØºÙŠØ± Ù‚Ø±ÙŠØ´ : Ø¹Ø¨Ø¯ Ø§Ù„Ù„Ù‡\n",
      "Word ID 7482666889028465404, starts at 5666, ends at 5667, and word is Ø£Ù†Ù‡Ø§ Ø¹Ø±ÙØª Ù„Ø¯Ù‰ Ù‚Ø±ÙŠØ´ØŒ ÙˆÙØ´Ø§ Ø°ÙƒØ±\n",
      "Word ID 7482666889028465404, starts at 6033, ends at 6035, and word is Ø¹Ù„ÙŠÙ‡ ÙˆØ³Ù„Ù… Ø¹Ø´ÙŠØ±ØªÙ‡ Ø¨Ù†ÙŠ Ù‡Ø§Ø´Ù… Ø¨Ø¹Ø¯ Ù†Ø²ÙˆÙ„ Ù‡Ø°Ù‡\n",
      "Word ID 7482666889028465404, starts at 6044, ends at 6046, and word is ÙˆÙ…Ø¹Ù‡Ù… Ù†ÙØ± Ù…Ù† Ø¨Ù†ÙŠ Ø§Ù„Ù…Ø·Ù„Ø¨ Ø¨Ù† Ø¹Ø¨Ø¯ Ù…Ù†Ø§Ù\n",
      "Word ID 7482666889028465404, starts at 6047, ends at 6049, and word is Ø¨Ù†ÙŠ Ø§Ù„Ù…Ø·Ù„Ø¨ Ø¨Ù† Ø¹Ø¨Ø¯ Ù…Ù†Ø§ÙØŒ ÙÙƒØ§Ù†ÙˆØ§ Ù†Ø­Ùˆ\n",
      "Word ID 7482666889028465404, starts at 6111, ends at 6112, and word is ÙŠØ«Ø¨ Ø¨Ùƒ Ø¨Ø·ÙˆÙ† Ù‚Ø±ÙŠØ´ØŒ ÙˆØªÙ…Ø¯Ù‡Ù… Ø§Ù„Ø¹Ø±Ø¨\n",
      "Word ID 7482666889028465404, starts at 6409, ends at 6410, and word is Ø¬Ø¹Ù„ ÙŠÙ†Ø§Ø¯Ù‰ Ø¨Ø·ÙˆÙ† Ù‚Ø±ÙŠØ´ØŒ ÙˆÙŠØ¯Ø¹ÙˆÙ‡Ù… Ù‚Ø¨Ø§Ø¦Ù„\n",
      "Word ID 7482666889028465404, starts at 6434, ends at 6436, and word is ØŒ ÙŠØ§ Ø¨Ù†ÙŠ Ø¹Ø¨Ø¯ Ù…Ù†Ø§ÙØŒ ÙŠØ§ Ø¨Ù†ÙŠ\n",
      "Word ID 7482666889028465404, starts at 6585, ends at 6586, and word is ( ÙŠØ§ Ù…Ø¹Ø´Ø± Ù‚Ø±ÙŠØ´ØŒ Ø§Ø´ØªØ±ÙˆØ§ Ø£Ù†ÙØ³ÙƒÙ…\n",
      "Word ID 7482666889028465404, starts at 6669, ends at 6671, and word is ÙŠØ§ Ù…Ø¹Ø´Ø± Ø¨Ù†ÙŠ Ø¹Ø¨Ø¯ Ù…Ù†Ø§ÙØŒ Ø£Ù†Ù‚Ø°ÙˆØ§ Ø£Ù†ÙØ³ÙƒÙ…\n",
      "Word ID 7482666889028465404, starts at 6707, ends at 6709, and word is .\n",
      "ÙŠØ§ Ø¨Ù†ÙŠ Ù‡Ø§Ø´Ù…ØŒ Ø£Ù†Ù‚Ø°ÙˆØ§ Ø£Ù†ÙØ³ÙƒÙ…\n",
      "Word ID 7482666889028465404, starts at 7053, ends at 7054, and word is ÙˆØªØ¨Ø§Ø¹Ø¯ ÙˆØ¹Ù†Ø§Ø¯ ÙˆØ§Ø´Ù…Ø£Ø²Øª Ù‚Ø±ÙŠØ´ Ù…Ù† ÙƒÙ„ Ø°Ù„Ùƒ\n",
      "Word ID 7482666889028465404, starts at 7141, ends at 7142, and word is Ø§Ù„Ø­Ø¬ØŒ ÙˆØ¹Ø±ÙØª Ù‚Ø±ÙŠØ´ Ø£Ù† ÙˆÙÙˆØ¯ Ø§Ù„Ø¹Ø±Ø¨\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "\n",
    "with open('raheeq.txt', encoding=\"utf8\") as f:\n",
    "    doc3 = nlp(f.read())\n",
    "\n",
    "phrase_list = ['Ø¨Ù†ÙŠ Ù‡Ø§Ø´Ù…', 'Ø¨Ù†Ùˆ Ù‡Ø§Ø´Ù…', 'Ù‚Ø±ÙŠØ´', 'Ø¨Ù†ÙŠ Ø§Ù„Ù…Ø·Ù„Ø¨', 'Ø¨Ù†Ùˆ Ø§Ù„Ù…Ø·Ù„Ø¨', 'Ø¹Ø¨Ø¯ Ù…Ù†Ø§Ù']\n",
    "phrase_patterns = [nlp(text) for text in phrase_list]\n",
    "matcher.add('Ù‚Ø±ÙŠØ´', phrase_patterns)\n",
    "\n",
    "matches = matcher(doc3)\n",
    "for match_id, start, end in matches:\n",
    "    print(f'Word ID {match_id}, starts at {start}, ends at {end}, and word is {doc3[start-3:end+3]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2682ddaf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ğŸ’¡ Ù…Ù„Ø®Øµ Ø§Ù„Ù‚Ø³Ù… | Section Summary\n",
    "\n",
    "| ğŸ‡¸ğŸ‡¦ Ø§Ù„Ø£Ø¯Ø§Ø©     | ğŸ‡¬ğŸ‡§ Tool                  | ğŸ§  Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…                               |\n",
    "| --------------- | -------------------------- | ------------------------------------------ |\n",
    "| `Matcher`       | Rule-based pattern matcher | Ù…Ø·Ø§Ø¨Ù‚Ø© Ø£Ù†Ù…Ø§Ø· Ù…Ø®ØµØµØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø®ØµØ§Ø¦Øµ Ø§Ù„ÙƒÙ„Ù…Ø§Øª |\n",
    "| `PhraseMatcher` | Fast phrase lookup         | Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø³Ø±ÙŠØ¹ Ø¹Ù† Ø¹Ø¨Ø§Ø±Ø§Øª Ø¬Ø§Ù‡Ø²Ø©               |\n",
    "| `OP`            | Quantifier                 | Ù„ØªØ­Ø¯ÙŠØ¯ Ø¹Ø¯Ø¯ Ù…Ø±Ø§Øª Ø§Ù„ØªÙƒØ±Ø§Ø±                    |\n",
    "| `IS_PUNCT`      | Punctuation flag           | ÙŠØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ…                    |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f59462",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ§  Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„Ø«Ø§Ù…Ù†: Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù†Ø­ÙˆÙŠ\n",
    "\n",
    "## ğŸ‡¸ğŸ‡¦ **Ø§Ù„Ø´Ø±Ø­ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©**\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ Ø§Ù„Ù…ÙÙ‡ÙˆÙ… Ø§Ù„Ø¹Ø§Ù…\n",
    "\n",
    "Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù†Ø­ÙˆÙŠ Ù‡Ùˆ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© Ù„Ù„Ø¬Ù…Ù„ØŒ ÙˆÙ‡Ùˆ Ø§Ù„Ø°ÙŠ ÙŠÙˆØ¶Ù‘Ø­ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„ÙƒÙ„Ù…Ø§Øª ÙÙŠ Ø§Ù„Ø¬Ù…Ù„Ø© ÙˆÙÙ‚ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù†Ø­ÙˆÙŠØ©.\n",
    "ÙŠÙ‡Ø¯Ù Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø­ÙˆÙŠ Ø¥Ù„Ù‰ Ø¨Ù†Ø§Ø¡ ØªÙ…Ø«ÙŠÙ„ ÙŠÙØ¸Ù‡Ø± ÙƒÙŠÙ ØªØ¹ØªÙ…Ø¯ ÙƒÙ„ ÙƒÙ„Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø®Ø±Ù‰ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø¬Ù…Ù„Ø©ØŒ\n",
    "Ù„ÙŠØ³Ø§Ø¹Ø¯ Ø§Ù„Ø­Ø§Ø³ÙˆØ¨ Ø¹Ù„Ù‰ ÙÙ‡Ù… Ø§Ù„Ø¬Ù…Ù„ ÙƒÙˆØ­Ø¯Ø§Øª ÙƒØ§Ù…Ù„Ø© ÙˆÙ„ÙŠØ³Øª Ù…Ø¬Ø±Ø¯ ÙƒÙ„Ù…Ø§Øª Ù…Ù†ÙØµÙ„Ø©.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¤ Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ù†Ø­ÙˆÙŠØ© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©\n",
    "\n",
    "|   Ø§Ù„Ø±Ù…Ø²  | Ø§Ù„Ù…Ø¹Ù†Ù‰ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©       |                      |\n",
    "| :------: | :-------------------- | :------------------- |\n",
    "|   **S**  | Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©        | Sentence             |\n",
    "|  **NP**  | Ø¬Ù…Ù„Ø© Ø§Ø³Ù…ÙŠØ©            | Noun Phrase          |\n",
    "|  **VP**  | Ø¬Ù…Ù„Ø© ÙØ¹Ù„ÙŠØ©            | Verb Phrase          |\n",
    "|  **Det** | Ø£Ø¯Ø§Ø© ØªØ¹Ø±ÙŠÙ Ø£Ùˆ ØªØ­Ø¯ÙŠØ¯   | Determiner           |\n",
    "|  **PP**  | Ø´Ø¨Ù‡ Ø¬Ù…Ù„Ø© (Ø¬Ø§Ø± ÙˆÙ…Ø¬Ø±ÙˆØ±) | Prepositional Phrase |\n",
    "| **ADJP** | Ø¬Ù…Ù„Ø© ØµÙØ©              | Adjective Phrase     |\n",
    "| **ADVP** | Ø¬Ù…Ù„Ø© Ø­Ø§Ù„              | Adverb Phrase        |\n",
    "|   **N**  | Ø§Ø³Ù…                   | Noun                 |\n",
    "|   **V**  | ÙØ¹Ù„                   | Verb                 |\n",
    "|   **P**  | Ø­Ø±Ù Ø¬Ø±                | Preposition          |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸŒ€ Ø£ÙˆÙ„Ù‹Ø§: Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„ØªØ±ÙƒÙŠØ¨ÙŠ (Constituency Structure)\n",
    "\n",
    "ÙŠØ¹ØªÙ…Ø¯ Ù‡Ø°Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¬Ù…Ù„Ø© Ø¥Ù„Ù‰ Ù…ÙƒÙˆÙ†Ø§Øª ØµØºÙŠØ±Ø© Ù…Ø«Ù„ Ø§Ù„ÙØ§Ø¹Ù„ØŒ Ø§Ù„ÙØ¹Ù„ØŒ ÙˆØ§Ù„Ù…ÙØ¹ÙˆÙ„ Ø¨Ù‡ØŒ\n",
    "Ø«Ù… Ø¨Ù†Ø§Ø¡ Ø´Ø¬Ø±Ø© Ù‡Ø±Ù…ÙŠØ© ØªÙˆØ¶Ù‘Ø­ ÙƒÙŠÙÙŠØ© Ø§Ø±ØªØ¨Ø§Ø· Ù‡Ø°Ù‡ Ø§Ù„Ø£Ø¬Ø²Ø§Ø¡ Ù…Ø¹Ù‹Ø§ Ù„ØªÙƒÙˆÙŠÙ† Ø§Ù„Ù…Ø¹Ù†Ù‰ Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù„Ø¬Ù…Ù„Ø©.\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"assets/Constituency.png\" alt=\"NLP Tools\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§± Ù…Ø«Ø§Ù„:\n",
    "\n",
    "**Fed raises interest rate**\n",
    "\n",
    "* **Fed** â†’ Ø¬Ù…Ù„Ø© Ø§Ø³Ù…ÙŠØ© (NP)\n",
    "* **raises** â†’ ÙØ¹Ù„ (V)\n",
    "* **interest rate** â†’ Ø¬Ù…Ù„Ø© Ø§Ø³Ù…ÙŠØ© (NP)\n",
    "\n",
    "Ø¨Ø¯Ù…Ø¬ (NP + V) Ù†Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø¬Ù…Ù„Ø© ÙØ¹Ù„ÙŠØ© (VP)ØŒ\n",
    "Ø«Ù… Ø¨Ø¶Ù…Ù‘Ù‡Ø§ Ø¥Ù„Ù‰ Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„Ø§Ø³Ù…ÙŠØ© Ø§Ù„Ø£ÙˆÙ„Ù‰ ØªØªÙƒÙˆÙ‘Ù† Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø© (S).\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ—£ Ù…Ø«Ø§Ù„ Ø¢Ø®Ø±:\n",
    "\n",
    "**John talked to the children about drugs**\n",
    "\n",
    "ÙŠÙ…ÙƒÙ† Ø¥Ø¹Ø§Ø¯Ø© ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¬Ù…Ù„Ø© Ø¨Ø·Ø±Ù‚ Ù…Ø®ØªÙ„ÙØ© Ø¯ÙˆÙ† Ø£Ù† ÙŠØªØºÙŠØ± Ù…Ø¹Ù†Ø§Ù‡Ø§ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØŒ Ù…Ø«Ù„:\n",
    "\n",
    "* John talked about drugs to the children\n",
    "* About drugs John talked to the children\n",
    "\n",
    "ÙˆØ°Ù„Ùƒ Ù„Ø£Ù† Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ù†Ø­ÙˆÙŠØ© Ø¨ÙŠÙ† Ø§Ù„ÙƒÙ„Ù…Ø§Øª ØªØ¨Ù‚Ù‰ ÙƒÙ…Ø§ Ù‡ÙŠ.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§  Ø§Ù„ØºÙ…ÙˆØ¶ Ø§Ù„ØªØ±ÙƒÙŠØ¨ÙŠ\n",
    "\n",
    "Ø¨Ø¹Ø¶ Ø§Ù„Ø¬Ù…Ù„ ÙŠÙ…ÙƒÙ† Ø£Ù† ØªÙÙÙ‡Ù… Ø¨Ø¹Ø¯Ø© ØªØ±Ø§ÙƒÙŠØ¨ Ù†Ø­ÙˆÙŠØ© Ù…Ø®ØªÙ„ÙØ©ØŒ Ù…Ø«Ù„:\n",
    "**Cats scratch people with cats with claws**\n",
    "ÙÙ‚Ø¯ ÙŠÙÙÙ‡Ù… Ø£Ù† Ø§Ù„Ù‚Ø·Ø· ØªØ®Ø¯Ø´ Ø§Ù„Ù†Ø§Ø³ Ø¨Ù…Ø®Ø§Ù„Ø¨Ù‡Ø§ØŒ\n",
    "Ø£Ùˆ Ø£Ù† Ø§Ù„Ù†Ø§Ø³ Ø§Ù„Ø°ÙŠÙ† Ù„Ø¯ÙŠÙ‡Ù… Ù‚Ø·Ø· Ù‡Ù… Ù…Ù† ÙŠÙØ®Ø¯Ø´ÙˆÙ† â€” Ø­Ø³Ø¨ ØªÙØ³ÙŠØ± Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù†Ø­ÙˆÙŠ.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§© Ù…Ø«Ø§Ù„ ÙƒÙ„Ø§Ø³ÙŠÙƒÙŠ:\n",
    "\n",
    "**Women without her man is nothing**\n",
    "\n",
    "ÙŠÙ…ÙƒÙ† ØªÙØ³ÙŠØ± Ø§Ù„Ø¬Ù…Ù„Ø© Ø¨Ø·Ø±ÙŠÙ‚ØªÙŠÙ† Ù…Ø®ØªÙ„ÙØªÙŠÙ† ØªÙ…Ø§Ù…Ù‹Ø§:\n",
    "\n",
    "1. **Women, without her, man is nothing.** â†’ Ø§Ù„Ù…Ø±Ø£Ø© Ø£Ø³Ø§Ø³ ÙƒÙ„ Ø´ÙŠØ¡.\n",
    "2. **Women without her man, is nothing.** â†’ Ø§Ù„Ù…Ø±Ø£Ø© Ù„Ø§ Ù‚ÙŠÙ…Ø© Ù„Ù‡Ø§ Ø¨Ø¯ÙˆÙ† Ø§Ù„Ø±Ø¬Ù„.\n",
    "\n",
    "Ø§Ù„Ø§Ø®ØªÙ„Ø§Ù ÙÙŠ Ø§Ù„ØªØ±ÙƒÙŠØ¨ Ø§Ù„Ù†Ø­ÙˆÙŠ ØºÙŠÙ‘Ø± Ø§Ù„Ù…Ø¹Ù†Ù‰ ØªÙ…Ø§Ù…Ù‹Ø§!\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”— Ø«Ø§Ù†ÙŠÙ‹Ø§: Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ÙŠ (Dependency Structure)\n",
    "\n",
    "ÙŠØ±ÙƒÙ‘Ø² Ù‡Ø°Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙÙŠ Ø§Ù„Ø¬Ù…Ù„Ø© (Ø§Ù„Ø±Ø£Ø³ - Head)ØŒ\n",
    "Ø«Ù… ÙŠØ­Ø¯Ù‘Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªÙŠ ØªØ¹ØªÙ…Ø¯ Ø¹Ù„ÙŠÙ‡Ø§ Ù…Ø¨Ø§Ø´Ø±Ø©ØŒ\n",
    "Ø£ÙŠ Ù…Ù† ÙŠØ±ØªØ¨Ø· Ø¨Ù…Ù† Ø¯Ø§Ø®Ù„ Ø§Ù„Ø¬Ù…Ù„Ø©.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"assets/Dependency.png\" alt=\"NLP Tools\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "---\n",
    "\n",
    "### âš™ï¸ Ù…Ø«Ø§Ù„:\n",
    "\n",
    "**The boy put the tortoise on the rug**\n",
    "\n",
    "Ø§Ù„ÙƒÙ„Ù…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù‡Ù†Ø§ Ù‡ÙŠ **put**ØŒ ÙˆØªØ±ØªØ¨Ø· Ø¨Ù‡Ø§:\n",
    "\n",
    "* **the boy** â†’ Ø§Ù„ÙØ§Ø¹Ù„ (Subject)\n",
    "* **the tortoise** â†’ Ø§Ù„Ù…ÙØ¹ÙˆÙ„ Ø¨Ù‡ (Object)\n",
    "* **on the rug** â†’ Ø´Ø¨Ù‡ Ø¬Ù…Ù„Ø© (Prepositional Phrase)\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§­ Ù…Ù„Ø§Ø­Ø¸Ø§Øª:\n",
    "\n",
    "Ø¨Ø¹Ø¶ Ø§Ù„Ø¬Ù…Ù„ Ù„Ø§ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…ÙØ¹ÙˆÙ„ Ø¨Ù‡ Ù…Ø«Ù„:\n",
    "**The boy slept.**\n",
    "\n",
    "ÙˆØ£Ø­ÙŠØ§Ù†Ù‹Ø§ ØªØ­ØªÙˆÙŠ Ø§Ù„Ø¬Ù…Ù„ Ø¹Ù„Ù‰ Ù…ÙƒÙˆÙ†Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ù…Ø«Ù„ Ø§Ù„Ø²Ù…Ø§Ù† Ø£Ùˆ Ø§Ù„Ø­Ø§Ù„ØŒ Ù…Ø«Ù„:\n",
    "**Train moved yesterday quickly.**\n",
    "ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø¬Ù…Ù„Ø© Ø§Ù„ÙƒÙ„Ù…Ø© **moved** Ù‡ÙŠ Ø§Ù„Ø±Ø£Ø³ØŒ\n",
    "ÙˆØªØ±ØªØ¨Ø· Ø¨Ù‡Ø§ Ø§Ù„ÙƒÙ„Ù…Ø§Øª **Train** (ÙØ§Ø¹Ù„)ØŒ **yesterday** (Ø¸Ø±Ù Ø²Ù…Ø§Ù†)ØŒ **quickly** (Ø­Ø§Ù„).\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§± Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ÙŠÙ†\n",
    "\n",
    "| Ø§Ù„Ù†ÙˆØ¹                              | Ø§Ù„ÙˆØµÙ                                             |\n",
    "| :--------------------------------- | :------------------------------------------------ |\n",
    "| **Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„ØªØ±ÙƒÙŠØ¨ÙŠ (Constituency)** | ÙŠØ±ÙƒÙ‘Ø² Ø¹Ù„Ù‰ ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¬Ù…Ù„Ø© Ø¥Ù„Ù‰ ÙˆØ­Ø¯Ø§Øª Ù„ØºÙˆÙŠØ© (Ø¹Ø¨Ø§Ø±Ø§Øª).  |\n",
    "| **Ø§Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ÙŠ (Dependency)**  | ÙŠØ±ÙƒÙ‘Ø² Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„ÙƒÙ„Ù…Ø§Øª (Ù…Ù† ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ù…Ù†). |\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ’¡ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø­Ø¯ÙŠØ«Ø© (2025)\n",
    "\n",
    "ÙÙŠ Ø¹Ø§Ù… 2025ØŒ Ø£ØµØ¨Ø­ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Ø­ÙˆÙŠ Ø¬Ø²Ø¡Ù‹Ø§ Ø±Ø¦ÙŠØ³ÙŠÙ‹Ø§ Ù…Ù† Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ù„ØºÙˆÙŠ Ø§Ù„Ø­Ø¯ÙŠØ«Ø© Ù…Ø«Ù„ **GPT** Ùˆ **BERT**.\n",
    "ØªÙØ³ØªØ®Ø¯Ù… Ø£Ø¯ÙˆØ§Øª Ù…Ø«Ù„ **spaCy** Ùˆ **Stanza** Ùˆ **UDPipe** Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù‡ÙŠØ§ÙƒÙ„ Ø§Ù„Ù†Ø­ÙˆÙŠØ© Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø© Ù„Ù„Ø¬Ù…Ù„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…Ø§Ø°Ø¬ Ø¹ØµØ¨ÙŠØ© Ø¹Ù…ÙŠÙ‚Ø©.\n",
    "ÙˆØªÙØ·Ø¨Ù‘Ù‚ Ù‡Ø°Ù‡ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„ÙŠÙˆÙ… ÙÙŠ Ù…Ø¬Ø§Ù„Ø§Øª Ù…Ø«Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù„ØºØ©ØŒ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ÙŠØ©ØŒ ÙˆÙÙ‡Ù… Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…Ø¹Ù‚Ù‘Ø¯Ø©.\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ§  Part Eight: **Syntactic Structure**\n",
    "\n",
    "## ğŸ‡¬ğŸ‡§ **English Explanation**\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ General Concept\n",
    "\n",
    "The syntactic structure represents the internal organization of sentences,\n",
    "showing how words relate to each other according to grammatical rules.\n",
    "\n",
    "The goal of syntactic analysis is to build a structure that shows how each word depends on others,\n",
    "helping computers understand sentences as complete units rather than isolated words.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¤ Main Grammatical Symbols\n",
    "\n",
    "|  Symbol  | English Meaning      |\n",
    "| :------: | :------------------- |\n",
    "|   **S**  | Sentence             |\n",
    "|  **NP**  | Noun Phrase          |\n",
    "|  **VP**  | Verb Phrase          |\n",
    "|  **Det** | Determiner           |\n",
    "|  **PP**  | Prepositional Phrase |\n",
    "| **ADJP** | Adjective Phrase     |\n",
    "| **ADVP** | Adverb Phrase        |\n",
    "|   **N**  | Noun                 |\n",
    "|   **V**  | Verb                 |\n",
    "|   **P**  | Preposition          |\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸŒ€ 1. Constituency Structure\n",
    "\n",
    "This model divides a sentence into smaller components such as the subject, verb, and object,\n",
    "and builds a hierarchical tree showing how these components combine to form meaning.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"assets/Constituency.png\" alt=\"NLP Tools\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§± Example:\n",
    "\n",
    "**Fed raises interest rate**\n",
    "\n",
    "* **Fed** â†’ Noun Phrase (NP)\n",
    "* **raises** â†’ Verb (V)\n",
    "* **interest rate** â†’ Noun Phrase (NP)\n",
    "\n",
    "Combining (NP + V) gives a Verb Phrase (VP),\n",
    "and merging with the first NP forms the complete sentence (S).\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ—£ Another Example:\n",
    "\n",
    "**John talked to the children about drugs**\n",
    "\n",
    "The sentence can be reordered in different ways without changing the overall meaning, e.g.:\n",
    "\n",
    "* John talked about drugs to the children\n",
    "* About drugs John talked to the children\n",
    "\n",
    "Because grammatical relationships remain intact.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§  Structural Ambiguity\n",
    "\n",
    "Some sentences can be interpreted in more than one grammatical way, e.g.:\n",
    "**Cats scratch people with cats with claws**\n",
    "This can mean cats scratch people using claws,\n",
    "or that people with cats are scratched â€” depending on structure.\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§© Classic Example:\n",
    "\n",
    "**Women without her man is nothing**\n",
    "\n",
    "Two completely different meanings:\n",
    "\n",
    "1. **Women, without her, man is nothing.** â†’ Women are essential.\n",
    "2. **Women without her man, is nothing.** â†’ A woman is nothing without her man.\n",
    "\n",
    "The syntactic structure changes the entire interpretation.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”— 2. Dependency Structure\n",
    "\n",
    "This model focuses on the **main word (head)** of the sentence,\n",
    "and identifies which words depend on it â€” i.e., how words are connected grammatically.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"assets/Dependency.png\" alt=\"NLP Tools\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "---\n",
    "\n",
    "### âš™ï¸ Example:\n",
    "\n",
    "**The boy put the tortoise on the rug**\n",
    "\n",
    "Main word: **put**, connected to:\n",
    "\n",
    "* **the boy** â†’ Subject\n",
    "* **the tortoise** â†’ Object\n",
    "* **on the rug** â†’ Prepositional Phrase\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§­ Notes\n",
    "\n",
    "Some sentences have no object, like **The boy slept.**\n",
    "Others include additional elements such as time or manner:\n",
    "**Train moved yesterday quickly.**\n",
    "\n",
    "Here, **moved** is the head, with **Train** (subject), **yesterday** (time), and **quickly** (manner).\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ§± Difference Between Models\n",
    "\n",
    "| Type                       | Description                                          |\n",
    "| :------------------------- | :--------------------------------------------------- |\n",
    "| **Constituency Structure** | Focuses on grouping words into hierarchical phrases. |\n",
    "| **Dependency Structure**   | Focuses on relationships between individual words.   |\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ’¡ Modern Notes (2025)\n",
    "\n",
    "By 2025, syntactic parsing is a key part of advanced language models such as **GPT** and **BERT**.\n",
    "Libraries like **spaCy**, **Stanza**, and **UDPipe** use neural networks to produce precise syntactic analyses.\n",
    "These analyses power fields like **Natural Language Generation**, **Intent Detection**, and **Question Understanding**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775141fa",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# ğŸ§© Ø§Ù„Ø¬Ø²Ø¡ Ø§Ù„ØªØ§Ø³Ø¹: ØªØµÙˆØ± Ø§Ù„Ù†ØµÙˆØµ | Text Visualization\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ¯ Ø§Ù„ØªØ¹Ø±ÙŠÙ | Definition\n",
    "\n",
    "ğŸ‡¸ğŸ‡¦ Ø£Ø¯Ø§Ø© **ØªØµÙˆØ± Ø§Ù„Ù†ØµÙˆØµ** ØªÙØ³ØªØ®Ø¯Ù… Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø£Ùˆ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø¯Ø§Ø®Ù„ Ø§Ù„Ø¬Ù…Ù„Ø© Ø¨Ø´ÙƒÙ„ Ù…Ø±Ø¦ÙŠ ÙˆÙˆØ§Ø¶Ø­.\n",
    "ğŸ‡¬ğŸ‡§ The **Text Visualization** tool is used to visually display the relationships between words or entities within a sentence.\n",
    "\n",
    "ğŸ‡¸ğŸ‡¦ ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø© **`displacy`** Ù…Ù† Ù…ÙƒØªØ¨Ø© **spaCy**ØŒ ÙˆØ§Ù„ØªÙŠ ØªØªÙŠØ­ Ø¹Ø±Ø¶ÙŠÙ† Ø£Ø³Ø§Ø³ÙŠÙŠÙ†:\n",
    "ğŸ‡¬ğŸ‡§ It relies on the **`displacy`** tool from the **spaCy** library, which provides two main visualization styles:\n",
    "\n",
    "| Ù†ÙˆØ¹ Ø§Ù„Ø¹Ø±Ø¶ | ğŸ‡¸ğŸ‡¦ Ø§Ù„ÙˆØµÙ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©                                   | ğŸ‡¬ğŸ‡§ Description                                                   |\n",
    "| --------- | ----------------------------------------------------- | ------------------------------------------------------------------ |\n",
    "| **dep**   | Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ù†Ø­ÙˆÙŠØ© (Ù…Ù† ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ù…Ù†)               | Shows syntactic *dependencies* between words                       |\n",
    "| **ent**   | Ù„Ø¹Ø±Ø¶ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³Ù…Ø§Ø© Ù…Ø«Ù„ Ø§Ù„Ø£Ø´Ø®Ø§Øµ ÙˆØ§Ù„Ù…Ù†Ø¸Ù…Ø§Øª ÙˆØ§Ù„ØªÙˆØ§Ø±ÙŠØ® | Displays *Named Entities* such as people, organizations, and dates |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e274233",
   "metadata": {},
   "source": [
    "### ğŸ§± Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø¹Ø±Ø¶ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ù†Ø­ÙˆÙŠØ© | Using Dependency Visualization (`style='dep'`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "968d1c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"1654aafd88c4467393acc8b0829de5e1-0\" class=\"displacy\" width=\"1010\" height=\"297.0\" direction=\"ltr\" style=\"max-width: none; height: 297.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"130\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"130\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"210\">going</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"210\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"290\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"290\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"370\">build</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"370\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"530\">U.K.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"530\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"610\">factory</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"610\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"690\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"690\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"850\">6</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"850\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"207.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">million.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1654aafd88c4467393acc8b0829de5e1-0-0\" stroke-width=\"2px\" d=\"M70,162.0 C70,82.0 200.0,82.0 200.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1654aafd88c4467393acc8b0829de5e1-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,164.0 L62,152.0 78,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1654aafd88c4467393acc8b0829de5e1-0-1\" stroke-width=\"2px\" d=\"M150,162.0 C150,122.0 195.0,122.0 195.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1654aafd88c4467393acc8b0829de5e1-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M150,164.0 L142,152.0 158,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1654aafd88c4467393acc8b0829de5e1-0-2\" stroke-width=\"2px\" d=\"M310,162.0 C310,122.0 355.0,122.0 355.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1654aafd88c4467393acc8b0829de5e1-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M310,164.0 L302,152.0 318,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1654aafd88c4467393acc8b0829de5e1-0-3\" stroke-width=\"2px\" d=\"M230,162.0 C230,82.0 360.0,82.0 360.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1654aafd88c4467393acc8b0829de5e1-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M360.0,164.0 L368.0,152.0 352.0,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1654aafd88c4467393acc8b0829de5e1-0-4\" stroke-width=\"2px\" d=\"M470,162.0 C470,82.0 600.0,82.0 600.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1654aafd88c4467393acc8b0829de5e1-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M470,164.0 L462,152.0 478,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1654aafd88c4467393acc8b0829de5e1-0-5\" stroke-width=\"2px\" d=\"M550,162.0 C550,122.0 595.0,122.0 595.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1654aafd88c4467393acc8b0829de5e1-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M550,164.0 L542,152.0 558,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1654aafd88c4467393acc8b0829de5e1-0-6\" stroke-width=\"2px\" d=\"M390,162.0 C390,42.0 605.0,42.0 605.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1654aafd88c4467393acc8b0829de5e1-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M605.0,164.0 L613.0,152.0 597.0,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1654aafd88c4467393acc8b0829de5e1-0-7\" stroke-width=\"2px\" d=\"M390,162.0 C390,2.0 690.0,2.0 690.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1654aafd88c4467393acc8b0829de5e1-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M690.0,164.0 L698.0,152.0 682.0,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1654aafd88c4467393acc8b0829de5e1-0-8\" stroke-width=\"2px\" d=\"M790,162.0 C790,82.0 920.0,82.0 920.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1654aafd88c4467393acc8b0829de5e1-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M790,164.0 L782,152.0 798,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1654aafd88c4467393acc8b0829de5e1-0-9\" stroke-width=\"2px\" d=\"M870,162.0 C870,122.0 915.0,122.0 915.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1654aafd88c4467393acc8b0829de5e1-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M870,164.0 L862,152.0 878,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-1654aafd88c4467393acc8b0829de5e1-0-10\" stroke-width=\"2px\" d=\"M710,162.0 C710,42.0 925.0,42.0 925.0,162.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-1654aafd88c4467393acc8b0829de5e1-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M925.0,164.0 L933.0,152.0 917.0,152.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "# Load the English model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Process a sample sentence\n",
    "doc = nlp(u'Apple is going to build a U.K. factory for $6 million.')\n",
    "\n",
    "# Visualize dependencies inside Jupyter\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 80})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46976055",
   "metadata": {},
   "source": [
    "> ğŸ‡¸ğŸ‡¦ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø«Ø§Ù„ ÙŠØªÙ… Ø¹Ø±Ø¶ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø¨ÙŠÙ† Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø¨ÙˆØ§Ø³Ø·Ø© Ø£Ø³Ù‡Ù… ØªÙˆØ¶Ø­ Ù…Ù† ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ù…Ù† (Ù…Ø«Ù„ Ø§Ù„ÙØ§Ø¹Ù„ ÙˆØ§Ù„Ù…ÙØ¹ÙˆÙ„ ÙˆØ§Ù„ÙØ¹Ù„).\n",
    ">\n",
    ">ğŸ‡¬ğŸ‡§ In this example, arrows indicate which words depend on others (subject, object, verb, etc.).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb6a566",
   "metadata": {},
   "source": [
    "### ğŸ” Ø¹Ø±Ø¶ ØªÙØ§ØµÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª | Inspecting Word Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "68635ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple      PROPN   nsubj   nominal subject\n",
      "is         AUX     aux     auxiliary\n",
      "going      VERB    ROOT    root\n",
      "to         PART    aux     auxiliary\n",
      "build      VERB    xcomp   open clausal complement\n",
      "a          DET     det     determiner\n",
      "U.K.       PROPN   compound compound\n",
      "factory    NOUN    dobj    direct object\n",
      "for        ADP     prep    prepositional modifier\n",
      "$          SYM     quantmod modifier of quantifier\n",
      "6          NUM     compound compound\n",
      "million    NUM     pobj    object of preposition\n",
      ".          PUNCT   punct   punctuation\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f'{token.text:{10}} {token.pos_:{7}} {token.dep_:{7}} {spacy.explain(token.dep_)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6a9a2f",
   "metadata": {},
   "source": [
    "> ğŸ‡¸ğŸ‡¦ ÙŠØ·Ø¨Ø¹ Ù‡Ø°Ø§ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ÙƒÙ„Ù…Ø© ÙˆÙ†ÙˆØ¹Ù‡Ø§ ÙˆÙˆØ¸ÙŠÙØªÙ‡Ø§ Ø§Ù„Ù†Ø­ÙˆÙŠØ© ÙˆÙ…Ø¹Ù†Ø§Ù‡Ø§.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ This prints each word, its POS tag, dependency label, and its explanation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6005944",
   "metadata": {},
   "source": [
    "### ğŸŒ Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ù… ÙÙŠ Ø§Ù„Ù…ØªØµÙØ­ | Display on Web Browser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "603a08e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render on browser (works outside restricted environments)\n",
    "# displacy.serve(doc, style='dep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce502929",
   "metadata": {},
   "source": [
    "> ğŸ‡¸ğŸ‡¦ ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‡Ø°Ø§ Ø§Ù„Ø£Ù…Ø± Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø´ÙƒÙ„ ÙÙŠ Ù…ØªØµÙØ­ Ø®Ø§Ø±Ø¬ÙŠ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Jupyter.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ You can use this command to render the visualization in a browser instead of Jupyter.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b67dbe7",
   "metadata": {},
   "source": [
    "### ğŸ§© Ø¹Ø±Ø¶ Ø¹Ø¯Ø© Ø¬Ù…Ù„ | Visualizing Multiple Sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "849b6cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "    <head>\n",
       "        <title>displaCy</title>\n",
       "    </head>\n",
       "\n",
       "    <body style=\"font-size: 16px; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol'; padding: 4rem 2rem; direction: ltr\">\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"f04256f043914d36a456acc89e547b02-0\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">This</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">sentence.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f04256f043914d36a456acc89e547b02-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f04256f043914d36a456acc89e547b02-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f04256f043914d36a456acc89e547b02-0-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f04256f043914d36a456acc89e547b02-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f04256f043914d36a456acc89e547b02-0-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f04256f043914d36a456acc89e547b02-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "\n",
       "<figure style=\"margin-bottom: 6rem\">\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"f04256f043914d36a456acc89e547b02-1\" class=\"displacy\" width=\"750\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">This</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">another</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">sentence.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f04256f043914d36a456acc89e547b02-1-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f04256f043914d36a456acc89e547b02-1-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f04256f043914d36a456acc89e547b02-1-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f04256f043914d36a456acc89e547b02-1-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-f04256f043914d36a456acc89e547b02-1-2\" stroke-width=\"2px\" d=\"M245,177.0 C245,2.0 575.0,2.0 575.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-f04256f043914d36a456acc89e547b02-1-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M575.0,179.0 L583.0,167.0 567.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>\n",
       "</figure>\n",
       "</body>\n",
       "</html></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc1 = nlp(\"This is a sentence.\")\n",
    "doc2 = nlp(\"This is another sentence.\")\n",
    "html = displacy.render([doc1, doc2], style=\"dep\", page=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7476d7b4",
   "metadata": {},
   "source": [
    "### ğŸ¨ ØªØ®ØµÙŠØµ Ø§Ù„Ù…Ø¸Ù‡Ø± | Customizing Appearance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4052db0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"ecce5d2e00694ecfbb2148b062b8a200-0\" class=\"displacy\" width=\"1850\" height=\"437.0\" direction=\"ltr\" style=\"max-width: none; height: 437.0px; color: white; background: #09a3d5; font-family: Source Sans Pro; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">going</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">to</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">build</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"800\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"800\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">U.K.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">factory</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1400\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1400\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1550\">6</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1550\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"347.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1700\">million.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1700\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ecce5d2e00694ecfbb2148b062b8a200-0-0\" stroke-width=\"2px\" d=\"M62,302.0 62,252.0 344.0,252.0 344.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ecce5d2e00694ecfbb2148b062b8a200-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,304.0 L58,296.0 66,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ecce5d2e00694ecfbb2148b062b8a200-0-1\" stroke-width=\"2px\" d=\"M212,302.0 212,277.0 341.0,277.0 341.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ecce5d2e00694ecfbb2148b062b8a200-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M212,304.0 L208,296.0 216,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ecce5d2e00694ecfbb2148b062b8a200-0-2\" stroke-width=\"2px\" d=\"M512,302.0 512,277.0 641.0,277.0 641.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ecce5d2e00694ecfbb2148b062b8a200-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M512,304.0 L508,296.0 516,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ecce5d2e00694ecfbb2148b062b8a200-0-3\" stroke-width=\"2px\" d=\"M362,302.0 362,252.0 644.0,252.0 644.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ecce5d2e00694ecfbb2148b062b8a200-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M644.0,304.0 L648.0,296.0 640.0,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ecce5d2e00694ecfbb2148b062b8a200-0-4\" stroke-width=\"2px\" d=\"M812,302.0 812,252.0 1094.0,252.0 1094.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ecce5d2e00694ecfbb2148b062b8a200-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M812,304.0 L808,296.0 816,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ecce5d2e00694ecfbb2148b062b8a200-0-5\" stroke-width=\"2px\" d=\"M962,302.0 962,277.0 1091.0,277.0 1091.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ecce5d2e00694ecfbb2148b062b8a200-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M962,304.0 L958,296.0 966,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ecce5d2e00694ecfbb2148b062b8a200-0-6\" stroke-width=\"2px\" d=\"M662,302.0 662,227.0 1097.0,227.0 1097.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ecce5d2e00694ecfbb2148b062b8a200-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1097.0,304.0 L1101.0,296.0 1093.0,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ecce5d2e00694ecfbb2148b062b8a200-0-7\" stroke-width=\"2px\" d=\"M662,302.0 662,202.0 1250.0,202.0 1250.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ecce5d2e00694ecfbb2148b062b8a200-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1250.0,304.0 L1254.0,296.0 1246.0,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ecce5d2e00694ecfbb2148b062b8a200-0-8\" stroke-width=\"2px\" d=\"M1412,302.0 1412,252.0 1694.0,252.0 1694.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ecce5d2e00694ecfbb2148b062b8a200-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1412,304.0 L1408,296.0 1416,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ecce5d2e00694ecfbb2148b062b8a200-0-9\" stroke-width=\"2px\" d=\"M1562,302.0 1562,277.0 1691.0,277.0 1691.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ecce5d2e00694ecfbb2148b062b8a200-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1562,304.0 L1558,296.0 1566,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-ecce5d2e00694ecfbb2148b062b8a200-0-10\" stroke-width=\"2px\" d=\"M1262,302.0 1262,227.0 1697.0,227.0 1697.0,302.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-ecce5d2e00694ecfbb2148b062b8a200-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1697.0,304.0 L1701.0,296.0 1693.0,296.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style=\"dep\", options={\n",
    "    \"compact\": True,\n",
    "    \"bg\": \"#09a3d5\",\n",
    "    \"color\": \"white\",\n",
    "    \"font\": \"Source Sans Pro\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb922e55",
   "metadata": {},
   "source": [
    "> ğŸ‡¸ğŸ‡¦ ÙŠÙ…ÙƒÙ†Ùƒ ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø®Ù„ÙÙŠØ©ØŒ Ø§Ù„Ø®Ø·ØŒ Ø§Ù„Ø£Ù„ÙˆØ§Ù†ØŒ ÙˆØ§Ù„Ù…Ø³Ø§ÙØ© Ø¨ÙŠÙ† Ø§Ù„ÙƒÙ„Ù…Ø§Øª.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ You can change background, font, colors, and spacing between words.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2bae39",
   "metadata": {},
   "source": [
    "### ğŸ’¾ Ø­ÙØ¸ Ø§Ù„Ø±Ø³Ù… ÙƒØµÙˆØ±Ø© SVG | Exporting Visualization as SVG Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3da410fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "sentences = [\"This is an example.\", \"This is another one.\"]\n",
    "for sent in sentences:\n",
    "    doc = nlp(sent)\n",
    "    svg = displacy.render(doc, style=\"dep\", jupyter=False)\n",
    "    file_name = '-'.join([w.text for w in doc if not w.is_punct]) + \".svg\"\n",
    "    output_path = Path(file_name)\n",
    "    output_path.open(\"w\", encoding=\"utf-8\").write(svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb664be2",
   "metadata": {},
   "source": [
    "> ğŸ‡¸ğŸ‡¦ ÙŠÙ…ÙƒÙ† Ø­ÙØ¸ Ø§Ù„Ù…Ø®Ø·Ø· ÙƒØµÙˆØ±Ø© SVG Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¯Ù‚Ø© Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ ÙÙŠ Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ± Ø£Ùˆ Ø§Ù„Ø¹Ø±ÙˆØ¶.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ You can export the dependency graph as a high-quality SVG image for reports or presentations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d015d4e",
   "metadata": {},
   "source": [
    "### ğŸ§  Ø¹Ø±Ø¶ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³Ù…Ø§Ø© | Named Entity Visualization (`style='ent'`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a430db74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the last quarter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    nearly 20 thousand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " iPods for a profit of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $6 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(u'Over the last quarter Apple sold nearly 20 thousand iPods for a profit of $6 million.')\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125676ae",
   "metadata": {},
   "source": [
    "> ğŸ‡¸ğŸ‡¦ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ø¹Ø±Ø¶ØŒ ÙŠØªÙ… ØªÙ„ÙˆÙŠÙ† Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³Ù…Ø§Ø© Ù…Ø«Ù„ Ø§Ù„Ø´Ø±ÙƒØ§ØªØŒ Ø§Ù„Ø£Ø±Ù‚Ø§Ù…ØŒ ÙˆØ§Ù„ØªÙˆØ§Ø±ÙŠØ® Ø¨Ø£Ù„ÙˆØ§Ù† Ù…Ø®ØªÙ„ÙØ©.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ In this visualization, named entities like companies, numbers, and dates are highlighted in different colors.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167d13e4",
   "metadata": {},
   "source": [
    "### ğŸ¨ ØªØ®ØµÙŠØµ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ø£Ù„ÙˆØ§Ù† | Customizing Entities and Colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d52b4969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over the last quarter \n",
       "<mark class=\"entity\" style=\"background: linear-gradient(90deg, #aa9cfc, #fc9ce7); padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold nearly 20 thousand iPods for a profit of $6 million.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options = {'ents': ['ORG', 'PRODUCT']}\n",
    "colors = {'ORG': 'linear-gradient(90deg, #aa9cfc, #fc9ce7)', 'PRODUCT': 'radial-gradient(yellow, green)'}\n",
    "\n",
    "displacy.render(doc, style='ent', jupyter=True, options={'ents': ['ORG', 'PRODUCT'], 'colors': colors})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8748d0",
   "metadata": {},
   "source": [
    "> ğŸ‡¸ğŸ‡¦ ÙŠÙ…ÙƒÙ†Ùƒ ØªØ­Ø¯ÙŠØ¯ Ø£Ù†ÙˆØ§Ø¹ Ù…Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ù„ØªØ¸Ù‡Ø± ÙÙ‚Ø·ØŒ ÙˆØªØ®ØµÙŠØµ Ø£Ù„ÙˆØ§Ù†Ù‡Ø§ Ø§Ù„Ø®Ø§ØµØ©.\n",
    ">\n",
    "> ğŸ‡¬ğŸ‡§ You can choose specific entity types to display and assign them custom colors.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dded45",
   "metadata": {},
   "source": [
    "### ğŸŒ Ø¯Ø¹Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© | Arabic Language Support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6cd8051e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"0ec99de6b19743de981827e1f8e3a06c-0\" class=\"displacy\" width=\"850\" height=\"337.0\" direction=\"ltr\" style=\"max-width: none; height: 337.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Ø³ØªÙ‚ÙˆÙ…</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"130\">Ø´Ø±ÙƒØ©</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"130\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"210\">Ù…Ø±Ø³ÙŠØ¯Ø³</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"210\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"290\">Ø¨Ø´Ø±Ø§Ø¡</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"290\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"370\">Ø´Ø±ÙƒØ©</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"370\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">ÙƒØ±Ø§ÙŠØ³Ù„Ø±</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"530\">Ø¨Ù…Ø¨Ù„Øº</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"530\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"610\">5</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"610\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"690\">Ù…Ù„ÙŠÙˆÙ†</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"690\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">Ø¯ÙˆÙ„Ø§Ø±</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0ec99de6b19743de981827e1f8e3a06c-0-0\" stroke-width=\"2px\" d=\"M150,202.0 C150,162.0 190.0,162.0 190.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0ec99de6b19743de981827e1f8e3a06c-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M150,204.0 L142,192.0 158,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0ec99de6b19743de981827e1f8e3a06c-0-1\" stroke-width=\"2px\" d=\"M230,202.0 C230,162.0 270.0,162.0 270.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0ec99de6b19743de981827e1f8e3a06c-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M230,204.0 L222,192.0 238,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0ec99de6b19743de981827e1f8e3a06c-0-2\" stroke-width=\"2px\" d=\"M70,202.0 C70,122.0 275.0,122.0 275.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0ec99de6b19743de981827e1f8e3a06c-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M275.0,204.0 L283.0,192.0 267.0,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0ec99de6b19743de981827e1f8e3a06c-0-3\" stroke-width=\"2px\" d=\"M70,202.0 C70,82.0 360.0,82.0 360.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0ec99de6b19743de981827e1f8e3a06c-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M360.0,204.0 L368.0,192.0 352.0,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0ec99de6b19743de981827e1f8e3a06c-0-4\" stroke-width=\"2px\" d=\"M70,202.0 C70,42.0 445.0,42.0 445.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0ec99de6b19743de981827e1f8e3a06c-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M445.0,204.0 L453.0,192.0 437.0,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0ec99de6b19743de981827e1f8e3a06c-0-5\" stroke-width=\"2px\" d=\"M470,202.0 C470,162.0 510.0,162.0 510.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0ec99de6b19743de981827e1f8e3a06c-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M510.0,204.0 L518.0,192.0 502.0,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0ec99de6b19743de981827e1f8e3a06c-0-6\" stroke-width=\"2px\" d=\"M630,202.0 C630,122.0 755.0,122.0 755.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0ec99de6b19743de981827e1f8e3a06c-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M630,204.0 L622,192.0 638,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0ec99de6b19743de981827e1f8e3a06c-0-7\" stroke-width=\"2px\" d=\"M710,202.0 C710,162.0 750.0,162.0 750.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0ec99de6b19743de981827e1f8e3a06c-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M710,204.0 L702,192.0 718,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0ec99de6b19743de981827e1f8e3a06c-0-8\" stroke-width=\"2px\" d=\"M70,202.0 C70,2.0 770.0,2.0 770.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0ec99de6b19743de981827e1f8e3a06c-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770.0,204.0 L778.0,192.0 762.0,192.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp('Ø³ØªÙ‚ÙˆÙ… Ø´Ø±ÙƒØ© Ù…Ø±Ø³ÙŠØ¯Ø³ Ø¨Ø´Ø±Ø§Ø¡ Ø´Ø±ÙƒØ© ÙƒØ±Ø§ÙŠØ³Ù„Ø± Ø¨Ù…Ø¨Ù„Øº 5 Ù…Ù„ÙŠÙˆÙ† Ø¯ÙˆÙ„Ø§Ø±')\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 80})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b649fbc9",
   "metadata": {},
   "source": [
    "> ğŸ‡¸ğŸ‡¦ ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø¯Ø§Ø© Ù…Ø¹ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©ØŒ Ù„ÙƒÙ†Ù‡Ø§ ØªÙ‚Ø¯Ù… Ø£Ø¯Ø§Ø¡ Ù…ØªÙˆØ³Ø·Ù‹Ø§ Ù„Ø£Ù†Ù‡Ø§ Ù„ÙŠØ³Øª Ù…Ø¯Ø±Ø¨Ø© Ø¨Ø´ÙƒÙ„ Ù…Ø®ØµØµ Ù„Ù„Ø¹Ø±Ø¨ÙŠØ©.\n",
    ">\n",
    ">ğŸ‡¬ğŸ‡§ The tool can handle Arabic text, though performance is moderate as the model isnâ€™t fine-tuned for Arabic.\n",
    "\n",
    ">ğŸ‡¸ğŸ‡¦ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ØŒ ÙŠÙÙØ¶Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…Ø§Ø°Ø¬ Ù…Ø«Ù„ **CAMeL Tools** Ø£Ùˆ **AraBERT**.\n",
    ">\n",
    ">ğŸ‡¬ğŸ‡§ For better Arabic performance, use specialized models like **CAMeL Tools** or **AraBERT**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125728d4",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### ğŸ§¾ Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ø¹Ø§Ù… | Summary Table\n",
    "\n",
    "| Ø§Ù„Ø®Ø§ØµÙŠØ©         | ğŸ‡¸ğŸ‡¦ Ø§Ù„Ø´Ø±Ø­ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©              | ğŸ‡¬ğŸ‡§ English Description                |\n",
    "| --------------- | -------------------------------- | --------------------------------------- |\n",
    "| **style='dep'** | Ø¹Ø±Ø¶ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ù†Ø­ÙˆÙŠØ© Ø¨ÙŠÙ† Ø§Ù„ÙƒÙ„Ù…Ø§Øª | Shows syntactic dependencies            |\n",
    "| **style='ent'** | Ø¹Ø±Ø¶ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³Ù…Ø§Ø© Ø¯Ø§Ø®Ù„ Ø§Ù„Ù†Øµ   | Displays named entities                 |\n",
    "| **options**     | Ù„ØªØ®ØµÙŠØµ Ø§Ù„Ø£Ù„ÙˆØ§Ù† ÙˆØ§Ù„Ø®Ù„ÙÙŠØ© ÙˆØ§Ù„Ø®Ø·    | Customize colors, background, and fonts |\n",
    "| **render()**    | Ø¹Ø±Ø¶ Ø¯Ø§Ø®Ù„ Jupyter Notebook        | Render inside Jupyter                   |\n",
    "| **serve()**     | Ø¹Ø±Ø¶ ÙÙŠ Ù…ØªØµÙØ­ Ø®Ø§Ø±Ø¬ÙŠ               | Render on web browser                   |\n",
    "| **SVG export**  | Ø­ÙØ¸ Ø§Ù„Ø´ÙƒÙ„ ÙƒØµÙˆØ±Ø© Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø¬ÙˆØ¯Ø©     | Export visualization as SVG             |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd76aa2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## ğŸ Ø§Ù„Ø®Ø§ØªÙ…Ø© | Conclusion\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ‡¸ğŸ‡¦\n",
    "ÙˆÙ‡ÙƒØ°Ø§ Ù†ÙƒÙˆÙ† Ù‚Ø¯ ÙˆØµÙ„Ù†Ø§ Ø¥Ù„Ù‰ Ù†Ù‡Ø§ÙŠØ© Ø±Ø­Ù„ØªÙ†Ø§ ÙÙŠ **Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºÙˆÙŠØ© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© (NLP Tools)** ğŸŒŸ\n",
    "ØªØ¹Ø±ÙÙ†Ø§ Ø¹Ù„Ù‰ ÙƒÙŠÙÙŠØ© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ© â€” Ù…Ù† **ØªØ¬Ø²Ø¦Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª (Tokenization)** Ø¥Ù„Ù‰ **ØªÙ…ÙŠÙŠØ² Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª (NER)**ØŒ\n",
    "Ù…Ø±ÙˆØ±Ù‹Ø§ Ø¨Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ **Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ù†Ø­ÙˆÙŠØ© (POS)**ØŒ ÙˆØ¨Ù†Ø§Ø¡ **Ø§Ù„Ù‡ÙŠØ§ÙƒÙ„ Ø§Ù„Ù†Ø­ÙˆÙŠØ© (Syntax & Dependency Trees)**ØŒ\n",
    "ÙˆØ§Ù†ØªÙ‡Ø§Ø¡Ù‹ Ø¨Ø¹Ø±Ø¶Ù‡Ø§ Ø¨ØµØ±ÙŠÙ‹Ø§ Ø¹Ø¨Ø± Ø£Ø¯Ø§Ø© **Visualization â€“ displaCy** Ø§Ù„Ø±Ø§Ø¦Ø¹Ø©.\n",
    "\n",
    "Ù„Ù‚Ø¯ Ø£ØµØ¨Ø­Øª Ø§Ù„Ø¢Ù† ØªÙ…ØªÙ„Ùƒ ÙÙ‡Ù…Ù‹Ø§ Ù‚ÙˆÙŠÙ‹Ø§ Ù„Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ© Ù„Ù„Ø¬Ù…Ù„ØŒ\n",
    "ÙˆÙƒÙŠÙ ÙŠÙÙƒØ± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù„ØºÙˆÙŠ ÙÙŠ ØªØ­Ù„ÙŠÙ„ ÙƒÙ„ ÙƒÙ„Ù…Ø© Ø¯Ø§Ø®Ù„ Ø§Ù„Ù†Øµ ğŸ§ âœ¨\n",
    "\n",
    "Ù„ÙƒÙ† Ø±Ø­Ù„ØªÙ†Ø§ Ù„Ù… ØªÙ†ØªÙ‡Ù Ø¨Ø¹Ø¯! ğŸš€\n",
    "ÙÙŠ Ø§Ù„Ù‚Ø³Ù… Ø§Ù„ØªØ§Ù„ÙŠØŒ Ø³Ù†Ø¨Ø¯Ø£ **Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨Ø³ÙŠØ·Ø© Ù„Ù„Ù†ØµÙˆØµ (Basic Text Processing)** â€”\n",
    "Ø­ÙŠØ« Ø³Ù†ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµØŒ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶Ø¬ÙŠØ¬ØŒ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³Ø¨Ù‚Ø© (Preprocessing)ØŒ\n",
    "ÙˆØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø§Ù„Ø®Ø§Ù… Ø¥Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø§Ù‡Ø²Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ ÙˆØ§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ ÙÙŠ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬.\n",
    "\n",
    "Ø§Ø³ØªØ¹Ø¯Ù‘ ğŸ”¥ ÙØ§Ù„Ù‚Ø§Ø¯Ù… Ù‡Ùˆ Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ù†Ø­Ùˆ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø¥Ù„Ù‰ **Ù…Ø¹Ø±ÙØ© Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„**!\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ‡¬ğŸ‡§\n",
    "And that brings us to the end of our journey through **Natural Language Processing Tools (NLP Tools)** ğŸŒŸ\n",
    "Weâ€™ve explored how text is analyzed step by step â€” from **Tokenization** and **POS tagging**,\n",
    "to **Named Entity Recognition (NER)** and **Syntactic Structures (Dependency Trees)**,\n",
    "culminating in beautiful visualizations with **spaCyâ€™s displaCy** tool.\n",
    "\n",
    "You now understand how words connect, how grammar is represented,\n",
    "and how NLP models interpret the language we use every day ğŸ§ âœ¨\n",
    "\n",
    "But the adventure doesnâ€™t stop here! ğŸš€\n",
    "Next, weâ€™ll dive into **Basic Text Processing** â€”\n",
    "where weâ€™ll clean, normalize, and prepare raw text for intelligent analysis and model training.\n",
    "\n",
    "Get ready ğŸ”¥ because up next we begin transforming raw words into **actionable insights**!\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
